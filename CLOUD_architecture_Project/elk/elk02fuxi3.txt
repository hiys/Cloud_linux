1 昨天已经搭建好 elasticsearch 集群
清除所有 index
导入 logs.jsonl 日志

mapping：
映射：创建索引的时候，可以预先定义字段的类型及相关属性。
作用：这样会让索引建立得更加的细致和完善。
分类：静态映射和动态映射。
动态映射：自动根据数据进行相应的映射。
静态映射：自定义字段映射数据类型。

kibana部分

1.kibana的概念及特点。
概念：数据可视化平台工具
特点：
    - 灵活的分析和可视化平台
    - 实时总结和流数据的图表
    - 为不同的用户显示直观的界面
    - 即时分享和嵌入的仪表板

2.kibana的安装配置。
rpm -ivh kibana-4.5.2-1.x86_64.rpm

#配置 kibana 
/opt/kibana/config/kibana.yml
server.port: 5601
server.host: "0.0.0.0"
elasticsearch.url: "http://192.168.4.13:9200"
kibana.index: ".kibana"
kibana.defaultAppId: "discover"
elasticsearch.pingTimeout: 1500
elasticsearch.requestTimeout: 30000
elasticsearch.startupTimeout: 5000

通过图形页面展示，注意时间是 2015 年，需要调整时间才能正常显示

Beats 平台集合了多种单一用途 数据采集器。
这些采集器安装后可用作轻量型代理，
从成百上千或成千上万台机器向 Logstash 或 Elasticsearch 发送数据
--------------------------------在 所有的 web 服务器上下载并安装Filebeat------------------
filebeat-1.2.3-x86_64.rpm   

logstash部分
Logstash 是 Elastic Stack 的中央数据流引擎，
用于收集、丰富和统一所有数据，而不管格式或模式。
当与Elasticsearch，Kibana，及 Beats 共同使用
的时候便会拥有特别强大的实时处理能力

 logstash是一个数据分析软件，主要目的是分析log日志。
整一套软件可以当作一个MVC模型，
logstash是controller层，
Elasticsearch是一个model层，
kibana是view层。
  首先将数据传给logstash，
它将数据进行过滤和格式化（转成JSON格式），
然后传给Elasticsearch进行存储、建搜索的索引，
kibana提供前端的页面再进行搜索和图表可视化，
它是调用Elasticsearch的接口返回的数据进行可视化。
logstash和Elasticsearch是用Java写的，
kibana使用node.js框架。

这个软件官网有很详细的使用说明，https://www.elastic.co/，除了docs之外，
还有视频教程

3.logstash的概念及特点。

Logstash 是 Elastic Stack 的中央数据流引擎，
用于收集、丰富和统一所有数据，
而不管格式或模式。
当与Elasticsearch，Kibana，及 Beats 共同使用
的时候便会拥有强大的实时处理能力

概念：logstash是一个数据采集、加工处理以及传输(输出)的工具。
特点：
    - 所有类型的数据集中处理
    - 不同模式和格式数据的正常化
    - 自定义日志格式的迅速扩展
    - 为自定义数据源轻松添加插件

https://www.elastic.co/cn/videos

filebeat-1.2.3-x86_64.rpm   

Beats 是一系列轻量级的数据收集器，
直接运行在终端设备并向 Elasticsearch 发送数据信息。
Packetbeat 用来收集网络数据。

安装Logstash
rpm -ivh logstash-2.3.4-1.noarch.rpm
Logstash 依赖 java 环境，需要安装 java-1.8.0-openjdk

安装之后，创建第一个测试的配置文件
/etc/Logstash/logstash.conf
input{ stdin{} } 
filter{  }
output{ stdout{} }

使用 logstash -f logstash.conf 启动，如果输入数据能看到返回证明 logstash 安装正确

logstash 数据处理结构
                        |-------------------------logstash---------------------|
｛数据源｝ -->{ input{数据接收}-- filter{数据处理} -- output{数据发送}  } --> {ES集群}
                        |-------------------------logstash---------------------|


布尔值类型:  ssl_enable => true
字节类型:     bytes => "1MiB"
字符串类型:  name => "xkops"
数值类型:     port => 22
数组:            match => ["datetime","UNIX"]
哈希:            options => {key1 => "value1",key2 => "value2"}
编码解码:     codec => "json"
路径:            file_path => "/tmp/filename"
注释:       #

条件判断：
等于:       ==
不等于:     !=
小于:       <
大于:       >
小于等于:   <=
大于等于:   >=
匹配正则:   =~
不匹配正则: !~
包含:        in
不包含:     not in 
与:	and
或:	or
非与:          nand
非或:	xor
复合表达式: ()
取反符合:   !()

logstash-file 插件: 从文件读取，在屏幕输出
file插件字段解释：
codec =>  #可选项，默认是plain，可设置其他编码方式。
discover_interval => #可选项，logstash多久检查一下path下有新文件，默认15s。
exclude => #可选项，排除path下不想监听的文件。
sincedb_path => #可选项，记录文件以及文件读取信息位置的数据文件。~/.sincedb_xxxx
sincedb_write_interval => #可选项，logstash多久写一次sincedb文件，默认15s.
stat_interval => #可选项，logstash多久检查一次被监听文件的变化，默认1s。
start_position => #可选项，logstash从哪个位置读取文件数据，默认从尾部，值为：end。初次导入，设置为：beginning。
path => #必选项，配置文件路径，可定义多个。
tags => #可选项，在数据处理过程中，由具体的插件来添加或者删除的标记。
type => #可选项，自定义处理时间类型。比如nginxlog。

input{
    file{
        start_position => "beginning"
        sincedb_path => "/var/lib/logstash/sincedb-access"
        path => ["/tmp/blog","/tmp/alog"]
        type => 'filelog'
    }
}

filter{  }
output{ stdout{} }

logstash-tcp 插件：从网络读取，在屏幕输出
tcp插件字段解释：
add_field => #可选项，默认{}。
codec => #可选项，默认plain。
data_timeout => #可选项，默认-1。
host => #可选项，默认0.0.0.0。
mode => #可选项，值为["server","client"]之一，默认为server。
port => #必选，端口。
ssl_cacert => #可选项，定义相关路径。
ssl_cert => #可选项，定义相关路径。
ssl_enable => #可选项，默认为false。
ssl_key => #可选项，定义相关路径。
ssl_key_passphrase => #可选项，默认nil
ssl_verify => #可选项，默认false。
tags => #可选项
type => #可选项
input{
    tcp{
        host => "0.0.0.0"
        port => 8888
        type => "tcplog"
    }
}
filter{  }
output{ stdout{} }

在服务器上启动 logstash , 在客户机上使用 shell 脚本测试
function tcpmsg() {
    exec 9<>/dev/tcp/192.168.4.10/8888
    echo -ne "${1}\r\n" >&9
    exec 9<&-
}

logstash-udp插件：
udp插件字段解释：
add_field => #可选项，默认{}。
host => #可选项，默认0.0.0.0。
queue_size => #默认2000
tags => #可选项
type => #可选项
workers => #默认为2

input{
    udp{
        host => "192.168.4.10"
        port => 9999
    }
}
filter{  }
output{ stdout{} }

在服务器上启动 logstash , 在客户机上使用 shell 脚本测试
function udpmsg() {
    exec 9<>/dev/udp/192.168.4.10/9999
    echo -ne "${1}\r" >&9
    exec 9<&-
}

logstash-syslog 插件：

input{
    syslog{
        host => "192.168.4.10"
        port => 514
        type => "syslog"
    }
}
filter{  }
output{ stdout{} }

在服务器启动 logstash，在客户机修改 /etc/rsyslog.conf 配置问件，添加
*.*	@@192.168.4.10:514
重新启动 rsyslog 服务
systemctl restart rsyslog
使用明令写入 syslog 进行测试
logger -p local0.info -t test_logstash 'test message'
输入命令以后可以在 /var/log/messages 看到，在 logstash 服务器端也同时能看到输出

codec类插件
常用的插件：plain、json、json_lines、rubydebug、multiline等

input{
    file{
        start_position => "beginning"
        sincedb_path => "/dev/null"
        path => ["/tmp/alog"]
        type => 'filelog'
        codec => "json"
    }
}
output{
    stdout{ codec => "rubydebug" }
}

利用 rubydebug 方便调试，如果输入在文件是 json 在 input 指定编码格式

filter grok插件：解析各种非结构化的日志数据插件
grok有丰富的patterns,查看方式
/opt/logstash/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-2.0.5/patterns/grok-patterns

filter{
    grok{
        match => ["message","%{IP:ip} %{WORD:method} %{URIPATH:uri} %{NUMBER:bytes} %{NUMBER:duration}"]
    }
}

grok 使用正则表达式把飞结构化的数据结构化在分组匹配，正则表达式需要根据具体数据结构编写，虽然编写困难，但适用性极广，几乎可以应用于各类数据

最后是一个完整的 Logstash 的配置文件，使用Logstash 收集数据，格式化以后放入 ES 集群
input{
    file{
        start_position => "beginning"
        sincedb_path => "/dev/null"
        path => ["/tmp/alog"]
        type => 'filelog'
        codec => "json"
    }
}

filter{
}
output{ 
    if [type] == "filelog"{
    elasticsearch {
        hosts => ["192.168.4.15:9200"]
        index => "weblog"
        flush_size => 2000
        idle_flush_time => 10
    }}
}

放入集群以后的数据可以通过 kibana 展示
在生产环境中，我们往往还需要配置 redis 用来缓存 或 filebeat 用来收集日志，这里给出简单的配置样例，需要更深入学习的同学请查看官方文档

https://github.com/logstash-plugins

redis 配置
input{
    redis{
    host => 'redis-server'
    port => '6379'
    data_type => 'list'
    key => 'lb'
    codec => 'json'
    }
}
filebeat-1.2.3-x86_64.rpm 
filebeat 配置
input {
    beats {
        port => 5044
        codec => "json"
    }
}

filebeat 客户端相关配置文件
filebeat:
  prospectors:
    -
      paths:
        - /root/logs.jsonl
      document_type: logstash
    - 
      paths:
        - /root/shakespeare.json
      document_type: shakespeare
    - 
      paths:
        - /root/accounts.json
      document_type: account
    
  registry_file: /var/lib/filebeat/registry
output:
  logstash:
    hosts: ["192.168.4.10:5044"]
shipper:
logging:
  files:

/**************************************

logstash和Elasticsearch是用Java写的，
kibana使用node.js框架。


[root@Va1 ~]# systemctl is-active  elasticsearch
active

[root@Va1 ~]# egrep   -nv  "^#|^$"   /etc/elasticsearch/elasticsearch.yml
17:cluster.name: elk-cluster  # 设置集群名称{elasticsearch服务器识别集群的唯一方式}
23:node.name: Va1
51:network.bind_host: 192.168.0.11
53:network.publish_host: 192.168.0.11
54:network.host: 192.168.0.11
55:transport.tcp.port: 9300
58:http.port: 9200
68:discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

[root@Va1 ~]# netstat   -nplut |grep  java
tcp6       0      0 192.168.0.11:9200       :::*      LISTEN      1114/java
tcp6       0      0 192.168.0.11:9300       :::*      LISTEN      1114/java

[root@Va1 ~]# yum  -y  install  kibana
已安装:
  kibana.x86_64 0:4.5.2-1                                                              

完毕！
[root@Va1 ~]# rpm   -q  kibana
kibana-4.5.2-1.x86_64

[root@Va1 ~]# rpm  -ql  kibana  |head  -5
/etc/default/kibana
/etc/init.d/kibana
/lib/systemd/system/kibana.service
/opt/kibana/LICENSE.txt
/opt/kibana/README.txt


[root@Va1 ~]# cd /opt/kibana/config/ ;ls
kibana.yml

dashboard
英 [ˈdæʃbɔ:d]   美 [ˈdæʃbɔ:rd]  
n. 仪表板;仪表盘;仪表的控制盘;挡泥板

[root@Va1 config]# vim kibana.yml  #配置 kibana 

  2 server.port: 5601  # 默认值 : 5601 Kibana 由后端服务器提供服务。此设置指定要使用的端口。
  3 
  4 # The host to bind the server to.
  5 server.host: "0.0.0.0"   #默认值 : “localhost”此设置指定后端服务器的主机。

 15 elasticsearch.url: "http://Va1:9200"    #要用于所有查询的 Elasticsearch 实例的 URL。

#  Kibana 使用 Elasticsearch 中的索引来存储保存的搜索，可视化和仪表板。
             # 如果索引不存在，Kibana 将创建一个新索引。
 23 kibana.index: ".kibana"
                                  #打开kibana页面时，默认打开的页面discover
  # 实际上有 4 个首页主项 页面 
    Discover  Visualize  Dashboard  Settings
       发现          可视化        仪表板      设置
 26 kibana.defaultAppId: "discover"  # 要加载的默认应用程序是“discover”

# elasticsearch.requestTimeout 设置以毫秒为单位的时间等待 Elasticsearch 对 PING 作出响应。
 53 elasticsearch.pingTimeout: 1500   # ping检测超时时间

# 等待来自后端或 Elasticsearch 的响应的时间（以毫秒为单位）。此值必须为正整数。
 57 elasticsearch.requestTimeout: 30000  # 请求超时

#重试前在 Kibana 启动时等待 Elasticsearch 的时间（以毫秒为单位）。
 64 elasticsearch.startupTimeout: 5000  #启动超时

Kibana 配置文件 kibana.yaml 文件详解
https://blog.csdn.net/heatdeath/article/details/79531297
------------------------------------------------------------------------------------------

[root@Va1 config]# egrep -vn '^(#|$)'  kibana.yml
2:server.port: 5601
5:server.host: "0.0.0.0"  //服务器监听地址 0.0.0.0可以代表本机或其他任意主机地址
15:elasticsearch.url: "http://Va1:9200" # 声明地址，从哪里查，集群里面随便选一个
23:kibana.index: ".kibana"
26:kibana.defaultAppId: "discover"
53:elasticsearch.pingTimeout: 1500
57:elasticsearch.requestTimeout: 30000
64:elasticsearch.startupTimeout: 5000

[root@Va1 config]# systemctl  start  kibana  && systemctl  enable  kibana  # 开机自启动

[root@Va1 config]# netstat   -npult |grep 5601  # 查看 kibana 监听端口
tcp    0      0 0.0.0.0:5601       0.0.0.0:*       LISTEN      4907/node  

http://192.168.0.11:5601  在浏览器中打开 kibana 服务平台
http://192.168.0.11:5601/app/kibana#/settings/indices/?_g=(refreshInterval:(display:Off,pause:!f,value:0),time:(from:now-15m,mode:quick,to:now))

http://192.168.0.11:5601/status  ## 检查运行状态(绿色正常)
Status: Green 






[root@Va2 ~]# cat  /etc/httpd/logs/access_log
127.0.0.1 - - [13/Jan/2019:17:42:41 +0800] "GET / HTTP/1.1" 200 43 "-" "ELinks/0.12pre6 (textmode; Linux; -)"
127.0.0.1 - - [13/Jan/2019:17:45:00 +0800] "GET / HTTP/1.1" 200 67 "-" "ELinks/0.12pre6 (textmode; Linux; -)"

()  ()  ()  \1   \2   \3  分组匹配 组名函数名


25[0-5]|2[0-4]\d|1?\d?\d

?\d
?\d  匹配零个或一个 十进制数字字符  ## 注意 . 点和 ? 问号的区别
.\d  匹配 一个  十进制数字字符

精确匹配ip地址
((25[0-5]|2[0-4]\d|1?\d?\d)\.){3}(25[0-5]|2[0-4]\d|1?\d?\d)

模糊匹配ip地址
([12]?\d?\d\.){3}[12]?\d?\d
模糊匹配ip地址
([12](?\d){2}\.){3}[12](?\d){2}
模糊匹配ip地址
[0-9.]+

(?<ip>[0-9]+).*[(?<time>.+)\]  [A-Z]+


重定向stdin 0  stdout 1 stderr 2
内核启动的时候默认打开这三个I/O设备文件：
标准输入文件stdin，得到文件描述符 0
标准输出文件stdout，得到文件描述符 1
标准错误输出文件stderr，得到文件描述符 2。

Linux重定向操作符 功能描述
> 将命令输出写入文件或设备，而不是命令提示符或句柄
< 从文件而不是从键盘或句柄读入命令输入
>> 将命令输出添加到文件末尾而不删除文件中已有的信息
>& 将一个句柄的输出写入到另一个句柄的输入中

<& 从一个句柄读取输入并将其写入到另一个句柄输出中

| 从一个命令中读取输出并将其写入另一个命令的输入中;也称为管道操作符

使用"2>&1" 把标准错误stderr重定向到标准输出stdout；
2、使用"&>"把标准正确和错误stderr重定向到标准输出stdout；


一个文件描述符 是文件系统为了跟踪这个打开的文件而分配给它的一个数字. 
也可以的将其理解为文件指针的一个简单版本. 与C语言中文件句柄的概念很相似.

关闭文件描述符

&- 关闭标准输出
n&- 表示将 n 号输出关闭

n<&-
关闭输入文件描述符 n.
0<&-, <&-
关闭 stdin.
n>&-
关闭输出文件描述符 n.
1>&-, >&-
关闭 stdout.

2>&1 也就是 FD2＝FD1 ，
这里并不是说FD2 的值等于FD1的值，
因为 > 是改变送出的数据信道，
也就是说把 FD2 的 “数据输出通道” 改为 FD1 的 “数据输出通道”

linux exec与重定向
exec和source都属于bash内部命令（builtins commands），
在bash下输入man exec
或man source可以查看所有的内部命令信息。
source命令，不再产生新的shell，而在当前shell下执行一切命令

exec
在bash下输入man exec，找到exec命令解释处，可以看到
”No new process is created.”这样的解释，
这就是说exec命令不产生新的子进程。

如恢复重定向或关闭的 stdout： exec 1>&2 ，恢复重定向或关闭的stderr：exec 2>&1。

如果stdout和stderr全部都关闭了，又没有保存原来的FD，可以用：exec 1>/dev/tty 恢复。

[root@room9pc01 ~]# ls  /dev/tty  -l
crw-rw-rw- 1 root tty 5, 0 1月  20 09:09 /dev/tty

cmd >a 2>a 和 cmd >a 2>&1 为什么不同？
cmd >a 2>a ：stdout和stderr都直接送往文件 a ，a文件会被打开两遍，
由此导致stdout和stderr互相覆盖。

cmd >a 2>&1 ：stdout直接送往文件a ，stderr是继承了FD1的管道之后，再被送往文件a 。
a文件只被打开一遍，就是FD1将其打开。

不同点在于：
cmd >a 2>a 相当于使用了两个互相竞争使用文件a的管道；
而cmd >a 2>&1 只使用了一个管道，但在其源头已经包括了stdout和stderr。

从IO效率上来讲，cmd >a 2>&1的效率应该更高！

-----------------------------------------------

exec 6>&1     # 将fd #6与stdout链接起来.
          # 保存stdout.

exec > $LOGFILE     # stdout就被文件"logfile.txt"所代替了.

exec 1>1.txt       # stdout重定向至1.txt
exec >filename命令将会把stdout重定向到一个指定的文件中. 
这样所有命令的输出就都会发送到那个指定的文件, 而不是stdout.

exec 1>&6 6>&-      # 恢复stdout, 然后关闭文件描述符#6.
                     # 关闭 FD6
n>&-
关闭输出文件描述符 n.
-------------------------------------------------------
exec 6<&0          # 将文件描述符#6与stdin链接起来.
            # 保存stdin.

exec < data-file  
# stdin被文件"data-file"所代替.

exec 0<&6  6<&-
#  现在将stdin从fd #6中恢复, 因为刚才我们把stdin重定向到#6了,
#+ 然后关闭fd #6 ( 6<&- ), 好让这个描述符继续被其他进程所使用.
n<&-
关闭输入文件描述符 n.
# <&6 6<&-    这么做也可以.
--------------------------------

2>&1  # 重定向stderr到stdout.
  # 将错误消息的输出, 发送到与标准输出所指向的地方.

i>&j   # 重定向文件描述符i到j.
   # 指向i文件的所有输出都发送到j.

>&j   # 默认的, 重定向文件描述符1(stdout)到j.
     # 所有传递到stdout的输出都送到j中去.

0< FILENAME
 < FILENAME  # 从文件中接受输入.
   # 与">"是成对命令, 并且通常都是结合使用.
   # grep search-word <filename
[root@Va2 ~]# cat  new2.txt 
haha55
Hixixi
[root@Va2 ~]# grep xix  < new2.txt
Hixixi
[root@Va2 ~]# 

[j]<>filename
  # 为了读写"filename", 把文件"filename"打开, 并且将文件描述符"j"分配给它.
  # 如果文件"filename"不存在, 那么就创建它.
  # 如果文件描述符"j"没指定, 那默认是fd 0, stdin.
   # 这种应用通常是为了写到一个文件中指定的地方.
[root@Va2 ~]# cat   wenjian.txt 
a1#a2#a3
b1#b2#b3
c1#c2#c3
[root@Va2 ~]# exec  6<> wenjian.txt  # 打开"File"并且将fd 6分配给wenjian.txt

[root@Va2 ~]# read  -n  5  <&6   # 只读取5个字符.

[root@Va2 ~]# echo  addabc123 >&6  #写入数据
[root@Va2 ~]# cat   wenjian.txt 
a1#a2addabc123
b3
c1#c2#c3
[root@Va2 ~]# exec  6>&-   # 关闭fd 6
n>&-  # 关闭输出文件描述符 n

n<&-  #关闭输入文件描述符n.

[root@Va2 ~]# echo  -e "\nd1#d2#d3#d4" >>  wenjian.txt

[root@Va2 ~]# cat   wenjian.txt 
a1#a2addabc123
b3
c1#c2#c3

d1#d2#d3#d4
[root@Va2 ~]# 





[root@Va6 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1905         125        1554           8         225        1546
Swap:          2047           0        2047
[root@Va6 ~]# cat  /etc/yum.repos.d/local.repo 
[CentOS7-1708]
name=CentOS7-1708
gpgcheck=0
baseurl=ftp://192.168.0.254/CentOS7-1708/
enabled=1

[ansible]
name=ansible
baseurl=ftp://192.168.0.254/ansible
gpgcheck=0
enabled=1

安装Logstash
rpm -ivh logstash-2.3.4-1.noarch.rpm
Logstash 依赖 java 环境，需要安装 java-1.8.0-openjdk


[root@Va6 ~]# yum list |grep logstash
logstash.noarch                          1:2.3.4-1                 ansible  
    
[root@Va6 ~]# yum search  logstash
...........................
============================= N/S matched: logstash =============================
filebeat.x86_64 : Sends log files to Logstash or directly to Elasticsearch.
logstash.noarch : An extensible logging pipeline

  名称和简介匹配 only，使用“search all”试试。

[root@Va6 ~]# yum  -y  install  java-1.8.0-openjdk  |tail  -2
软件包 1:java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64 已安装并且是最新版本
无须任何处理

[root@Va6 ~]# yum  -y  install  logstash.noarch  |tail  -3
  logstash.noarch 1:2.3.4-1                                                     

完毕！
[root@Va6 ~]# rpm  -qa |grep logstash
logstash-2.3.4-1.noarch


[root@Va6 ~]# ls  /etc/logstash/
conf.d
[root@Va6 ~]# ls  /etc/logstash/conf.d/
[root@Va6 ~]# touch   /etc/logstash/logstash.conf ##手动创建配置文件
[root@Va6 ~]# ls  /etc/logstash/
conf.d  logstash.conf

[root@Va6 ~]# rpm  -ql  logstash  |wc -l
10663
[root@Va6 ~]# rpm  -ql  logstash |head   -5
/etc/init.d/logstash
/etc/logrotate.d/logstash
/etc/logstash/conf.d
/etc/sysconfig/logstash
/opt/logstash/CHANGELOG.md

[root@Va6 ~]# ls  /opt/logstash/
bin           CONTRIBUTORS  Gemfile.jruby-1.9.lock  LICENSE     vendor
CHANGELOG.md  Gemfile       lib                     NOTICE.TXT

[root@Va6 ~]# ls  /opt/logstash/bin/
logstash      logstash.lib.sh  logstash-plugin.bat  plugin.bat  rspec.bat
logstash.bat  logstash-plugin  plugin               rspec       setup.bat

[root@Va6 ~]# ll  /opt/logstash/bin/logstash
-rwxrwxr-x 1 logstash logstash 1854 7月   7 2016 /opt/logstash/bin/logstash

[root@Va6 ~]# cd  /opt/logstash/bin/
###[root@Va6 bin]# ./logstash
/**************
[root@room9pc01 ~]# tail  -3  /etc/bashrc
# vim:ts=4:sw=4
/usr/sbin/ifconfig rhce:0 172.25.0.250
echo Taren1 | passwd --stdin root &> /dev/null

*************/

[root@Va6 ~]# vim  /etc/bashrc 
[root@Va6 ~]# tail  -3  /etc/bashrc
fi
# vim:ts=4:sw=4
PATH=${PATH}:/opt/logstash/bin/

[root@Va6 ~]# vim  /etc/profile
[root@Va6 ~]# tail  -2 /etc/profile
unset -f pathmunge
PATH=/opt/logstash/bin/:$PATH

[root@Va6 ~]# ls .bash
.bash_history  .bash_logout   .bash_profile  .bashrc        
[root@Va6 ~]# ls .bashrc 
.bashrc
[root@Va6 ~]# ll  .bash_history  #shell 命令的日志
-rw-------. 1 root root 4946 1月  17 21:43 .bash_history
初始化时读取bashrc,
bashrc 是专门用来给 bash 做初始化的
比如用来初始化 bash 的设置,
 bash 的代码补全, bash 的别名, bash 的颜色.
非交互式只会读取bashrc。
一般把alias和function一类的放到bashrc或~/.bashrc中。

交互式shell登录时读取profile
首先读入的是全局环境变量设定档/etc/profile
profile 是用户唯一的用来设置环境变量的地方,针对全局设置
把export更多的放在profile文件中。

最后再根据用户帐号读取~/.bashrc , bashrc 针对某个用户 设置

[root@Va6 ~]# ll  /opt/logstash/bin/logstash
-rwxrwxr-x 1 logstash logstash 1854 7月   7 2016 /opt/logstash/bin/logstash
[root@Va6 ~]# tail  -3  /etc/bashrc
fi
# vim:ts=4:sw=4
PATH=${PATH}:/opt/logstash/bin/

[root@Va6 ~]# which  logstash
/usr/bin/which: no logstash in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
[root@Va6 ~]# .  /etc/bashrc 
[root@Va6 ~]# which  logstash
/opt/logstash/bin/logstash

[root@Va6 ~]# ls /opt/logstash/
bin           CONTRIBUTORS  Gemfile.jruby-1.9.lock  LICENSE     vendor
CHANGELOG.md  Gemfile       lib                     NOTICE.TXT

[root@Va6 ~]# ls  /opt/logstash/bin/
logstash      logstash.lib.sh  logstash-plugin.bat  plugin.bat  rspec.bat
logstash.bat  logstash-plugin  plugin               rspec       setup.bat

[root@Va6 ~]# ll  /opt/logstash/bin/logstash-plugin #插件管理文件
-rwxrwxr-x 1 logstash logstash 439 7月   7 2016 /opt/logstash/bin/logstash-plugin

[root@Va6 ~]# /opt/logstash/bin/logstash-plugin   -h

Ignoring ffi-1.9.13 because its extensions are not built.  Try: gem pristine ffi --version 1.9.13
Usage:
    bin/logstash-plugin [OPTIONS] SUBCOMMAND [ARG] ...

Parameters:
    SUBCOMMAND                    subcommand
    [ARG] ...                     subcommand arguments

Subcommands:
    install        安装      Install a plugin
    uninstall      卸载      Uninstall a plugin
    update                        Update a plugin
    pack     包安装 插件       Package currently installed plugins
    unpack   解包 包卸载 插件  Unpack packaged plugins
    list                          List all installed plugins

Options:
    -h, --help                    print help

[root@Va6 ~]# /opt/logstash/bin/logstash-plugin   list  |grep  http
Ignoring ffi-1.9.13 because its extensions are not built.  Try: gem pristine ffi --version 1.9.13
logstash-input-http
logstash-input-http_poller
logstash-output-http
[root@Va6 ~]# /opt/logstash/bin/logstash-plugin   list  |grep  stdin
............
logstash-input-stdin
[root@Va6 ~]# /opt/logstash/bin/logstash-plugin   list  |grep  stdout
..............
logstash-output-stdout
[root@Va6 ~]# /opt/logstash/bin/logstash-plugin   list  |grep  filter
................
logstash-filter-anonymize
logstash-filter-checksum
logstash-filter-clone
logstash-filter-csv
logstash-filter-date
logstash-filter-dns
logstash-filter-drop
logstash-filter-fingerprint
logstash-filter-geoip
logstash-filter-grok
logstash-filter-json
logstash-filter-kv
logstash-filter-metrics
logstash-filter-multiline
logstash-filter-mutate
logstash-filter-ruby
logstash-filter-sleep
logstash-filter-split
logstash-filter-syslog_pri
logstash-filter-throttle
logstash-filter-urldecode
logstash-filter-useragent
logstash-filter-uuid
logstash-filter-xml

[root@Va6 ~]# logstash
logstash         logstash.lib.sh  logstash-plugin  

[root@Va6 ~]# logstash-plugin   list  |grep codec  ## codec类 编码解码 插件

Ignoring ffi-1.9.13 because its extensions are not built.  Try: gem pristine ffi --version 1.9.13
logstash-codec-collectd
logstash-codec-dots
logstash-codec-edn
logstash-codec-edn_lines
logstash-codec-es_bulk
logstash-codec-fluent
logstash-codec-graphite

logstash-codec-json
logstash-codec-json_lines

logstash-codec-line
logstash-codec-msgpack
logstash-codec-multiline
logstash-codec-netflow
logstash-codec-oldlogstashjson

logstash-codec-plain  默认plain
logstash-codec-rubydebug

[root@Va6 ~]# 


codec类插件
常用的插件：plain、json、json_lines、rubydebug、multiline等

tcp插件字段解释：
add_field => #可选项，默认{}。
codec => #可选项，默认plain。

编码解码:     codec => "json"

file插件字段解释：
codec =>  #可选项，默认是plain，可设置其他编码方式。



[root@Va6 ~]# ls /etc/logstash/
conf.d  logstash.conf

使用 logstash -f logstash.conf 启动，如果输入数据能看到返回证明 logstash 安装正确

logstash 数据处理结构
                        |-------------------------logstash---------------------|
｛数据源｝ -->{ input{数据接收}-- filter{数据处理} -- output{数据发送}  } --> {ES集群}
                        |-------------------------logstash---------------------|

[root@Va6 ~]# vim  /etc/logstash/logstash.conf 
[root@Va6 ~]# cat  /etc/logstash/logstash.conf
input {
  stdin{}
}

filter{}

output{
  stdout{}
}
[root@Va6 ~]# logstash  --help  |grep  -2  "\-f, --config"

Options:
    -f, --config CONFIG_PATH      Load the logstash config from a specific file
                                  or directory.  If a directory is given, all
                                  files in that directory will be concatenated
[root@Va6 ~]# cat  #注意命令cat 的输入输出
echo 123abc
echo 123abc
echo haha
echo haha

^C
[root@Va6 ~]# logstash  -f  /etc/logstash/logstash.conf
Settings: Default pipeline workers: 2
Pipeline main started
echo  abc123          #注意输入      
2019-01-20T04:40:58.448Z Va6 echo  abc123  # 注意"echo  abc123" 输出
byebye boy   #注意输入  
2019-01-20T04:41:48.359Z Va6 byebye boy   #注意byebye boy输出 
^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}
Received shutdown signal, but pipeline is still waiting for in-flight events
to be processed. Sending another ^C will force quit Logstash, but this may cause
data loss. {:level=>:warn}    #敲回车 确认退出 管道
 收到停机信号，但管道仍在等待飞行中的事件
待处理。发送另一个^C将强制退出logstash，但这可能导致
数据丢失。{:level＝>：警告}
Pipeline main has been shutdown

[root@Va6 ~]# 
pipeline    n. 管道;输油管道;渠道，传递途径
vt. （通过管道）运输，传递;为…安装管道

使用 logstash -f logstash.conf 启动，如果输入数据能看到返回证明 logstash 安装正确
logstash 数据处理结构
                        |-------------------------logstash---------------------|
｛数据源｝ -->{ input{数据接收}-- filter{数据处理} -- output{数据发送}  } --> {ES集群}
                        |-------------------------logstash---------------------|
/****************
[j]<>filename
  # 为了读写"filename", 把文件"filename"打开, 并且将文件描述符"j"分配给它.
  # 如果文件"filename"不存在, 那么就创建它.
  # 如果文件描述符"j"没指定, 那默认是fd 0, stdin.
   # 这种应用通常是为了写到一个文件中指定的地方.
[root@Va2 ~]# cat   wenjian.txt 
a1#a2#a3
b1#b2#b3
c1#c2#c3
[root@Va2 ~]# exec  6<> wenjian.txt  # 打开"File"并且将fd 6分配给wenjian.txt
[root@Va2 ~]# read  -n  5  <&6   # 只读取5个字符.
[root@Va2 ~]# echo  addabc123 >&6  #写入数据
[root@Va2 ~]# cat   wenjian.txt 
a1#a2addabc123
b3
c1#c2#c3
[root@Va2 ~]# exec  6>&-   # 关闭fd 6
n>&-  # 关闭输出文件描述符 n
n<&-  #关闭输入文件描述符n.
**********************/

[root@Va6 ~]# man bash  |egrep -A3  "\/dev\/(tcp|udp)"
              /dev/tcp/host/port
                     如果 host 是一个合法的主机名或 Internet  地址，并且  port
                     是  一个整数端口号或服务名，bash  试图建立与相应的 socket
                     (套接字) 的 TCP 连接。
              /dev/udp/host/port
                     如果 host 是一个合法的主机名或 Internet  地址，并且  port
                     是  一个整数端口号或服务名，bash  试图建立与相应的 socket
                     (套接字) 的 UDP 连接。

https://github.com/logstash-plugins  #打开官网文档
logstash-output-http

https://github.com/logstash-plugins/logstash-output-http
README.md

https://github.com/logstash-plugins/logstash-output-http/blob/master/README.md

Documentation

Logstash provides infrastructure to automatically generate documentation for this plugin. We use the asciidoc format to write documentation so any comments in the source code will be first converted into asciidoc and then into html. All plugin documentation are placed under one  [ central location ]点击链接 .

For formatting code or config example, you can use the asciidoc [source,ruby] directive
For more asciidoc formatting tips, see the excellent reference here https://github.com/elastic/docs#asciidoc-guide

https://www.elastic.co/guide/en/logstash/current/index.html #网页加载较慢
                                        翻译中文
Logstash Reference              Logstash参考
Logstash Reference:             Logstash参考:
Logstash Introduction           Logstash简介
Getting Started with Logstash   Logstash入门
How Logstash Works              Logstash的工作原理
Setting Up and Running Logstash   设置和运行Logstash
Upgrading Logstash                升级Logstash
Configuring Logstash              配置Logstash
Managing Logstash                 管理Logstash
Working with Logstash Modules     使用Logstash模块
Working with Filebeat Modules     使用Filebeat模块
Data Resiliency         数据弹性
Transforming Data       转换数据
Deploying and Scaling Logstash   部署和扩展Logstash
Performance Tuning      性能调优
Monitoring Logstash     监控Logstash
Monitoring APIs         监控API
Working with plugins    使用插件

Input plugins           输入插件
Output plugins          输出插件
Filter plugins          过滤插件
Codec plugins           编解码器插件

Contributing to Logstash   贡献于Logstash
Glossary of Terms          专业术语
Breaking Changes           突破性变化
Release Notes              发行说明

点击 Input plugins   输入插件
https://www.elastic.co/guide/en/logstash/current/input-plugins.html

[exec]
Captures the output of a shell command as an event
[logstash-input-exec]

[file]点击链接
Streams events from files
[logstash-input-file]

https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html
File input pluginedit
Plugin version: v4.1.8
Released on: 2018-11-27
Changelog
.......
File Input Configuration Optionsedit
This plugin supports the following configuration options plus the Common Options described later.
...........
键名(固定的不能修改)    键的值的类型                   键值(可以选择修改,是否必须要配置)
Setting	       Input type	              Required
close_older        number or string_duration   No
delimiter          string                      No
discover_interval  number                      No
exclude            array                       No
...................
path               array                       Yes


codec
..................
enable_metric
...........
id
Value type is string
...........

input {
  file {    #file插件 格式
    id => "my_plugin_id"
  }
}
tags
Value type is array
There is no default value for this setting.
...............











codec类插件(默认plain)
常用的插件：plain、json、json_lines、rubydebug、multiline等
编码解码:     codec => "json"
[root@Va6 ~]# vim   /etc/logstash/logstash.conf 
[root@Va6 ~]# cat  /etc/logstash/logstash.conf
input {
  stdin{ codec => "json" }  #改为 json插件
}

filter{}

output{
  stdout{}
}
[root@Va6 ~]# logstash  -f  /etc/logstash/logstash.conf
Settings: Default pipeline workers: 2
Pipeline main started
{ "key1":1, "key2":"b2", "c":3  }   #输入json格式的数据
2019-01-20T05:55:29.508Z Va6 %{message}  # 出现 %{message}证明 json格式数据被识别了
{"a":1, "b":2, "c":3}
2019-01-20T05:56:41.238Z Va6 %{message}
^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}

Pipeline main has been shutdown

[root@Va6 ~]# vim    /etc/logstash/logstash.conf
[root@Va6 ~]# cat   /etc/logstash/logstash.conf
input {
  stdin{ codec => "json" }
}

filter{}

output{
  stdout{ codec => "json" }
}
[root@Va6 ~]# logstash  -f  /etc/logstash/logstash.conf
Settings: Default pipeline workers: 2
Pipeline main started
{ "key1":1, "key2":"b2", "c":3  }   #输入json格式的数据 ; 
                                              #输出结果是一行,如果要使得输出结果是多行格式,可以使用插件rubydebug
{"key1":1,"key2":"b2","c":3,"@version":"1","@timestamp":"2019-01-20T06:00:52.962Z","host":"Va6"}

abcluanxie        ##输入 非 json格式的数据
{"message":"abcluanxie","tags":["_jsonparsefailure"],"@version":"1","@timestamp":"2019-01-20T06:01:33.020Z","host":"Va6"}

^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}

Pipeline main has been shutdown
[root@Va6 ~]# 
codec类插件(默认plain)
常用的插件：plain、json、json_lines、rubydebug、multiline等
编码解码:     codec => "rubydebug"

ruby debug 红宝石调试
ruby  n. 红宝石，红玉;红宝石色，深红色;<英>细铅字;红葡萄酒
adj. 红宝石的;红宝石色的
vt. 使带红宝石色;把…弄红;把…涂染成红色
debug     英 [ˌdi:ˈbʌg]   美 [diˈbʌɡ]  
vt. 拆除窃听器;排除故障


[root@Va6 ~]# vim    /etc/logstash/logstash.conf #输出结果是多行格式,使用插件rubydebug

[root@Va6 ~]# cat   /etc/logstash/logstash.conf
input {
  stdin{ codec => "json" }  # 使用插件json编码
}

filter{}

output{          # 使用插件rubydebug 解码
  stdout{ codec => "rubydebug" }
}
[root@Va6 ~]# logstash  -f  /etc/logstash/logstash.conf
Settings: Default pipeline workers: 2
Pipeline main started
{ "key1":1, "key2":"b2", "c":3  }
{
          "key1" => 1,
          "key2" => "b2",
             "c" => 3,
      "@version" => "1",
    "@timestamp" => "2019-01-20T06:15:37.789Z",
          "host" => "Va6"
}

abcluanxie           # 输入格式不满足json格式条件
{
       "message" => "abcluanxie",
          "tags" => [
        [0] "_jsonparsefailure"  #报错无法解码
    ],
      "@version" => "1",
    "@timestamp" => "2019-01-20T06:16:05.558Z",
          "host" => "Va6"
}

^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}

Pipeline main has been shutdown

[root@Va6 ~]# 
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-path

键名(固定的不能修改)    键的值的类型                   键值(可以选择修改,是否必须要配置)
Setting	       Input type	              Required
close_older        number or string_duration   No
delimiter          string                      No
discover_interval  number                      No
exclude            array                       No
...................
[path]点击关键词      [array]                       Yes
..............
path
This is a required setting.
Value type is array
There is no default value for this setting.
The path(s) to the file(s) to use as an input. You can use filename patterns here, such as /var/log/*.log. If you use a pattern like /var/log/**/*.log, a recursive search of /var/log will be done for all *.log files. Paths must be absolute and cannot be relative.
此设置没有默认值。
用作输入的文件的路径。您可以在这里使用文件名模式，例如/var/log/*.log。
如果使用类似/var/log/**/*.log的模式，将对所有*.log文件进行/var/log的递归搜索。
路径必须是绝对路径，不能是相对路径。
You may also configure multiple paths. See an example on the Logstash configuration page.
您还可以配置多个路径。请参阅logstash配置页上的示例。

input {
  file {    #file插件 格式
    id => "my_plugin_id"
  }
}
[root@Va6 ~]# vim    /etc/logstash/logstash.conf
[root@Va6 ~]# cat  /etc/logstash/logstash.conf
input {
  file {
      path => ["/tmp/a.log","/var/tmp/b.log"]
  }
}

filter{}

output{
  stdout{ codec => "rubydebug" }
}
[root@Va6 ~]# touch  /tmp/a.log   /var/tmp/b.log
[root@Va6 ~]# ll   /tmp/a.log   /var/tmp/b.log
-rw-r--r-- 1 root root 0 1月  20 15:00 /tmp/a.log
-rw-r--r-- 1 root root 0 1月  20 15:00 /var/tmp/b.log

[root@Va6 ~]# logstash  -f  /etc/logstash/logstash.conf
Settings: Default pipeline workers: 2
Pipeline main started


-------------------------------------- 在 另一个 终端 进入Va6  测试 -------------
[root@room9pc01 ~]# ssh  -X 192.168.0.16
root@192.168.0.16's password: 
Last login: Sun Jan 20 09:08:54 2019 from 192.168.0.254
[root@Va6 ~]#  ll   /tmp/a.log   /var/tmp/b.log
-rw-r--r-- 1 root root 0 1月  20 15:00 /tmp/a.log
-rw-r--r-- 1 root root 0 1月  20 15:00 /var/tmp/b.log
[root@Va6 ~]# echo  ${RANDOM}
13894
[root@Va6 ~]# echo  BB_${RANDOM} >> /var/tmp/b.log
[root@Va6 ~]# echo  A_${RANDOM} >> /tmp/a.log 

------- 再回到原先的终端,发现新加了监控结果[ 注意logstash 只监控新添加的数据,
      会记录原有读取数据的旧位置,主要由 sincedb_path => 指向的指针文件 决定,
    默认sincedb_path => 指向的指针文件 是用户家目录下的文件 /root/.sincedb_*xxx ] ----------

Settings: Default pipeline workers: 2
Pipeline main started
{
       "message" => "BB_22844",
      "@version" => "1",
    "@timestamp" => "2019-01-20T07:07:10.109Z",
          "path" => "/var/tmp/b.log",
          "host" => "Va6"
}
{
       "message" => "A_30657",
      "@version" => "1",
    "@timestamp" => "2019-01-20T07:07:30.137Z",
          "path" => "/tmp/a.log",
          "host" => "Va6"
}

^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}
Pipeline main has been shutdown

[root@Va6 ~]# cat  /etc/logstash/logstash.conf
input {
  file {
      path => ["/tmp/a.log","/var/tmp/b.log"]
  }
}

filter{}

output{
  stdout{ codec => "rubydebug" }
}
[root@Va6 ~]# ll  /root/.s
.sincedb_e9a1772295a869da80134b5c4e75816e
.ssh/
          # /root/.sincedb_ 记录了文件读取的位置,此文件默认在用户家目录之下
[root@Va6 ~]# ll  /root/.sincedb_e9a1772295a869da80134b5c4e75816e 
-rw-r--r-- 1 root root 37 1月  20 15:10 /root/.sincedb_e9a1772295a869da80134b5c4e75816e

[root@Va6 ~]# cat   /root/.sincedb_e9a1772295a869da80134b5c4e75816e
16777285 0 64768 8
2063556 0 64768 9
---------------------------------------
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-sincedb_path

键名(固定的不能修改)    键的值的类型                   键值(可以选择修改,是否必须要配置)
Setting	       Input type	              Required
close_older        number or string_duration   No
delimiter          string                      No
discover_interval  number                      No
exclude            array                       No
...................
[path]                  [array]               Yes
.................
[sincedb_path]点击关键词    string        No

sincedb_path
Value type is string
There is no default value for this setting.
Path of the sincedb database file (keeps track of the current position of monitored log files) that will be written to disk. The default will write sincedb files to <path.data>/plugins/inputs/file NOTE: it must be a file path and not a directory path
将写入磁盘的sincedb数据库文件的路径（跟踪受监视日志文件的当前位置）。
默认值将把sincedb文件写入<path.data>/plugins/inputs/file
注：它必须是文件路径而不是目录路径

[root@Va6 ~]# vim    /etc/logstash/logstash.conf
[root@Va6 ~]# cat    /etc/logstash/logstash.conf  #修改指针文件的路径
input {
  file {
      path => ["/tmp/a.log","/var/tmp/b.log"]
      sincedb_path => "/var/lib/logstash/since.db"
  }
}

filter{}

output{
  stdout{ codec => "rubydebug" }
}                             
[root@Va6 ~]# file   /root/.sincedb_e9a1772295a869da80134b5c4e75816e
/root/.sincedb_e9a1772295a869da80134b5c4e75816e: ASCII text
  # /root/.sincedb_ (指针文件)记录了 path => ["/tmp/a.log","/var/tmp/b.log"]文件读取的位置,
    # 此文件默认在用户家目录之下

[root@Va6 ~]# rm  -f  /root/.sincedb_e9a1772295a869da80134b5c4e75816e #删除旧指针文件

[root@Va6 ~]# ls  /var/lib/logstash/
[root@Va6 ~]# ll  /var/lib/logstash/since.db
ls: 无法访问/var/lib/logstash/since.db: 没有那个文件或目录

[root@Va6 ~]# echo  A2_${RANDOM} >> /tmp/a.log; echo  BB2_${RANDOM} >> /var/tmp/b.log 

https://www.elastic.co/guide/en/logstash/current/plugins-inputs-file.html#plugins-inputs-file-sincedb_path
..................
start_position 
Value can be any of: beginning, end
Default value is "end"
_启动位置
值可以是任何：开始，结束
默认值是“结局”

[root@Va6 ~]# vim    /etc/logstash/logstash.conf
[root@Va6 ~]# cat   /etc/logstash/logstash.conf
input {
  file {
    path        => ["/tmp/a.log","/var/tmp/b.log"]
    sincedb_path   => "/var/lib/logstash/since.db"
    start_position => "beginning"  # 当sincedb_path指向的 指针文件" 不 存在 " 时,
                                               把默认读取位置从文件的头部开始读取
                              (注意如果不设置,默认值是从文件结束点开始读取数据)
  }
}

filter{}

output{
  stdout{ codec => "rubydebug" }
}
[root@Va6 ~]# 
[root@Va6 ~]# logstash  -f  /etc/logstash/logstash.conf
Settings: Default pipeline workers: 2
Pipeline main started
{
       "message" => "A_30657",
      "@version" => "1",
    "@timestamp" => "2019-01-20T07:55:51.214Z",
          "path" => "/tmp/a.log",
          "host" => "Va6"
}
{
       "message" => "A2_1637",
      "@version" => "1",
    "@timestamp" => "2019-01-20T07:55:51.236Z",
          "path" => "/tmp/a.log",
          "host" => "Va6"
}
{
       "message" => "BB_22844",
      "@version" => "1",
    "@timestamp" => "2019-01-20T07:55:51.240Z",
          "path" => "/var/tmp/b.log",
          "host" => "Va6"
}
{
       "message" => "BB2_24034",
      "@version" => "1",
    "@timestamp" => "2019-01-20T07:55:51.240Z",
          "path" => "/var/tmp/b.log",
          "host" => "Va6"
}

^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}
Pipeline main has been shutdown

[root@Va6 ~]# touch  /tmp/apache.log   /var/tmp/nginx.log

[root@Va6 ~]# vim    /etc/logstash/logstash.conf

[root@Va6 ~]# cat    /etc/logstash/logstash.conf
input {
  file {      #path属性接受的参数是一个数组，其含义是标明需要读取的文件路径,
    path        => ["/tmp/apache.log"]  #监听文件路径

       # 如果需要每次都从开始读取文件的话，设置start_position => beginning是没有用的，
                     # 可以选择  sincedb_path   定义为   /dev/null
    sincedb_path   => "/var/lib/logstash/since.db"

      #logstash 从什么 位置开始读取文件数据， 默认是结束位置 
    start_position => "beginning"   # 设置 监听文件 从 起始位置 开始读取数据

    type        => "http_log"   # 给日志设置标签,定义类型,
                     可以在logstash -f /etc/logstash/logstash.conf输出结果中区分文件来源
  }
  file {
    path        => ["/var/tmp/nginx.log"]
    sincedb_path   => "/var/lib/logstash/since.db"
    start_position => "beginning"
    type        => "nginx_log"
  }
}

filter{}

output{
  stdout{ codec => "rubydebug" }
}
[root@Va6 ~]# ls  -l  /var/lib/logstash/since.db 
-rw-r--r-- 1 root root 39 1月  20 15:56 /var/lib/logstash/since.db
[root@Va6 ~]# cat  /var/lib/logstash/since.db
16777285 0 64768 16
2063556 0 64768 19
[root@Va6 ~]# logstash  -f  /etc/logstash/logstash.conf  #开始运行服务
Settings: Default pipeline workers: 2
Pipeline main started
                # 再次执行命令,没有任何输出,
              是因为指针文件定义的读取位置错误,也可能是path 指向的文件内容是空null

^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}
Pipeline main has been shutdown

[root@Va6 ~]# ls  -l  /var/lib/logstash/since.db 
-rw-r--r-- 1 root root 76 1月  20 16:10 /var/lib/logstash/since.db
[root@Va6 ~]# cat   /var/lib/logstash/since.db
16777285 0 64768 16
2063556 0 64768 19
16777288 0 64768 0
2063557 0 64768 0

[root@Va6 ~]# >  /var/lib/logstash/since.db
[root@Va6 ~]# cat  /var/lib/logstash/since.db

[root@Va6 ~]# echo  apache_${RANDOM} >> /tmp/apache.log 
[root@Va6 ~]# cat  /tmp/apache.log
apache_22927
[root@Va6 ~]# echo  nginx_${RANDOM} >>  /var/tmp/nginx.log 
[root@Va6 ~]# cat   /var/tmp/nginx.log
nginx_15208
[root@Va6 ~]# logstash
logstash         logstash.lib.sh  logstash-plugin  
[root@Va6 ~]# logstash  -f  /etc/logstash/logstash.conf #开始运行logstash服务
Settings: Default pipeline workers: 2
Pipeline main started
{
       "message" => "apache_22927",
      "@version" => "1",
    "@timestamp" => "2019-01-20T08:26:10.606Z",
          "path" => "/tmp/apache.log",
          "host" => "Va6",
          "type" => "http_log"
}
{
       "message" => "nginx_15208",
      "@version" => "1",
    "@timestamp" => "2019-01-20T08:26:10.587Z",
          "path" => "/var/tmp/nginx.log",
          "host" => "Va6",
          "type" => "nginx_log"
}

^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}
Pipeline main has been shutdown

[root@Va6 ~]# ll   /var/lib/logstash/since.db 
-rw-r--r-- 1 root root 20 1月  20 16:26 /var/lib/logstash/since.db
[root@Va6 ~]# cat  /var/lib/logstash/since.db
16777288 0 64768 13
/****************
        path => [‘pathA’，‘pathB’]

        #表示多久去path路径下查看是够有新的文件产生。默认是15秒检查一次。
        discover_interval => 15

        #排除那些文件，也就是不去读取那些文件
        exclude => [‘fileName1’,‘fileNmae2’]

        #被监听的文件多久没更新后断开连接不在监听，默认是一个小时。
        close_older => 3600

        #在每次检查文件列 表的时候， 如果一个文件的最后 修改时间 超过这个值， 就忽略这个文件。 默认一天。
        ignore_older => 86400

        #logstash 每隔多 久检查一次被监听文件状态（ 是否有更新） ， 默认是 1 秒。
        stat_interval => 1
****************************/
     
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-tcp.html

Tcp Input Configuration Options
This plugin supports the following configuration options plus the Common Options described later.

Setting   Input type                        Required
host       string                               No
mode       string, one of ["server", "client"]  No
port       number                               Yes
....................

Details
.............
id
................
input {
  tcp {  # tcp协议 mode插件 支持服务端和客户端角色
    id => "my_plugin_id"
  }
}
tags
..........................
Common Optionsedit
The following configuration options are supported by all input plugins:

Setting               Input type               Required
add_field              hash                     No
codec                  codec                    No
enable_metric          boolean                  No
id                     string                   No
tags                   array                    No
type                   string                   No
-----------------------------
+[Working with plugins]
-[Input plugins]

azure_event_hubs
beats
cloudwatch
...........
elasticsearch
exec
file
.....
tcp
twitter
[udp]点击链接
https://www.elastic.co/guide/en/logstash/current/plugins-inputs-udp.html

Udp Input Configuration Optionsedit
This plugin supports the following configuration options plus the Common Options described later.

Setting      Input type    Required
buffer_size   number       No
host          string       No
port          number       Yes
..............
input {
  udp {   ## udp mode插件 只能作为服务器
    id => "my_plugin_id"
  }
}
..............
hostedit
Value type is string
Default value is "0.0.0.0"
................

 UDP是无连接通信协议，
即在数据传输时，数据的发送端和接收端不建立逻辑连接。
简单来说，当一台计算机向另外一台计算机发送数据时，
发送端不会确认接收端是否存在，就会发出数据，
同样接收端在收到数据时，也不会向发送端反馈是否收到数据。

[root@Va6 ~]# vim    /etc/logstash/logstash.conf
[root@Va6 ~]# cat    /etc/logstash/logstash.conf
input {
  file {
    path        => ["/tmp/apache.log"]
    sincedb_path   => "/var/lib/logstash/since.db"
    start_position => "beginning"
    type        => "http_log"
  }
  tcp {
    mode     => "server"  # 默认操作模式, server:监听客户端连接(client:连接到服务器)
    host     => "0.0.0.0"
    port     =>  8888
    type     => "tcp_type"
  }
  udp {
    port     =>  8888
    type     => "udp_type"
  }
}

filter{}

output{
  stdout{ codec => "rubydebug" }
}
[root@Va6 ~]# ss  -npult  |grep  8888
[root@Va6 ~]# logstash   -f  /etc/logstash/logstash.conf 
Settings: Default pipeline workers: 2
Pipeline main started


-------------------------------- 在 另一个 终端 进入Va6  测试 -------------

[root@Va6 ~]#  ss  -npult  |grep  8888
udp    UNCONN     0      0    :::8888  :::*     users:(("java",pid=7145,fd=37))
tcp    LISTEN     0      50   :::8888  :::*     users:(("java",pid=7145,fd=16))

--------------------------------------
[root@Va2 ~]# which  function 
/usr/bin/which: no function in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
[root@Va2 ~]# type  function
function 是 shell 关键字
[root@Va2 ~]# function  sendtcp(){
> exec  7<>/dev/tcp/192.168.0.16/8888
> echo  "$@" >&7
> exec  7<&-
> }
[root@Va2 ~]# sendtcp   xixihahaVa2-->>Va6
[root@Va2 ~]# which sendtcp
/usr/bin/which: no sendtcp in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
[root@Va2 ~]# type   sendtcp
sendtcp 是函数
sendtcp () 
{ 
    exec 7<> /dev/tcp/192.168.0.16/8888;
    echo "$@" 1>&7;
    exec 7>&-
}

/*******************
$@与$*的区别：
　　$@与$*都可以使用一个变量来来表示所有的参数内容，但这两个变量之间有一些不同之处。
　　$@：将输入的参数作为一个列表对象
　　$*：将输入的参数作为一个单词
********/

[root@Va6 ~]# logstash   -f  /etc/logstash/logstash.conf 
Settings: Default pipeline workers: 2
Pipeline main started
{
       "message" => "xixihahaVa2--",
      "@version" => "1",
    "@timestamp" => "2019-01-20T10:13:17.722Z",
          "host" => "192.168.0.12",
          "port" => 40502,
          "type" => "tcp_type"
}

^CSIGINT received. Shutting down the agent. {:level=>:warn}
stopping pipeline {:id=>"main"}
UDP ..................... :level=>:warn}
Pipeline main has been shutdown

[root@Va6 ~]# 

Grok 是 Logstash 最重要的插件之一。也是迄今为止使蹩脚的、无结构的日志结构化和可查询的最好方式。Grok在解析 syslog logs、apache and other webserver logs、mysql logs等任意格式的文件上表现完美








