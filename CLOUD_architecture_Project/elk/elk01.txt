 关系型   --------  非关系型
MySQL    ?--?  NoSQL
Database  ---->   Index
Table        ---->   Type
Row          ---->   Document
Column    ---->   Filed

ELK组成：
    - E：是指Elasticsearch，完成数据的存储和检索
    - L：是Logstash，完成数据的采集、过滤及解析
    - K：Kibana，以WEB方式展示

curl 命令

访问一个网页
curl http://www.baidu.com

显示头信息
curl -I http://www.baidu.com

显示详细的交互信息
curl -v http://www.baidu.com

把网页内存保存为文件
curl -o urfile http://www.baidu.com

禁用 防火墙，禁用 selinux

elasticsearch 安装
1、安装 openjdk 包
yum install -y java-1.8.0-openjdk-devel

验证
java -version
jps

安装 elasticsearch 
rpm -ivh elasticsearch-2.3.4.rpm

修改配置文件启动服务
network.host: ip.xx.xx.xx
systemctl start elasticsearch

验证
systemctl status elasticsearch
netstat -ltunp

通过浏览器访问
http://192.168.4.11:9200/

elasticsearch 集群安装
在多台机器上安装部署 java-1.8.0-openjdk-devel，elasticsearch-2.3.4.rpm
修改 hosts 文件，保证所有机器通过名称能 ping 通集群中的其他机器

禁用防火墙 和 selinux
禁用防火墙 和 selinux
禁用防火墙 和 selinux

在所有节点修改配置文件 /etc/elasticsearch/elasticsearch.yml 
cluster.name: my-elk01
node.name: node5
network.host: 0.0.0.0
discovery.zen.ping.unicast.hosts: ["node1", "node2", "node3", "node5"]

启动所有节点的 elasticsearch 服务
通过浏览器可以访问任意节点的 http://ip.xx.xx.xx:9200/

验证集群是否正常，访问
http://192.168.4.15:9200/_cluster/health?pretty

{
  "cluster_name" : "my-elk01", #集群名称
  "status" : "green", # 表示正常
  "timed_out" : false,
  "number_of_nodes" : 5, #当前节点数量
  "number_of_data_nodes" : 5,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}

插件的安装 head  kopf  bigdesk
1 拷贝插件 zip 包到一个目录
2 /usr/share/elasticsearch/bin/plugin install file:///插件的位置/插件包.zip 安装

3 验证：
安装完成以后可以通过
/usr/share/elasticsearch/bin/plugin list 看到我们已经安装的插件的名称

4 访问head 插件
它展现ES集群的拓扑结构
可以通过它来进行索引（Index）和节点（Node）级别的操作
它提供一组针对集群的查询API，并将结果以json和表格形式返回
它提供一些快捷菜单，用以展现集群的各种状态
http://192.168.4.11:9200/_plugin/head/


5 kopf 插件安装
kopf是一个ElasticSearch的管理工具，它提供了对ES集群操作的API。
/usr/share/elasticsearch/bin/plugin install file:///xxx-kopf.zip

访问地址
http://192.168.4.11:9200/_plugin/kopf/

6 bigdesk 插件安装
bigdesk是elasticsearch的一个集群监控工具
可以通过它来查看es集群的各种状态，
如：cpu、内存使用情况，索引数据、搜索情况，http连接数等。
/usr/share/elasticsearch/bin/plugin install file:///bigdesk-xxx.zip

访问地址
http://192.168.4.11:9200/_plugin/bigdesk/

使用RESTful API操作elasticsearch
curl -XPUT 'http://192.168.4.11:9200/school/' -d '{
    "settings":{
        "index":{
            "number_of_shards": 5,
            "number_of_replicas": 1
        }
    }
}'

获取索引配置信息：
curl -XGET 'http://192.168.4.11:9200/school/_settings/'
curl -XGET 'http://192.168.4.11:9200/_all/_settings/'

创建文档
curl -XPUT 'http://192.168.4.11:9200/school/students/1' -d '{
    "title": "devops",
    "name":{
        "first": "guzhang",
        "last": "wu"
    },
    "age": 25
}'

查询文档信息
curl -XGET 'http://192.168.4.11:9200/school/students/1'
curl -XGET 'http://192.168.4.11:9200/school/students/1?_source=name,age'

更新文档信息
curl -XPOST 'http://192.168.4.11:9200/school/students/1/_update' -d '{
    "doc":{
        "age": 30
    }
}'

删除文档信息
curl -XDELETE 'http://192.168.4.14:9200/school/students/1'

批量导入数据
curl -XPOST 'http://192.168.4.14:9200/_bulk' --data-binary @shakespeare.json
curl -XPOST 'http://192.168.4.14:9200/_bulk' --data-binary @logs.jsonl
curl -XPOST 'http://192.168.4.14:9200/accounts/act/_bulk?pretty' --data-binary @accounts.json

批量查询数据
curl -XGET 'http://192.168.4.11:9200/_mget?pretty' -d '{ 
    "docs":[
        {
            "_index": "accounts",
            "_type:": "act",
            "_id": 1
        },
        {
            "_index": "accounts",
            "_type:": "act",
            "_id": 2
        },
        {
            "_index": "shakespeare",
            "_type:": "scene",
            "_id": 1
        }
    ]
}'

json 是什么，格式怎么书写


==============================

正则表达式构造

\p{名称}
匹配属于 Unicode 常规类别或命名块的任何字符

\P{名称}
匹配不属于 Unicode 常规类别或命名块的任何字符

非单词字符：\W
\W 匹配任何非单词字符。\W 语言元素等效于以下字符类：
[^\p{Ll}\p{Lu}\p{Lt}\p{Lo}\p{Nd}\p{Pc}\p{Lm}]

单词字符：\w
\w 与任何单词字符匹配

类别	描述
Ll	字母，小写
Lu	字母，大写
Lt	字母，首字母大写
Lo	字母，其他
Lm	字母，修饰符
Nd	数字，十进制数
Pc	标点，连接符。 此类别包含 10 个字符，最常用的字符是 LOWLINE 字符 (_)，u+005F。
如果指定了符合 ECMAScript 的行为，则 \w 等效于 [a-zA-Z_0-9]。

?\d  匹配零个或一个 十进制数字字符  ## 注意 . 点和 ? 问号的区别
.\d  匹配 一个  十进制数字字符


通配符类型：
. 表示任意字符
? 表示出现0次或1次   ？：匹配 零个或 任意单个字符
* 表示 出现0次或多次    *：匹配任意长度的任意字符
+ 表示出现1次或 多次
{m,n} 表示出现至少m次，最多n次
{m,} 表示出现最少m次，最多不限
{m}表示就出现m次
{,n} 表示出现最多n次，最少不限
( )    分组
   [ ]：匹配指定范围内的任意单个字符
   [^]：匹配指定范围之外的任意单个字符
  [:space:]：空白字符
  [:punct:]：标点符号
  [:lower:]：小写字母
 [:upper:]：大写字母
 [:alpha:]：大小写字母
 [:digit:]：数字
   [:alnum:]：数字和大小写字母


2 正则表达式中的字符类
 正字符组：[ ]
 负字符组：[^]
 任意字符： .
  Unicode类别或Unicode块：\p{}
  负 Unicode 类别或 Unicode 块：\P {}
 单词字符：\w
 非单词字符：\W
  空白字符：\s
  非空白字符：\S
  十进制数字字符：\d
  非数字字符：\D


标点符号
[计]punctuation; 
  interpunction

punctuation 标点符号
interpunction 标点，标点符号
alphabet n. 字母表;字母系统;入门，初步

显示所有以a或者m开头的文件： 
  ls -l [am]*
显示所有文件名中包含了数字的文件：
 ls -l *[0-9]* 或者ls -l *[[:digit:]]*


1     2     3
12   0-9   0-9

1   \d   \d
2    0-5
      5    0-5
    0-4  \d

25[0-5]|2[0-4]\d|1?\d?\d

?\d
?\d  匹配零个或一个 十进制数字字符  ## 注意 . 点和 ? 问号的区别
.\d  匹配 一个  十进制数字字符

精确匹配ip地址
((25[0-5]|2[0-4]\d|1?\d?\d)\.){3}(25[0-5]|2[0-4]\d|1?\d?\d)

模糊匹配ip地址
([12]?\d?\d\.){3}[12]?\d?\d
模糊匹配ip地址
([12](?\d){2}\.){3}[12](?\d){2}

常见正则表达式
　　匹配中文字符的正则表达式： [u4e00-u9fa5]   
　　
　　匹配双字节字符(包括汉字在内)：[^x00-xff] 
　　评注：可以用来计算字符串的长度（一个双字节字符长度计2，ASCII字符计1） 
　　匹配空白行的正则表达式：ns*r 
　　评注：可以用来删除空白行 
　　匹配HTML标记的正则表达式：<(S*?)[^>]*>.*?|<.*? /> 
　　评注：网上流传的版本太糟糕，上面这个也仅仅能匹配部分，对于复杂的嵌套标记依旧无能为力 
　　匹配首尾空白字符的正则表达式：^s*|s*$ 
　　评注：可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式 
　　匹配Email地址的正则表达式：w+([-+.]w+)*@w+([-.]w+)*.w+([-.]w+)* 
　　评注：表单验证时很实用 
　　匹配网址URL的正则表达式：^(http|https):\/\/[\w\-_]+(\.[\w\-_]+)+([\w\-\.,@?^=%&amp;:/~\+#]*[\w\-\@?^=%&amp;/~\+#])?$
　　评注：网上流传的版本功能很有限，上面这个基本可以满足需求 
　　

     匹配帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：^[a-zA-Z][a-zA-Z0-9_]{4,15}$ 
　　评注：表单验证时很实用 
　　匹配国内电话号码：d{3}-d{8}|d{4}-d{7} 
　　评注：匹配形式如 0511-4405222 或 021-87888822 
　　匹配腾讯QQ号：[1-9][0-9]{4,} 
　　评注：腾讯QQ号从10000开始 
　　匹配中国邮政编码：[1-9]d{5}(?!d) 
　　评注：中国邮政编码为6位数字 
　　匹配身份证：d{15}|d{18} 
　　评注：中国的身份证为15位或18位 
　　匹配ip地址：d+.d+.d+.d+ 
　　评注：提取ip地址时有用 
　　匹配特定数字： 
　　^[1-9]d*$　 　 //匹配正整数 
　　^-[1-9]d*$ 　 //匹配负整数 
　　^-?[1-9]d*$　　 //匹配整数 
　　^[1-9]d*|0$　 //匹配非负整数（正整数 + 0） 
　　^-[1-9]d*|0$　　 //匹配非正整数（负整数 + 0） 
　　^[1-9]d*.d*|0.d*[1-9]d*$　　 //匹配正浮点数 
　　^-([1-9]d*.d*|0.d*[1-9]d*)$　 //匹配负浮点数 
　　^-?([1-9]d*.d*|0.d*[1-9]d*|0?.0+|0)$　 //匹配浮点数 
　　^[1-9]d*.d*|0.d*[1-9]d*|0?.0+|0$　　 //匹配非负浮点数（正浮点数 + 0） 
　　^(-([1-9]d*.d*|0.d*[1-9]d*))|0?.0+|0$　　//匹配非正浮点数（负浮点数 + 0） 
　　评注：处理大量数据时有用，具体应用时注意修正 
　　匹配特定字符串： 
　　^[A-Za-z]+$　　//匹配由26个英文字母组成的字符串 
　　^[A-Z]+$　　//匹配由26个英文字母的大写组成的字符串 
　　^[a-z]+$　　//匹配由26个英文字母的小写组成的字符串 
　　^[A-Za-z0-9]+$　　//匹配由数字和26个英文字母组成的字符串 
　　^w+$　　//匹配由数字、26个英文字母或者下划线组成的字符串 
　　在使用RegularExpressionValidator验证控件时的验证功能及其验证表达式介绍如下: 
　　只能输入数字：“^[0-9]*$” 
　　只能输入n位的数字：“^d{n}$” 
　　只能输入至少n位数字：“^d{n,}$” 
　　只能输入m-n位的数字：“^d{m,n}$” 
　　只能输入零和非零开头的数字：“^(0|[1-9][0-9]*)$” 
　　只能输入有两位小数的正实数：“^[0-9]+(.[0-9]{2})?$” 
　　只能输入有1-3位小数的正实数：“^[0-9]+(.[0-9]{1,3})?$” 
　　只能输入非零的正整数：“^+?[1-9][0-9]*$” 
　　只能输入非零的负整数：“^-[1-9][0-9]*$” 
　　只能输入长度为3的字符：“^.{3}$” 
　　只能输入由26个英文字母组成的字符串：“^[A-Za-z]+$” 
　　只能输入由26个大写英文字母组成的字符串：“^[A-Z]+$” 
　　只能输入由26个小写英文字母组成的字符串：“^[a-z]+$” 
　　只能输入由数字和26个英文字母组成的字符串：“^[A-Za-z0-9]+$” 
　　只能输入由数字、26个英文字母或者下划线组成的字符串：“^w+$” 
　　验证用户密码:“^[a-zA-Z]w{5,17}$”正确格式为：以字母开头，长度在6-18之间， 只能包含字符、数字和下划线。 
　　验证是否含有^%&'',;=?$"等字符：“[^%&'',;=?$x22]+” 
　　只能输入汉字：“^[u4e00-u9fa5],{0,}$” 
　　验证Email地址：“^w+[-+.]w+)*@w+([-.]w+)*.w+([-.]w+)*$” 
　　验证电话号码：“^((d{3,4})|d{3,4}-)?d{7,8}$” 
　　正确格式为：“XXXX-XXXXXXX”，“XXXX-XXXXXXXX”，“XXX-XXXXXXX”， 
　　“XXX-XXXXXXXX”，“XXXXXXX”，“XXXXXXXX”。 
　　验证身份证号（15位或18位数字）：“^d{15}|d{}18$” 
　　验证一年的12个月：“^(0?[1-9]|1[0-2])$”正确格式为：“01”-“09”和“1”“12” 
　　验证一个月的31天：“^((0?[1-9])|((1|2)[0-9])|30|31)$” 
　　正确格式为：“01”“09”和“1”“31”。 
　　匹配中文字符的正则表达式： [u4e00-u9fa5] 
　　匹配双字节字符(包括汉字在内)：[^x00-xff] 
　　匹配空行的正则表达式：n[s| ]*r 
　　匹配HTML标记的正则表达式：/<(.*)>.*|<(.*) />/ 
　　匹配首尾空格的正则表达式：(^s*)|(s*$)  
　　

二、正则表达式应用
(1)应用：计算字符串的长度（一个双字节字符长度计2，ASCII字符计1） 
　　String.prototype.len=function(){return this.replace([^x00-xff]/g,"aa").length;} 
　　

(2)应用：javascript中没有像vbscript那样的trim函数，我们就可以利用这个表达式来实现 
　　String.prototype.trim = function() 
　　{ 
　　　　return this.replace(/(^s*)|(s*$)/g, ""); 
　　} 

(3)应用：利用正则表达式分解和转换IP地址 
　　

复制代码
function IP2V(ip) //IP地址转换成对应数值 
{ 
　　re=/(d+).(d+).(d+).(d+)/g //匹配IP地址的正则表达式 
　　if(re.test(ip)) 
　　{ 
　　    return RegExp.$1*Math.pow(255,3))+RegExp.$2*Math.pow(255,2))+RegExp.$3*255+RegExp.$4*1 
　　} 
　　else 
　　{ 
　　    throw new Error("Not a valid IP address!") 
　　} 
} 
复制代码
　　

(4)应用：从URL地址中提取文件名的javascript程序 
　　s="http://www.9499.net/page1.htm"; 
　　s=s.replace(/(.*/){0,}([^.]+).*/ig,"$2") ;//Page1.htm 
　　

(5)应用：利用正则表达式限制网页表单里的文本框输入内容 
　　
用正则表达式限制只能输入中文：onkeyup="value=value.replace(/[^u4E00-u9FA5]/g,'') "onbeforepaste="clipboardData.setData(''text'',clipboardData.getData(''text'').replace(/[^u4E00-u9FA5]/g,''))" 
　　
用正则表达式限制只能输入全角字符： onkeyup="value=value.replace(/[^uFF00-uFFFF]/g,'') "onbeforepaste="clipboardData.setData(''text'',clipboardData.getData(''text'').replace(/[^uFF00-uFFFF]/g,''))" 
　　
用正则表达式限制只能输入数字：onkeyup="value=value.replace(/[^d]/g,'') "onbeforepaste= "clipboardData.setData(''text'',clipboardData.getData(''text'').replace(/[^d]/g,''))" 
　　
用正则表达式限制只能输入数字和英文：onkeyup="value=value.replace(/[W]/g,'') "onbeforepaste="clipboardData.setData(''text'',clipboardData.getData(''text'').replace(/[^d]/g,''

 

三、/i,/g,/ig,/gi,/m
正则表达式中/i,/g,/ig,/gi,/m的区别和含义

/i (忽略大小写)
/g (全文查找出现的所有匹配字符)
/m (多行查找)
/gi(全文查找、忽略大小写)
/ig(全文查找、忽略大小写)


 awk实现group by ,统计log最大访问的ip
awk '{a[$2]+=1}END{for (i in a)print i,a[i]}' file  

awk的数组 
其下标可以是任意字符或者字符串。比如a[bob]，表示数组a的一个元素，它的下标是"bob"。 
上面例子中就是把$2当数组下标，value是次数。 

然后再用sort排序 
-k 使用哪个字段排序 
-n 按照数值来排序  9 < 10 
-r 倒序 
-t<分隔字符>  指定排序时所用的栏位分隔字符 

sort -n -k 2 filename > 输出结果filename  

除了以上方法外，还可以使用uniq 
uniq去重复 
uniq -c 在输出行前面加上每行在输入文件中出现的次数。 

Java代码  收藏代码
awk '{print $2}'filename| sort | uniq -c | sort -n  




I/O重定向详解
1、 基本概念(这是理解后面的知识的前提，请务必理解)
a、 I/O重定向通常与 FD有关，shell的FD通常为10个，即 0～9;
b、 常用FD有3个，为0(stdin，标准输入)、1(stdout，标准输出)、2(stderr，标准错误输出)，默认与keyboard、monitor、monitor有关;
c、 用 < 来改变读进的数据信道(stdin)，使之从指定的档案读进;
d、 用 > 来改变送出的数据信道(stdout, stderr)，使之输出到指定的档案;
e、 0 是 < 的默认值，因此 < 与 0<是一样的;同理，> 与 1> 是一样的;
f、 在IO重定向 中，stdout 与 stderr 的管道会先准备好，才会从 stdin 读进资料;
g、 管道“|”(pipe line):上一个命令的 stdout 接到下一个命令的 stdin;
h、 tee 命令是在不影响原本 I/O 的情况下，将 stdout 复制一份到档案去;
i、 bash(ksh)执行命令的过程：分析命令-变量求值-命令替代(``和$( ))-重定向-通配符展开-确定路径-执行命令;
j、 ( ) 将 command group 置于 sub-shell 去执行，也称 nested sub-shell，它有一点非常重要的特性是：继承父shell的Standard input, output, and error plus any other open file descriptors。
k、 exec 命令：常用来替代当前 shell 并重新启动一个 shell，换句话说，并没有启动子 shell。使用这一命令时任何现有环境都将会被清除。exec 在对文件描述符进行操作的时候，也只有在这时，exec 不会覆盖你当前的 shell 环境。
2、 基本IO
cmd > file 把 stdout 重定向到 file 文件中;
cmd >> file 把 stdout 重定向到 file 文件中(追加);
cmd 1> fiel 把 stdout 重定向到 file 文件中;
cmd > file 2>&1 把 stdout 和 stderr 一起重定向到 file 文件中;
cmd 2> file 把 stderr 重定向到 file 文件中;
cmd 2>> file 把 stderr 重定向到 file 文件中(追加);
cmd >> file 2>&1 把 stderr 和 stderr 一起重定向到 file 文件中(追加);
cmd < file >file2 cmd 命令以 file 文件作为 stdin，以 file2 文件作为 stdout;
cat <>file 以读写的方式打开 file;
cmd < file cmd 命令以 file 文件作为 stdin;
cmd << delimiter Here document，从 stdin 中读入，直至遇到 delimiter 分界符。
3、 进阶IO
>&n 使用系统调用 dup (2) 复制文件描述符 n 并把结果用作标准输出;
<&n 标准输入复制自文件描述符 n;
<&- 关闭标准输入(键盘);
>&- 关闭标准输出;
n<&- 表示将 n 号输入关闭;
n>&- 表示将 n 号输出关闭;
上述所有形式都可以前导一个数字，此时建立的文件描述符由这个数字指定而不是缺省的 0 或 1。如：
... 2>file 运行一个命令并把错误输出(文件描述符 2)定向到 file。
... 2>&1 运行一个命令并把它的标准输出和输出合并。(严格的说是通过复制文件描述符 1 来建立文件描述符 2 ，但效果通常是合并了两个流。)
我们对 2>&1详细说明一下 ：2>&1 也就是 FD2=FD1 ，这里并不是说FD2 的值 等于FD1的值，因为 > 是改变送出的数据信道，也就是说把 FD2 的 “数据输出通道” 改为 FD1 的 “数据输出通道”。如果仅仅这样，这个改变好像没有什么作用，因为 FD2 的默认输出和 FD1的默认输出本来都是 monitor，一样的!但是，当 FD1 是其他文件，甚至是其他 FD 时，这个就具有特殊的用途了。请大家务必理解这一点。
exec 0exec 1>outfilename # 打开文件outfilename作为stdout。
exec 2>errfilename # 打开文件 errfilename作为 stderr。
exec 0<&- # 关闭 FD0。
exec 1>&- # 关闭 FD1。
exec 5>&- # 关闭 FD5。
1 COMMAND_OUTPUT >
2 # 重定向stdout到一个文件.
3 # 如果没有这个文件就创建, 否则就覆盖.
4
5 ls -lR > dir-tree.list
6 # 创建一个包含目录树列表的文件.
7
8 : > filename
9 # > 会把文件"filename"截断为0长度.
10 # 如果文件不存在, 那么就创建一个0长度的文件(与'touch'的效果相同).
11 # : 是一个占位符, 不产生任何输出.
12
13 > filename
14 # > 会把文件"filename"截断为0长度.
15 # 如果文件不存在, 那么就创建一个0长度的文件(与'touch'的效果相同).
16 # (与上边的": >"效果相同, 但是在某些shell下可能不能工作.)
17
18 COMMAND_OUTPUT >>
19 # 重定向stdout到一个文件.
20 # 如果文件不存在, 那么就创建它, 如果存在, 那么就追加到文件后边.
21
22
23 # 单行重定向命令(只会影响它们所在的行):
24 # --------------------------------------------------------------------
25
26 1>filename
27 # 重定向stdout到文件"filename".
28 1>>filename
29 # 重定向并追加stdout到文件"filename".
30 2>filename
31 # 重定向stderr到文件"filename".
32 2>>filename
33 # 重定向并追加stderr到文件"filename".
34 &>filename
35 # 将stdout和stderr都重定向到文件"filename".
36
37 #==============================================================================
38 # 重定向stdout, 一次一行.
39 LOGFILE=script.log
40
41 echo "This statement is sent to the log file, "$LOGFILE"." 1>$LOGFILE
42 echo "This statement is appended to "$LOGFILE"." 1>>$LOGFILE
43 echo "This statement is also appended to "$LOGFILE"." 1>>$LOGFILE
44 echo "This statement is echoed to stdout, and will not appear in "$LOGFILE"."
45 # 每行过后, 这些重定向命令会自动"reset".

49 # 重定向stderr, 一次一行.
50 ERRORFILE=script.errors
51
52 bad_command1 2>$ERRORFILE # 错误消息发到$ERRORFILE中.
53 bad_command2 2>>$ERRORFILE # 错误消息添加到$ERRORFILE中.
54 bad_command3 # 错误消息echo到stderr,
55 #+ 并且不出现在$ERRORFILE中.
56 # 每行过后, 这些重定向命令也会自动"reset".
57 #==============================================================================

61 2>&1
62 # 重定向stderr到stdout.
63 # 得到的错误消息与stdout一样, 发送到一个地方.
64
65 i>&j
66 # 重定向文件描述符i 到 j.
67 # 指向i文件的所有输出都发送到j中去.
68
69 >&j
70 # 默认的, 重定向文件描述符1(stdout)到 j.
71 # 所有传递到stdout的输出都送到j中去.
72
73 0< FILENAME
74 < FILENAME
75 # 从文件中接受输入.
76 # 与">"是成对命令, 并且通常都是结合使用.
77 #
78 # grep search-word
79
80
81 [j]<>filename
82 # 为了读写"filename", 把文件"filename"打开, 并且分配文件描述符"j"给它.
83 # 如果文件"filename"不存在, 那么就创建它.
84 # 如果文件描述符"j"没指定, 那默认是fd 0, stdin.
85 #
86 # 这种应用通常是为了写到一个文件中指定的地方.
87 echo 1234567890 > File # 写字符串到"File".
88 exec 3<> File # 打开"File"并且给它分配fd 3.
89 read -n 4 <&3 # 只读4个字符.
90 echo -n . >&3 # 写一个小数点.
91 exec 3>&- # 关闭fd 3.
92 cat File # ==> 1234.67890


93 # 随机存储.

98 # 管道.
99 # 通用目的的处理和命令链工具.
100 # 与">"很相似, 但是实际上更通用.
101 # 对于想将命令, 脚本, 文件和程序串连起来的时候很有用.
102 cat *.txt | sort | uniq > result-file
103 # 对所有的.txt文件的输出进行排序, 并且删除重复行,
104 # 最后将结果保存到"result-file"中.
可以将输入输出重定向和(或)管道的多个实例结合到一起写在一行上.
1 command < input-file > output-file
2
3 command1 | command2 | command3 > output-file
可以将多个输出流重定向到一个文件上.
1 ls -yz >> command.log 2>&1
2 # 将错误选项"yz"的结果放到文件"command.log"中.
3 # 因为stderr被重定向到这个文件中,
4 #+ 所有的错误消息也就都指向那里了.
5
6 # 注意, 下边这个例子就不会给出相同的结果.
7 ls -yz 2>&1 >> command.log
8 # 输出一个错误消息, 但是并不写到文件中.
9
10 # 如果将stdout和stderr都重定向,
11 #+ 命令的顺序会有些不同.
exec
使用exec重定向标准输入
1 #!/bin/bash
2 # 使用'exec'重定向标准输入.
3
4
5 exec 6<&0 # 将文件描述符#6与stdin链接起来.
6 # 保存了stdin.
7
8 exec < data-file # stdin被文件"data-file"所代替.
9
10 read a1 # 读取文件"data-file"的第一行.
11 read a2 # 读取文件"data-file"的第二行.
12
13 echo
14 echo "Following lines read from file."
15 echo "-------------------------------"
16 echo $a1
17 echo $a2
18
19 echo; echo; echo
20
21 exec 0<&6 6<&-
22 # 现在将stdin从fd #6中恢复, 因为刚才我们把stdin重定向到#6了,
23 #+ 然后关闭fd #6 ( 6<&- ), 好让这个描述符继续被其他进程所使用.
24 #
25 # <&6 6<&- 这么做也可以.
26
27 echo -n "Enter data "
28 read b1 # 现在"read"已经恢复正常了, 就是从stdin中读取.
29 echo "Input read from stdin."
30 echo "----------------------"
31 echo "b1 = $b1"
32
33 echo
34
35 exit 0
使用exec来重定向stdout

1 #!/bin/bash 
2 # reassign-stdout.sh 
3 
4 LOGFILE=logfile.txt 
5 
6 exec 6>&1 # 将fd #6与stdout相连接. 
7 # 保存stdout. 
8 
9 exec > $LOGFILE # stdout就被文件"logfile.txt"所代替了. 
10 
11 # ----------------------------------------------------------- # 
12 # 在这块中所有命令的输出就都发向文件 $LOGFILE. 
13 
14 echo -n "Logfile: " 
15 date 
16 echo "-------------------------------------" 
17 echo 
18 
19 echo "Output of "ls -al" command" 
20 echo 
21 ls -al 
22 echo; echo 
23 echo "Output of "df" command" 
24 echo 
25 df 
26 
27 # ----------------------------------------------------------- # 
28 
29 exec 1>&6 6>&- # 恢复stdout, 然后关闭文件描述符#6. 
30 
31 echo 
32 echo "== stdout now restored to default == " 
33 echo 
34 ls -al 
35 echo 
36 
37 exit 0
使用exec在同一脚本中重定向stdin和stdout

1 #!/bin/bash 
2 # upperconv.sh 
3 # 将一个指定的输入文件转换为大写. 
5 E_FILE_ACCESS=70 
6 E_WRONG_ARGS=71  
8 if [ ! -r "$1" ] # 判断指定的输入文件是否可读? 
9 then 
10 echo "Can't read from input file!" 
11 echo "Usage: $0 input-file output-file" 
12 exit $E_FILE_ACCESS 
13 fi # 即使输入文件($1)没被指定 
14 #+ 也还是会以相同的错误退出(为什么?). 

16 if [ -z "$2" ] 
17 then 
18 echo "Need to specify output file." 
19 echo "Usage: $0 input-file output-file" 
20 exit $E_WRONG_ARGS 
21 fi 

24 exec 4<&0 
25 exec < $1 # 将会从输入文件中读取. 
26 
27 exec 7>&1 
28 exec > $2 # 将写到输出文件中.
 29 # 假设输出文件是可写的(添加检查?). 
30 
31 # ----------------------------------------------- 
32 cat - | tr a-z A-Z # 转换为大写. 
33 # ^^^^^ # 从stdin中读取.Reads from stdin. 
34 # ^^^^^^^^^^ # 写到stdout上. 
35 # 然而, stdin和stdout都被重定向了. 
36 # ----------------------------------------------- 
37 
38 exec 1>&7 7>&- # 恢复 stout. 
39 exec 0<&4 4<&- # 恢复 stdin. 
40 
41 # 恢复之后, 下边这行代码将会如期望的一样打印到stdout上. 
42 echo "File "$1" written to "$2" as uppercase conversion." 
43 
44 exit 0
I/O重定向是一种避免可怕的子shell中不可存取变量问题的方法.



















