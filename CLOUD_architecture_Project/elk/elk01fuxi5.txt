
cURL是一个利用URL语法在命令行下工作的文件传输工具，1997年首次发行。

它支持文件上传和下载，所以是综合传输工具，但按传统，习惯称cURL为下载工具。

cURL还包含了用于程序开发的libcurl。

cURL支持的通信协议有
FTP、 FTPS、
HTTP、HTTPS、
TFTP、SFTP、
Gopher、SCP、Telnet、
DICT、 FILE、LDAP、
LDAPS、
IMAP、
POP3、SMTP和RTSP。


curl 支持
SSL认证、
HTTP POST、 HTTP PUT、
FTP上传,  
HTTP form based upload、
proxies、
HTTP/2、cookies、 
用户名+密码认证(Basic, Plain, Digest, 
CRAM-MD5, NTLM, Negotiate and Kerberos)、
file transfer resume、
proxy tunneling。

libcurl支持的平台有
Solaris、NetBSD、FreeBSD、OpenBSD、
Darwin、 HP-UX、 IRIX、    AIX、
Tru64、  Linux、 UnixWare、HURD、
Windows、Symbian、Amiga、  OS/2、
BeOS、  Mac OS X、Ultrix、 QNX、
BlackBerry Tablet OS、OpenVMS、RISC OS、
Novell NetWare、DOS 等。

ELK分别代表的意思
Elasticsearch：负责日志检索和储存
Logstash：负责日志的收集和分析、处理
Kibana：负责日志的可视化
这三款软件都是开源软件，通常是配合使用，而且又先后归于Elastic.co公司名下，故被简称为ELK

 ELK可以实现什么功能

在海量日志系统的运维中，
可用于解决分布式日志数据集中式查询和管理、系统监控，
包含系统硬件和应用各个组件的监控、故障排查、安全信息和事件管理、报表功能

Elasticsearch主要特点

1、实时分析
2、分布式实时文件存储，并将每一个字段都编入索引
3、文档导向，所有的对象全部是文档
4、高可用性，易扩展，支持集群（Cluster） 、 分片和复制（Shards 和 Replicas）
5、接口友好，支持JSON

关系型     --------   非关系型
MySQL    ?--?    NoSQL
Database ---->   Index
Table    ---->   Type
Row      ---->   Document
Column   ---->   Filed

ELK组成：
    - E：是指Elasticsearch [非关系型数据库,最重要]，完成数据的存储和检索
    - L：是Logstash[可使用 docker 容器技术,数据次重要]，完成数据的采集、过滤及解析
    - K：Kibana [与 apache 作用相同 ] ，以WEB方式展示 

Linux  apache    mysql[关系型]       php[处理后台程序]
L        A         M                  P
L        K         E                  L
Linux  kibana elasticsearch[非关系型] logstash[处理日志的工作[ java开发的 ]]

Elasticsearch中的概念与关系型数据库对比

Relational DB  Databases Tables   Rows   Columns
关系型数据库        数据库       表         行         列

Elasticsearch  Indices   Types  Documents  Fields
搜索引擎             索引        类型      文档       域(字段)


[root@room9pc01 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:          15781        1756       12903         131        1120       13591
Swap:             0           0           0
[root@room9pc01 ~]# echo "15781-1524*8-2048" |bc
1541
[root@room9pc01 ~]# uptime 
 09:32:12 up 13 min,  2 users,  load average: 0.32, 0.60, 0.40

[root@room9pc01 ~]# cat  /etc/resolv.conf 
nameserver  176.121.0.100

[root@room9pc01 ~]# tail  -2  /etc/rc.local 
mount  -o  loop  -t  iso9660  /var/git/CentOS7-1708.iso  /var/ftp/CentOS7-1708
echo  "nameserver  176.121.0.100" >  /etc/resolv.conf

[root@room9pc01 ~]# uptime 
 09:46:37 up 28 min,  2 users,  load average: 1.17, 0.86, 0.62

[root@room9pc01 ~]# uptime
 11:33:05 up  2:14,  8 users,  load average: 0.46, 0.51, 0.54


 ~]# tar  -xf  /var/git/elk.tar  -C  /var/ftp/ansible/ 

[root@room9pc01 ~]# ls   /var/ftp/
ansible  CentOS7-1708  elk  pub  rhel7  share

[root@room9pc01 ~]# ls   /var/ftp/ansible/
ansible-2.4.2.0-2.el7.noarch.rpm         python-httplib2-0.9.2-1.el7.noarch.rpm
elasticsearch-2.3.4.rpm                  python-paramiko-2.1.1-4.el7.noarch.rpm
filebeat-1.2.3-x86_64.rpm                python-passlib-1.6.5-2.el7.noarch.rpm
kibana-4.5.2-1.x86_64.rpm                repodata
logstash-2.3.4-1.noarch.rpm              sshpass-1.06-2.el7.x86_64.rpm
python2-jmespath-0.9.0-3.el7.noarch.rpm

[root@room9pc01 ~]# createrepo   --update  /var/ftp/ansible/



[root@room9pc01 ~]# ssh -Xo  StrictHostKeyChecking=no  192.168.0.11
.................
[root@Va1 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1984         416        1372           8         195        1403
Swap:          2047           0        2047

[root@Va1 ~]# yum  clean all >/dev/null  && yum repolist  |tail  -4
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

[root@Va1 ~]# yum list  |grep  openjdk^C
[root@Va1 ~]# yum list  |grep  java-1.8.0-openjdk

[root@Va1 ~]# yum  -y  install   java-1.8.0-openjdk  
..............
软件包 1:java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64 已安装并且是最新版本
无须任何处理

[root@Va1 ~]# rpm  -qa  |grep  java-1.8.0-openjdk
java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64
java-1.8.0-openjdk-headless-1.8.0.131-11.b12.el7.x86_64

[root@Va1 ~]# java -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)

[root@Va1 ~]# yum  search  elasticsearch
.................
[root@Va1 ~]# yum   -y  install  elasticsearch   ##安装非关系型数据库es
..............
[root@Va1 ~]# rpm  -qa  |grep   elasticsearch
elasticsearch-2.3.4-1.noarch

[root@Va1 elasticsearch]# systemctl   start  elasticsearch  &&  systemctl  enable  elasticsearch

[root@Va1 ~]# ls   /etc/elasticsearch/
elasticsearch.yml  logging.yml  scripts

[root@Va1 ~]# cd   /etc/elasticsearch/

在所有节点修改配置文件 /etc/elasticsearch/elasticsearch.yml 

[root@Va1 elasticsearch]# vim   elasticsearch.yml 

 17 cluster.name: elk-cluster # 设置集群名称{elasticsearch服务器识别集群的唯一方式}

 23 node.name: Va1  # 节点名称,可自动生成也可手动配置(本主机名 /etc/hosts解析域名).
# [root@Va1 ~]# cat  /etc/hostname 
Va1

 50 # ---------------------------------- Network -----------------------------------
    # 设置绑定的ip地址,可以是ipv4或ipv6的,默认为0.0.0.0 
 51 network.bind_host: 192.168.0.11

 52 # Set the bind address to a specific IP (IPv4 or IPv6):
  # 设置其它节点和该节点交互的ip地址,如果不设置它会自动设置,值必须是个真实的ip地址 
 53 network.publish_host: 192.168.0.11

 # # 同时设置bind_host和publish_host上面两个参数 
 54 network.host: 192.168.0.11  # 绑定监听IP特定的网络地址

 # 设置节点间交互的tcp端口,默认是9300 
 55 transport.tcp.port: 9300

 56 # Set a custom port for HTTP:
 57 #
# # 设置对外服务的http端口,默认为9200 
 58 http.port: 9200

# 这是一个集群中的主节点的初始列表,当节点(主节点或者数据节点)启动时使用这个列表进行探测 
 68 discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

[root@Va1 ~]# egrep   -nv  "^#|^$"   /etc/elasticsearch/elasticsearch.yml
17:cluster.name: elk-cluster  # 设置集群名称{elasticsearch服务器识别集群的唯一方式}
23:node.name: Va1
51:network.bind_host: 192.168.0.11
53:network.publish_host: 192.168.0.11
54:network.host: 192.168.0.11
55:transport.tcp.port: 9300
58:http.port: 9200
68:discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

[root@Va1 ~]# systemctl   restart   elasticsearch

[root@Va1 ~]# elinks  -dump  192.168.0.11:9200
   { "name" : "Va1", "cluster_name" : "elk-cluster", "version" : { "number" :
   "2.3.4", "build_hash" : "e455fd0c13dceca8dbbdbb1665d068ae55dabe3f",
   "build_timestamp" : "2016-06-30T11:24:31Z", "build_snapshot" : false,
   "lucene_version" : "5.5.0" }, "tagline" : "You Know, for Search" }

[root@Va1 ~]# ansible app  -m  authorized_key  -a  "user=root  exclusive=true  \
manage_dir=true  key='$(< /root/.ssh/id_rsa.pub)'"  -k 
SSH password: 1
.........
Va2 | SUCCESS => {
..............

[root@Va1 ~]# vim  hosts.yml
[root@Va1 ~]# cat  hosts.yml
---
- hosts: app
  remote_user: root
  tasks:
    - copy:
        src: /etc/hosts
        dest: /etc/hosts
        owner: root
        group: root
        mode: 0644
    - copy:
        src: /etc/yum.repos.d/local.repo
        dest: /etc/yum.repos.d/local.repo
        owner: root
        group: root
        mode: 0644

[root@Va1 ~]# ansible-playbook  -i  /etc/ansible/hosts   hosts.yml
......................
[root@Va1 ~]# vim   hosts
[root@Va1 ~]# cat   hosts
[elas]
Va[2:5]

[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m  shell   -a  "yum clean all >/dev/null && yum repolist  |tail   -4"

[root@Va1 ~]# vim  setelk.yaml
[root@Va1 ~]# cat  setelk.yaml
---
- hosts: elas
  remote_user: root
  tasks:
    - yum:
        name: java-1.8.0-openjdk,elasticsearch
        state: latest
    - service:
        name: elasticsearch
        enabled: yes

[root@Va1 ~]# ansible-playbook  -i  /root/hosts  setelk.yaml  #剧本批量安装软件

[root@Va1 ~]# ansible elas -i /root/hosts -m shell -a "rpm -q  elasticsearch"

                        ## 在覆盖之前将原文件备份，备份文件包含时间信息 backup=yes

[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m copy  -a "src=/etc/elasticsearch/elasticsearch.yml dest=/etc/elasticsearch/ owner=root group=root  mode=0644  backup=no"  ##backup备份no  批量修改es数据库配置文件

[root@Va1 ~]# ansible elas  -i  /root/hosts -m  shell  -a  'sed  -i  "s/^\(node.name:\).*/\1 ${HOSTNAME}/"  /etc/elasticsearch/elasticsearch.yml'  ##修改es数据库配置文件节点名称

[root@Va1 ~]# cat  /root/hosts
[elas]
Va[2:5]
[root@Va1 ~]# vim  ip.yaml
[root@Va1 ~]# cat  ip.yaml
---
- hosts: elas
  remote_user: root
  tasks:
    - shell: sed  -i "s/192.168.0.1.*/$(ifconfig eth0 |awk '/inet /{print $2}')/"  /etc/elasticsearch/elasticsearch.yml     # 注意这是一行

[root@Va1 ~]# ansible-playbook -i  /root/hosts  ip.yaml  ##使用剧本修改es配置文件ip地址

[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m  shell  -a "systemctl restart elasticsearch"         
                   #批量重启动 非关系型数据库elasticsearch 服务

      # ## "number_of_data_nodes" : 5,注意是5个节点 # 启动验证 集群状态 成功

[root@Va1 ~]# elinks  -dump   192.168.0.11:9200/_cluster/health?pretty  # 启动验证成功
[root@Va1 ~]# elinks  -dump   192.168.0.11:9200/_cluster/health?pretty

   { "cluster_name" : "elk-cluster", "status" : "green", "timed_out" : false,
   "number_of_nodes" : 5, "number_of_data_nodes" : 5, "active_primary_shards"
   : 0, "active_shards" : 0, "relocating_shards" : 0, "initializing_shards" :
   0, "unassigned_shards" : 0, "delayed_unassigned_shards" : 0,
   "number_of_pending_tasks" : 0, "number_of_in_flight_fetch" : 0,
   "task_max_waiting_in_queue_millis" : 0, "active_shards_percent_as_number"
   : 100.0 }

http://192.168.0.11:9200/_cluster/health?pretty  # 启动验证成功
{
  "cluster_name" : "elk-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 5,  # ## 注意是5个节点
  "number_of_data_nodes" : 5,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}

正常情况下，集群得健康状态分为三种：
green 
最健康得状态，说明所有的分片包括备份都可用
yellow 
基本的分片可用，但是备份不可用（或者是没有备份）
red 
部分的分片可用，表明分片有一部分损坏。此时执行查询部分数据仍然可以查到，遇到这种情况，还是赶快解决比较好

[root@Va1 ~]# egrep   -nv  "^#|^$"   /etc/elasticsearch/elasticsearch.yml
17:cluster.name: elk-cluster
23:node.name: Va1
   ## 注意也可以这样写节点名  node.name: {{ansible_hostname}}

51:network.bind_host: 192.168.0.11
53:network.publish_host: 192.168.0.11
54:network.host: 192.168.0.11
55:transport.tcp.port: 9300
58:http.port: 9200
68:discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

/**********************************************
[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m  setup  |grep  hostname
        "ansible_hostname": "Va2", 
.........................
[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m setup  -a  "filter=ansible_hostname"
Va5 | SUCCESS => {
    "ansible_facts": {
        "ansible_hostname": "Va5"
    }, 
    "changed": false
................
[root@Va1 ~]# vim  test.yml
[root@Va1 ~]# cat  test.yml   #ansible的template模块可以传递 模块setup中的 变量
node.name: {{ansible_hostname}}

[root@Va1 ~]# vim  template.yml
[root@Va1 ~]# cat  template.yml
---
- hosts: elas
  remote_user: root
  tasks:
    - template:  # template模块可以从主机信息模块setup中提取变量来替换src: test.yml文件中的变量
        src: /root/test.yml
        dest: /root/test.yml
        owner: root
        group: root
        mode: 0644
[root@Va1 ~]# cat  /root/hosts
[elas]
Va[2:5]

[root@Va1 ~]# ansible-playbook    -i /root/hosts  template.yml
..............
[root@Va2 ~]# cat  test.yml 
node.name: Va2
[root@Va3 ~]# cat  test.yml 
node.name: Va3
[root@Va1 ~]# cat  /root/test.yml    #ansible的template模块可以传递 模块setup中的 变量
node.name: {{ansible_hostname}}
**************************/

pretty  英 [ˈprɪti]   美 [ˈprɪti]  
adj. 漂亮的;机灵的，聪明的
adv. 相当，颇
n. 漂亮的人（或东西）

[root@Va1 ~]# curl http://192.168.0.11:9200/_cluster/health?pretty  # 启动验证成功
{
  "cluster_name" : "elk-cluster",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 5,
  "number_of_data_nodes" : 5,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}


标准Http协议支持六种请求方法，即：
1、GET  发送一个请求来取得服务器上的某一资源

2、POST 向服务器发送数据,数据存放位置由服务器自己决定

3、PUT  向服务器发送数据,指定了数据资源的在服务器中存放的位置

4、Delete 删除服务器中的某一个资源

5、HEAD  发送一个请求,不含有呈现数据，仅含有HTTP头信息

6、Options 用于获取当前URL所支持的方法,若请求成功，则会在HTTP头中包含一个名为“Allow”的头，
             值是所支持的方法，如“GET, POST”。

HTTP报文格式 HTTP报文分为两类:
请求报文request, 响应报文response 

1，请求行
由3部分组成，分别为：请求方法、URL（见备注1）以及协议版本，之间由空格分隔

http请求方法（GET、POST、HEAD、OPTIONS、PUT、DELETE、TRACE、CONNECT）

HTTP/1.0  单次连接(不常用)
HTTP的1.0版本中只有三种请求方法： GET, POST 和 HEAD方法。

GET 
请求指定的页面信息，并返回实体主体。
GET请求请提交的数据放置在HTTP请求协议头中，
GET方法通过URL请求来传递用户的输入，
GET方式的提交你需要用Request.QueryString来取得变量的值。
GET方法提交数据，可能会带来安全性的问题，数据被浏览器缓存。
GET请求有长度限制。

DELETE
请求服务器删除指定的页面。
DELETE请求一般返回3种码
200（OK）——删除成功，同时返回已经删除的资源。
202（Accepted）——删除请求已经接受，但没有被立即执行（资源也许已经被转移到了待删除区域）。
204（No Content）——删除请求已经被执行，但是没有返回资源（也许是请求删除不存在的资源造成的）。

CONNECT
HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。

OPTIONS
允许客户端查看服务器的性能。

TRACE
回显服务器收到的请求，主要用于测试或诊断。

HTTP/1.1  多次连接
到了1.1版本时，新增加了五种请求方法：OPTIONS, PUT, DELETE, TRACE 和 CONNECT 方法。

请求行 由3部分组成，分别为：
请求方法、URL（见备注1）以及协议版本，之间由空格分隔

  GET   /index.html     HTTP/1.1           \r\n
请求方法   Request-URI     协议/主版本号.次版本号  分隔符

HTTP报文格式 HTTP报文分为两类:
请求报文request, 响应报文response 

URI：统一资源标识符，用来唯一的标识一个资源。
URI一般由三部分组成：
(1)访问资源的命名机制；
(2)存放资源的主机名；
(3)资源自身的名称，由路径表示，着重强调于资源。

URL由三部分组成：
(1)协议(或称为服务方式)；
(2)存有该资源的主机IP地址(有时也包括端口号)；
(3)主机资源的具体地址。如目录或文件名等。

显示头信息
curl -I http://www.baidu.com

概念
1. 配置文件
config/elasticsearch.yml   主配置文件
config/jvm.options         jvm参数配置文件
cofnig/log4j2.properties   日志配置文件

2. 基本概念
接近实时（NRT）
Elasticsearch 是一个接近实时的搜索平台。
这意味着，从索引一个文档直到这个文档能够被搜索到有一个很小的延迟（通常是 1 秒）。
集群（cluster）

代表一个集群，集群中有多个节点（node），
其中有一个为主节点，这个主节点是可以通过选举产生的，
主从节点是对于集群内部来说的。
es的一个概念就是去中心化，
字面上理解就是无中心节点，这是对于集群外部来说的，
因为从外部来看es集群，在逻辑上是个整体，
你与任何一个节点的通信和与整个es集群通信是等价的。

索引（index）
ElasticSearch将它的数据存储在一个或多个索引（index）中。
用SQL领域的术语来类比，索引就像数据库，
可以向索引写入文档或者从索引中读取文档，
并通过ElasticSearch内部使用Lucene将数据写入索引或从索引中检索数据。

文档（document）
文档（document）是ElasticSearch中的主要实体。
对所有使用ElasticSearch的案例来说，他们最终都可以归结为对文档的搜索。文档由字段构成。

映射（mapping）
所有文档写进索引之前都会先进行分析，
如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做映射（mapping）。
一般由用户自己定义规则。

类型（type）
每个文档都有与之对应的类型（type）定义。
这允许用户在一个索引中存储多种文档类型，并为不同文档提供类型提供不同的映射。

shard  英 [ʃɑ:d]   美 [ʃɑ:rd]  
n. （玻璃、金属或其他硬物的）尖利的碎片

分片（shards）
代表索引分片，es可以把一个完整的索引分成多个分片，
这样的好处是可以把一个大的索引拆分成多个，
分布到不同的节点上。

构成分布式搜索。
分片的数量只能在索引创建前指定，并且索引创建后不能更改。
5.X默认不能通过配置文件定义分片

curl 常用参数介绍：
-A 修改请求 agent
-X 设置请求方法
-I 显示返回头信息 (响应头支持网页跳转)
-I 参数则是只显示http response的头信息
-i 参数可以显示http response的头信息，连同网页代码一起
显示通信过程
 -v 参数可以显示一次http通信的整个过程，包括端口连接和http request头信息

ES常用：
PUT --增
DELETE --删
POST --改
GET --查

 使用 -L 跟随链接重定向 
6. 使用 -A 自定义 User-Agent 
7. 使用 -H 自定义 header 
8. 使用 -c 保存 Cookie 
9. 使用 -b 读取 Cookie 
10. 使用 -d 发送 POST 请求

-X 指定请求方式
http://www.ruanyifeng.com/blog/2011/09/curl.html

curl 发送json格式数据 请求
curl -H "Content-Type: application/json" -X POST  --data '{"userID":10001}' http://localhost:8085/GetUserInfo

curl 发送json参数
curl -i -X POST -H 'Content-type':'application/json' -d {\&quot;a\&quot;:\&quot;abcd\&quot;} http://127.0.0.1:28005/  

http: 超文本传输协议，同级别的是ftp、smt/pop3
curl: 命令行http client（构造http请求，获得http应答），同级别的是ftp-client、mail-client
json：数据格式，同级别的是html、xml
通常json是承载在http之上的。


curl 发送json参数
curl -i -X POST -H 'Content-type':'application/json' -d {\&quot;a\&quot;:\&quot;abcd\&quot;} http://127.0.0.1:28005/  
..........
http: 超文本传输协议，同级别的是ftp、smt/pop3
curl: 命令行http client（构造http请求，获得http应答），同级别的是ftp-client、mail-client
json：数据格式，同级别的是html、xml
通常json是承载在http之上的。
GET请求

curl -X GET http://localhost:8080/search?data=123  # -X GET是可选的

POST请求
curl -X POST -d  file.txt   http://localhost:8080/search -v
curl -X POST -d "data=123&key=456" http://localhost:8080/search -v 

由于-d选项为使用POST方式向server发送数据，
因此在使用-d的时候，可以省略-X POST。
使用-d时，将使用Content-type:application/x-www-form-urlencoded方式发送数据。

如果想使用JSON形式post数据，可以使用-H指定头部类型
curl -H "Content-Type:application/json" -d '{"data":"123","key":"456"}' http://localhost:8080/search -v

如果想在请求的时候带上Cookie，可以这样
curl -H "Cookie:username=XXX" {URL}

使用 -A 自定义 User-Agent
我们可以使用 -A 来自定义用户代理，例如下面的命令将伪装成安卓火狐浏览器对网页进行请求： 
curl -A “Mozilla/5.0 (Android; Mobile; rv:35.0) Gecko/35.0 Firefox/35.0” http://www.baidu.com 

[root@Va1 ~]# curl  -i  http://www.ip138.com/  # 显示http response的头信息，连同网页代码
............
[root@Va1 ~]# curl  -I  http://www.taobao.com/ #显示返回头信息 (响应头支持网页跳转)
HTTP/1.1 302 Found
Server: Tengine
Date: Wed, 16 Jan 2019 11:26:09 GMT
Content-Type: text/html
Content-Length: 258
Connection: keep-alive
Location: https://www.taobao.com/
Set-Cookie: thw=cn; Path=/; Domain=.taobao.com; Expires=Thu, 16-Jan-20 11:26:09 GMT;
Strict-Transport-Security: max-age=31536000

-X 设置请求方法
      curl  -i  -X  HEAD  发送一个请求,不含有呈现数据，仅含有HTTP头信息
[root@Va1 ~]# curl  -i  -X HEAD  http://www.taobao.com/ 
HTTP/1.1 302 Found
Server: Tengine
Date: Wed, 16 Jan 2019 11:31:06 GMT
Content-Type: text/html
Content-Length: 258
Connection: keep-alive
Location: https://www.taobao.com/
Set-Cookie: thw=cn; Path=/; Domain=.taobao.com; Expires=Thu, 16-Jan-20 11:31:06 GMT;
Strict-Transport-Security: max-age=31536000
^C
[root@Va1 ~]# 

 关系型    --------  非关系型
MySQL    ?--?  NoSQL
Database ---->   Index
Table    ---->   Type
Row      ---->   Document
Column   ---->   Filed

ELK组成：
    - E：是指Elasticsearch [非关系型数据库,最重要]，完成数据的存储和检索
    - L：是Logstash[可使用 docker 容器技术,数据次重要]，完成数据的采集、过滤及解析
    - K：Kibana [与 apache 作用相同 ] ，以WEB方式展示 

Linux  apache    mysql[关系型]       php[处理后台程序]
L        A         M                  P
L        K         E                  L
Linux  kibana elasticsearch[非关系型] logstash[处理日志的工作[ java开发的 ]]

 filebeat-1.2.3-x86_64.rpm

 kibana-4.5.2-1.x86_64.rpm
 logstash-2.3.4-1.noarch.rpm
 elasticsearch-2.3.4.rpm

ELK5.1.2+centos 7.4 安装配置

http://www.sohu.com/a/191293473_255462

ES与数据库同步工具——ElasticSearch-JDBC

ES内容管理工具——head
http://127.0.0.1:9200/_plugin/head/

ES服务器监控工具——bigdesk
http://127.0.0.1:9200/_plugin/bigdesk

ES集群操作的API工具——Kopf
http://127.0.0.1:9200/_plugin/kopf/

# 插件只能在单一的节点查看,使用

1. hq 监控，管理elasticsearch集群以及通过web界面来进行查询操作 

2. analysis-ik ik分词器，中文分词 

3. bigdesk 统计分析和图表化elasticsearch集群状态信息 [ cpu 内存信息  ]

4. head 最实用的通过web界面来查看elasticsearch集群状态信息 

5. inquisitor 一个帮助调试查询语句细节的工具 

6. marvel 超赞的一个通过json查询的工具,可惜是收费项目,非开源 

7. sql 一款国人写的通过类似sql语法进行查询的工具 

8. kopf 一个通过web界面来管理和监控elasticsearch集群状态信息 

elasticsearch-head是一个界面化的集群操作和管理工具，可以对集群进行傻瓜式操作。你可以通过插件把它集成到es（首选方式）,也可以安装成一个独立webapp。

es-head主要有三个方面的操作：

显示集群的拓扑,
并且能够执行索引和节点级别操作
搜索接口
能够查询集群中原始json或表格格式的检索数据
能够快速访问并显示集群的状态
有一个输入窗口,
允许任意调用RESTful API。
这个接口包含几个选项,可以组合在一起以产生有趣的结果;

curl 发送json格式数据 请求
curl -H "Content-Type: application/json" -X POST  --data '{"userID":10001}' http://localhost:8085/GetUserInfo

1. 请求方法(get、put、post、delete),查询json数据,节点和路径

2. 支持JSON验证器

3. 支持重复请求计时器

4. 支持使用javascript表达式变换结果

５. 收集结果的能力随着时间的推移(使用定时器),或比较的结果

6. 能力图表转换后的结果在一个简单的条形图(包括时间序列)

官方的文档：
https://github.com/mobz/elasticsearch-head

 filebeat-1.2.3-x86_64.rpm
 kibana-4.5.2-1.x86_64.rpm
 logstash-2.3.4-1.noarch.rpm
 elasticsearch-2.3.4.rpm

[root@room9pc01 ~]# ls /var/ftp/elk/
accounts.json.gz    elasticsearch-head-master.zip  shakespeare.json.gz
alog.gz             elasticsearch-kopf-master.zip
bigdesk-master.zip  logs.jsonl.gz

[root@Va1 ~]# mkdir elk
[root@Va1 ~]# ls  elk/
[root@Va1 ~]# lftp  192.168.0.254
lftp 192.168.0.254:~> ls  elk/
-rw-r--r--    1 0        0           57105 Mar 05  2014 accounts.json.gz
-rw-r--r--    1 0        0           82792 Jul 11  2017 alog.gz
-rw-r--r--    1 0        0          274341 Jul 04  2017 bigdesk-master.zip
-rw-r--r--    1 0        0          899857 Jul 04  2017 elasticsearch-head-master.zip
-rw-r--r--    1 0        0         2228148 Jul 04  2017 elasticsearch-kopf-master.zip
-rw-r--r--    1 0        0         8705693 Jul 04  2017 logs.jsonl.gz
-rw-r--r--    1 0        0         3597121 Jul 04  2017 shakespeare.json.gz
lftp 192.168.0.254:/> lcd  /root/elk/   ##设置本地存放目录
lcd 成功, 本地目录=/root/elk

lftp 192.168.0.254:/> mget elk/*  ##批量下载所有 文件
15845057 bytes transferred                                         
Total 7 files transferred
共传输7个文件
lftp 192.168.0.254:/> quit

[root@Va1 ~]# ls  elk/
accounts.json.gz    elasticsearch-head-master.zip  shakespeare.json.gz
alog.gz             elasticsearch-kopf-master.zip
bigdesk-master.zip  logs.jsonl.gz

 bigdesk 统计分析和图表化elasticsearch集群状态信息 [ cpu 内存信息]

 head 最实用的通过web界面来查看elasticsearch集群状态信息 

 kopf 一个通过web界面来管理和监控elasticsearch集群状态信息 

ES服务器监控工具——bigdesk
http://127.0.0.1:9200/_plugin/bigdesk
http://192.168.0.15:9200/_plugin/bigdesk/#nodes

ES内容管理工具——head
http://127.0.0.1:9200/_plugin/head/
http://192.168.0.15:9200/_plugin/head/

ES集群操作的API工具——Kopf
http://127.0.0.1:9200/_plugin/kopf/
http://192.168.0.15:9200/_plugin/kopf/#!/cluster

http://192.168.0.11:9200/_cluster/health?pretty  ##检查集群状态
正常情况下，集群得健康状态分为三种：
green 
最健康得状态，说明所有的分片包括备份都可用
yellow 
基本的分片可用，但是备份不可用（或者是没有备份）
red 
部分的分片可用，表明分片有一部分损坏。此时执行查询部分数据仍然可以查到

elasticsearch 
只有主数据库有写入权限,从数据库只读权限,
但是客户端的感觉是 所有 主 从 数据库 都是可读可写,
原因 [ 从数据库 把客户端的写请求 转发 给 主数据库,然后所有服务器同步更新数据 ]

REST  
REpresentational State Transfer
表现层 状态 迁移
一种最好理解的说法是，
URL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作

REST描述的是在网络中client和server的一种交互形式；
REST本身不实用，
实用的是如何设计 RESTful API（REST风格的网络接口）。

Elasticsearch的一个很大的优势是支持多种语言，
比如有Java API，.Net API等等，
最重要的是它还支持使用RESTful API。

RESTful是统一规范的http接口，任何语言都可以使用

restful接口常用的方式是get,put和post

Elasticsearch扩展性非常好，有很多官方和第三方开发的插件，
常用的有 
分词插件, 同步插件, 数据传输插件, 脚本支持插件, 站点插件 等 其它插件


[root@Va1 ~]# curl  http://192.168.0.15:9200/_cat
=^.^=
/_cat/allocation
/_cat/shards
/_cat/shards/{index}
/_cat/master
/_cat/nodes
/_cat/indices
/_cat/indices/{index}
/_cat/segments
/_cat/segments/{index}
/_cat/count
/_cat/count/{index}
/_cat/recovery
/_cat/recovery/{index}
/_cat/health
/_cat/pending_tasks
/_cat/aliases
/_cat/aliases/{alias}
/_cat/thread_pool
/_cat/plugins
/_cat/fielddata
/_cat/fielddata/{fields}
/_cat/nodeattrs
/_cat/repositories
/_cat/snapshots/{repository}
[root@Va1 ~]# curl  http://192.168.0.15:9200/_cat/health
1547716543 17:15:43 elk-cluster green 5 5 10 5 0 0 0 0 - 100.0% 

[root@Va1 ~]# curl  http://192.168.0.15:9200/_cat/plugins
Va5 bigdesk master s /_plugin/bigdesk/ 

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/plugins
Va5 bigdesk master s /_plugin/bigdesk/ 

[root@Va5 ~]# /usr/share/elasticsearch/bin/plugin  list
Installed plugins in /usr/share/elasticsearch/plugins:
    - bigdesk
    - head
    - kopf
[root@Va5 ~]# ls  /usr/share/elasticsearch/plugins/
bigdesk  head  kopf

[root@Va5 ~]# curl  http://192.168.0.15:9200/_cat/plugins
Va5 bigdesk master s /_plugin/bigdesk/ 

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/nodes
192.168.0.14 192.168.0.14  9 47 0.00 d m Va4 
192.168.0.11 192.168.0.11  4 36 0.07 d * Va1  ##注意带 星* 号的是elasticsearch 主数据库
192.168.0.12 192.168.0.12  9 47 0.00 d m Va2 
192.168.0.15 192.168.0.15 12 58 0.00 d m Va5 
192.168.0.13 192.168.0.13  9 47 0.00 d m Va3 

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/nodes?v
host         ip           heap.percent ram.percent load node.role master name 
192.168.0.14 192.168.0.14            9          47 0.00 d         m      Va4  
192.168.0.11 192.168.0.11            4          37 0.04 d         *      Va1  
192.168.0.12 192.168.0.12            9          47 0.00 d         m      Va2  
192.168.0.15 192.168.0.15           13          58 0.00 d         m      Va5  
192.168.0.13 192.168.0.13            9          47 0.00 d         m      Va3  

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/nodes?help
id       | id,nodeId    | unique node id
pid      | p            | process id 
host     | h            | host name
ip       | i            | ip address
port     | po           | bound transport port
.............................
cpu      | cpu          | recent cpu usage               
load     | l            | most recent load avg  
uptime   | u            | node uptime  
node.role| r,role,dc,nodeRole   | d:data node, c:client node 
master   | m            | m:master-eligible, *:current master    
name     | n            | node name  
.................

primary 首要的，主要的;主数据库
replica 复制品,从数据库
prirep  是主primary 从replica 的缩写合称

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/shards?v  ##查看所有分片信息

index    shard prirep state   docs store ip           node 
shujuku1 1     p      STARTED    0  159b 192.168.0.11 Va1  
shujuku1 1     r      STARTED    0  159b 192.168.0.13 Va3  
shujuku1 2     p      STARTED    0  159b 192.168.0.13 Va3  
shujuku1 2     r      STARTED    0  159b 192.168.0.12 Va2  
shujuku1 4     r      STARTED    0  159b 192.168.0.14 Va4  
shujuku1 4     p      STARTED    0  159b 192.168.0.15 Va5  
shujuku1 3     p      STARTED    0  159b 192.168.0.12 Va2  
shujuku1 3     r      STARTED    0  159b 192.168.0.15 Va5  
shujuku1 0     p      STARTED    0  159b 192.168.0.14 Va4  
shujuku1 0     r      STARTED    0  159b 192.168.0.11 Va1  

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/master?v ##查看主数据库节点信息
id                     host         ip           node 
-DE8yQS-Qr22QoG7Q4Y8_Q 192.168.0.11 192.168.0.11 Va1  

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/indices?v ##查看所有的数据库
health status index    pri rep docs.count docs.deleted store.size pri.store.size
green  open   shujuku1   5   1          0            0      1.5kb           795b

集群状态 索引属性查询
http://192.168.0.15:9200/_cat

创建索引{相当于mysql的数据库}
curl  -X POST http://192.168.0.11:9200/sjku/  -d '
{"settings":{
  "index":{
   "number_of_shards":5,"number_of_replicas":1   
  }
 }
}'  # 注意 单引号 '{}' 成对
                             ## 创建index数据库 sjku
[root@Va1 ~]# curl  -X POST http://192.168.0.11:9200/sjku/  -d '
> {"settings":{
>   "index":{
>    "number_of_shards":5,"number_of_replicas":1   
>   }
>  }
> }' 
{"acknowledged":true}[root@Va1 ~]# 
[root@Va1 ~]# curl   http://192.168.0.11:9200/_cat/indices?v  ##查看所有的数据库

health status index    pri rep docs.count docs.deleted store.size pri.store.size 
green  open   sjku       5   1          0            0      1.2kb           650b 
green  open   shujuku1   5   1          0            0      1.5kb           795b 

primary 首要的，主要的;主数据库
replica 复制品,从数据库
prirep  是主primary 从replica 的缩写合称

[root@Va1 ~]# curl   http://192.168.0.11:9200/_cat/shards?v   ##查看所有分片信息

index    shard prirep state   docs store ip           node 
sjku     1     p      STARTED    0  130b 192.168.0.11 Va1  
sjku     1     r      STARTED    0  130b 192.168.0.13 Va3  
sjku     2     p      STARTED    0  130b 192.168.0.13 Va3  
sjku     2     r      STARTED    0  130b 192.168.0.12 Va2  
sjku     4     r      STARTED    0  130b 192.168.0.14 Va4  
sjku     4     p      STARTED    0  130b 192.168.0.15 Va5  
sjku     3     p      STARTED    0  130b 192.168.0.12 Va2  
sjku     3     r      STARTED    0  130b 192.168.0.15 Va5  
sjku     0     p      STARTED    0  130b 192.168.0.14 Va4  
sjku     0     r      STARTED    0  130b 192.168.0.11 Va1  
shujuku1 1     p      STARTED    0  159b 192.168.0.11 Va1  
shujuku1 1     r      STARTED    0  159b 192.168.0.13 Va3  
shujuku1 2     p      STARTED    0  159b 192.168.0.13 Va3  
shujuku1 2     r      STARTED    0  159b 192.168.0.12 Va2  
shujuku1 4     r      STARTED    0  159b 192.168.0.14 Va4  
shujuku1 4     p      STARTED    0  159b 192.168.0.15 Va5  
shujuku1 3     p      STARTED    0  159b 192.168.0.12 Va2  
shujuku1 3     r      STARTED    0  159b 192.168.0.15 Va5  
shujuku1 0     p      STARTED    0  159b 192.168.0.14 Va4  
shujuku1 0     r      STARTED    0  159b 192.168.0.11 Va1  

[root@Va1 ~]# 
curl 常用参数介绍：
-A 修改请求 agent
-X 设置请求方法
-I 显示返回头信息 (响应头支持网页跳转)
-I 参数则是只显示http response的头信息
-i 参数可以显示http response的头信息，连同网页代码一起
显示通信过程
 -v 参数可以显示一次http通信的整个过程，包括端口连接和http request头信息
ES常用：
PUT --增
DELETE --删
POST --改
GET --查

 使用 -L 跟随链接重定向 
6. 使用 -A 自定义 User-Agent 
7. 使用 -H 自定义 header 
8. 使用 -c 保存 Cookie 
9. 使用 -b 读取 Cookie 
10. 使用 -d 发送 POST 请求

-X 指定请求方式
http://www.ruanyifeng.com/blog/2011/09/curl.html

curl 发送json格式数据 请求
curl -H "Content-Type: application/json" -X POST  --data '{"userID":10001}' http://localhost:8085/GetUserInfo

                             ## 创建index数据库 sjku
[root@Va1 ~]# curl  -X POST http://192.168.0.11:9200/sjku/  -d '
> {"settings":{
>   "index":{
>    "number_of_shards":5,"number_of_replicas":1   
>   }
>  }
> }'            # 注意 单引号 '{}' 成对
{"acknowledged":true}[root@Va1 ~]# 

[root@Va1 ~]# curl   http://192.168.0.11:9200/_cat/indices?v  ##查看所有的数据库

health status index    pri rep docs.count docs.deleted store.size pri.store.size 
green  open   sjku       5   1          0            0      1.2kb           650b 
green  open   shujuku1   5   1          0            0      1.5kb           795b 

关系型     --------  非关系型
MySQL    ?--?  NoSQL
Database ---->   Index
Table    ---->   Type
Row      ---->   Document
Column   ---->   Field

/***********
No handler found for uri [/sjku/btable/] and method [PUT]
找不到uri[/sjku/btable/]和方法[put]的处理程序
****************/
                注意  es 使用 PUT --增加数据
                注意这里的字段有不同的名字"key键":"value值" ,  "key2":"value2" ,id 值对应 1 和 3
               ##注意必须加 数字id号 /sjku/btable/1

[root@Va1 ~]# curl  -XPUT  http://192.168.0.11:9200/sjku/btable/1  -d  '{"key键":"value值","name":"nb","sex":"man","hobby":"playmusic","age":36}'  

{"_index":"sjku","_type":"btable","_id":"1","_version":1,"_shards":{"total":2,"successful":2,"failed":0},"created":true}[root@Va1 ~]# 

[root@Va1 ~]# 
        #  PUT  向服务器发送数据,指定了数据资源的在服务器中存放的位置
         # 使用 -H 自定义 header  -X 指定请求方式

      注意空格 Content-Type: application/必须有一个空格,  es 使用 PUT --增加数据
    注意这里的字段有不同的名字"key键":"value值" ,  "key2":"value2" ,id 值对应 1 和 3
               
[root@Va1 ~]# curl -H  "Content-Type: application/json" -XPUT  http://192.168.0.11:9200/sjku/btable/3  -d  '{"key2":"value2","name":"prettylily","sex":"girl","hobby":"playmusic","age":26}'

{"_index":"sjku","_type":"btable","_id":"3","_version":1,"_shards":{"total":2,"successful":2,"failed":0},"created":true}[root@Va1 ~]# 

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/indices?v  # 查看所有数据库
health status index    pri rep docs.count docs.deleted store.size pri.store.size 
green  open   sjku       5   1          2            0     16.5kb          8.2kb 
green  open   shujuku1   5   1          0            0      1.5kb           795b 

ES常用：
PUT --增
DELETE --删
POST --改
GET --查

curl -H  "Content-Type: application/json" -X POST  http://192.168.0.11:9200/sjku/btable/3  -d  '{"key2":"Vv",
"name":"prettylily",
"sex":"girl",
"hobby":"music",
"age":16}'
            # POST 向服务器发送数据,数据存放位置由服务器自己决定
             #  # 使用 -H 自定义 header  -X 指定请求方式
   ## id 值对应  3    es 使用 POST --修改数据  注意这里btable/3后面没有加 _update,则是新数据覆盖所有旧数据

[root@Va1 ~]# curl -H  "Content-Type: application/json" -X POST  http://192.168.0.11:9200/sjku/btable/3  -d  '{"key2":"Vv",
> "name":"prettylily",
> "sex":"girl",
> "hobby":"music",
> "age":16}'

{"_index":"sjku","_type":"btable","_id":"3","_version":2,"_shards":{"total":2,"successful":2,"failed":0},"created":false}[root@Va1 ~]# 

                  # POST 向服务器发送数据,数据存放位置由服务器自己决定
             #  # 使用 -H 自定义 header  -X 指定请求方式
  ## id 值对应 1   es使用 POST --修改数据 ,注意这里btable/1后面没有加 _update,则是新数据覆盖所有旧数据

[root@Va1 ~]# curl  -XPOST  http://192.168.0.11:9200/sjku/btable/1  -d  '{"key键":"属性值","name":"nb","sex":"man","hobby":"playmusic","age":37}'  

{"_index":"sjku","_type":"btable","_id":"1","_version":2,"_shards":{"total":2,"successful":2,"failed":0},"created":false}[root@Va1 ~]# 

           # POST 向服务器发送数据,数据存放位置由服务器自己决定
             #  # 使用 -H 自定义 header  -X 指定请求方式
   ## id 值对应  3    es 使用 POST --修改数据  
          注意这里btable/3后面加了 _update,
          则是新数据 覆盖 特定的 要修改的  旧数据 sjku/btable/3/_update 
         ## 注意新加的 json 数据中有关键字 {"doc":{"":""}}

[root@Va1 ~]# curl -H  "Content-Type: application/json" -X POST  http://192.168.0.11:9200/sjku/btable/3/_update   -d  '{"doc":{"key2":"属性值2"}}'

{"_index":"sjku","_type":"btable","_id":"3","_version":3,"_shards":{"total":2,"successful":2,"failed":0}}[root@Va1 ~]# 

           # POST 向服务器发送数据,数据存放位置由服务器自己决定
   ## id 值对应  1    es 使用 POST --修改数据  
          注意这里btable/3后面加了 _update,
          则是新数据 覆盖 特定的 要修改的  旧数据 sjku/btable/1/_update 
        ## 注意新加的 json 数据中有关键字 {"doc":{"":""}}

[root@Va1 ~]#  curl  -XPOST  http://192.168.0.11:9200/sjku/btable/1/_update  -d  '{"doc":{"hobby":"play","age":27}}'  


{"_index":"sjku","_type":"btable","_id":"1","_version":3,"_shards":{"total":2,"successful":2,"failed":0}}[root@Va1 ~]# 

              # GET  发送一个请求来取得服务器上的某一资源 可以省略 -XGET 

[root@Va1 ~]# curl  -XGET  http://192.168.0.12:9200/sjku/btable/1  # es 数据库查看特定id号的数据

{"_index":"sjku","_type":"btable","_id":"1","_version":3,"found":true,"_source":{"key键":"属性值","name":"nb","sex":"man","hobby":"play","age":27}}[root@Va1 ~]# 

 # GET  发送一个请求来取得服务器上的某一资源 可以省略 -XGET # es 数据库查看特定id号的数据

[root@Va1 ~]# curl  -XGET  http://192.168.0.12:9200/sjku/btable/1?pretty # 注意"?pretty"的作用
{
  "_index" : "sjku",
  "_type" : "btable",
  "_id" : "1",
  "_version" : 3,
  "found" : true,
  "_source" : {
    "key键" : "属性值",
    "name" : "nb",
    "sex" : "man",
    "hobby" : "play",
    "age" : 27
  }
}
[root@Va1 ~]# 
       # GET  发送一个请求来取得服务器上的某一资源 可以省略 -XGET # es 数据库查看特定id号的数据

[root@Va1 ~]# curl  -XGET  http://192.168.0.12:9200/sjku/btable/3  

{"_index":"sjku","_type":"btable","_id":"3","_version":3,"found":true,"_source":{"key2":"属性值2","name":"prettylily","sex":"girl","hobby":"music","age":16}}[root@Va1 ~]# 

       # GET  发送一个请求来取得服务器上的某一资源 可以省略 -XGET # es 数据库查看特定id号的数据

[root@Va1 ~]# curl   http://192.168.0.12:9200/sjku/btable/3?pretty # 注意"?pretty"的作用
{
  "_index" : "sjku",
  "_type" : "btable",
  "_id" : "3",
  "_version" : 3,
  "found" : true,
  "_source" : {
    "key2" : "属性值2",
    "name" : "prettylily",
    "sex" : "girl",
    "hobby" : "music",
    "age" : 16
  }
}

[root@Va1 ~]# curl  http://192.168.0.11:9200/_cat/indices?v  # 查看所有数据库信息
health status index    pri rep docs.count docs.deleted store.size pri.store.size 
green  open   sjku       5   1          2            0     16.5kb          8.2kb 
green  open   shujuku1   5   1          0            0      1.5kb           795b 

关系型     --------  非关系型
MySQL    ?--?  NoSQL
Database ---->   Index
Table    ---->   Type
Row行      ---->   Document文档
Column   ---->   Field

ES常用：
PUT --增
DELETE --删
POST --改
GET --查
         #  DELETE 删除服务器中的某一个资源
    ## id 值对应  1    es 使用 DELETE --删除数据  
  #好像  es 不能直接删除 Column字段----> Field,
 但是可以通过 使用 POST --修改数据 ,注意这里的表/id值 的 后面没有加 _update,
  则是新数据覆盖所有旧数据 ,这样可以 间接删除 了指定的 列

  #好像 es 不能直接删除 Table表---->Type 类型
   ## 好像 es 目前 只能删除 Row-->Document文档 ,只能删除 index数据库

[root@Va1 ~]# curl  -X DELETE  http://192.168.0.12:9200/sjku/btable/1

{"found":true,"_index":"sjku","_type":"btable","_id":"1","_version":4,"_shards":{"total":2,"successful":2,"failed":0}}[root@Va1 ~]# 

                               ## 再次查看id号是1 的数据,不存在了"found":false
[root@Va1 ~]# curl   http://192.168.0.12:9200/sjku/btable/1  

{"_index":"sjku","_type":"btable","_id":"1","found":false}[root@Va1 ~]# 


[root@Va1 ~]# curl  -X DELETE  http://192.168.0.12:9200/shujuku1  ## 删除数据库

{"acknowledged":true}[root@Va1 ~]# 

    ##删除了一个数据库,一条文档记录, 现在只剩下一个数据库中的一条记录了

[root@Va1 ~]# curl  http://192.168.0.12:9200/_cat/indices?v # 查看所有数据库详细信息

health status index pri rep docs.count docs.deleted store.size pri.store.size 
green  open   sjku    5   1          1            0      9.1kb          4.5kb 

创建索引{相当于mysql的数据库},设置分片数 5台服务器节点,数据备份副本数 2台服务器
curl  -X POST http://192.168.0.13:9200/sjku2/  -d '
{"settings":{
  "index":{
   "number_of_shards":5,"number_of_replicas":2  
  }
 }
}'  # 注意 单引号 '{}' 成对
                             ## 创建index数据库 sjku2

[root@Va1 ~]# curl  -X POST http://192.168.0.13:9200/sjku2/  -d '
> {"settings":{
>   "index":{
>    "number_of_shards":5,"number_of_replicas":2  
>   }
>  }
> }'
{"acknowledged":true} ## # 创建index数据库 sjku2 成功

primary 首要的，主要的;主数据库
replica 复制品,从数据库
prirep  是主primary 从replica 的缩写合称

[root@Va1 ~]# curl  http://192.168.0.14:9200/_cat/indices?v # 查看所有数据库详细信息

health status index pri rep docs.count docs.deleted store.size pri.store.size 
green  open   sjku    5   1          1            0      9.1kb          4.5kb 
green  open   sjku2   5   2          0            0      1.9kb           650b 

[root@Va1 ~]# 
[root@Va4 ~]# curl  -X DELETE  http://192.168.0.15:9200/*  ## 删除 所有的数据库
{"acknowledged":true}[root@Va4 ~]# 

[root@Va4 ~]# curl  http://192.168.0.15:9200/_cat/indices?v ## 查看所有的数据库都没了

health status index pri rep docs.count docs.deleted store.size pri.store.size 

  #好像  es 不能直接删除 Column字段----> Field,
 但是可以通过 使用 POST --修改数据 ,注意这里的  表type/id值  的 后面没有加 _update,
  则是新数据覆盖所有旧数据 ,这样可以 间接删除 了指定的 列

            ##查看所有节点信息 , 注意带 星* 号的是elasticsearch 主数据库

[root@Va4 ~]# curl  http://192.168.0.15:9200/_cat/nodes?v
host         ip           heap.percent ram.percent load node.role master name 
192.168.0.14 192.168.0.14            6          48 0.00 d         m      Va4  
192.168.0.11 192.168.0.11            8          37 0.00 d         *      Va1  
192.168.0.15 192.168.0.15            7          59 0.00 d         m      Va5  
192.168.0.13 192.168.0.13            3          47 0.02 d         m      Va3  
192.168.0.12 192.168.0.12            6          48 0.08 d         m      Va2  



[root@Va1 ~]# yum  -y  install  kibana
已安装:
  kibana.x86_64 0:4.5.2-1                                                              

完毕！
[root@Va1 ~]# rpm   -q  kibana
kibana-4.5.2-1.x86_64









[root@Va2 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1476         408         863           8         203         905
Swap:          2047           0        2047

[root@Va2 ~]# egrep   -nv  "^#|^$"   /etc/elasticsearch/elasticsearch.yml
17:cluster.name: elk-cluster
23:node.name: Va2
51:network.bind_host: 192.168.0.12
53:network.publish_host: 192.168.0.12
54:network.host: 192.168.0.12
55:transport.tcp.port: 9300
58:http.port: 9200
68:discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]







[root@Va3 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1476         405         875           8         194         910
Swap:          2047           0        2047
[root@Va3 ~]# ifconfig |awk '/inet /{print $2}'
192.168.0.13
192.168.1.13
192.168.2.13
127.0.0.1
192.168.122.1
[root@Va3 ~]# egrep   -nv  "^#|^$"   /etc/elasticsearch/elasticsearch.yml
17:cluster.name: elk-cluster
23:node.name: Va3
51:network.bind_host: 192.168.0.13
53:network.publish_host: 192.168.0.13
54:network.host: 192.168.0.13
55:transport.tcp.port: 9300
58:http.port: 9200
68:discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]







[root@Va4 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1476         412         864           8         199         902
Swap:          2047           0        2047

[root@Va4 ~]# egrep   -nv  "^#|^$"   /etc/elasticsearch/elasticsearch.yml
17:cluster.name: elk-cluster
23:node.name: Va4
51:network.bind_host: 192.168.0.14
53:network.publish_host: 192.168.0.14
54:network.host: 192.168.0.14
55:transport.tcp.port: 9300
58:http.port: 9200
68:discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]




[root@Va5 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1476         386         890           8         199         929
Swap:          2047           0        2047

[root@Va5 ~]# egrep   -nv  "^#|^$"   /etc/elasticsearch/elasticsearch.yml
17:cluster.name: elk-cluster
23:node.name: Va5
51:network.bind_host: 192.168.0.15
53:network.publish_host: 192.168.0.15
54:network.host: 192.168.0.15
55:transport.tcp.port: 9300
58:http.port: 9200
68:discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

 关系型    --------  非关系型
MySQL    ?--?  NoSQL
Database ---->   Index
Table    ---->   Type
Row      ---->   Document
Column   ---->   Filed

ELK组成：
    - E：是指Elasticsearch [非关系型数据库,最重要]，完成数据的存储和检索
    - L：是Logstash[可使用 docker 容器技术,数据次重要]，完成数据的采集、过滤及解析
    - K：Kibana [与 apache 作用相同 ] ，以WEB方式展示 

Linux  apache    mysql[关系型]       php[处理后台程序]
L        A         M                  P
L        K         E                  L
Linux  kibana elasticsearch[非关系型] logstash[处理日志的工作[ java开发的 ]]

 filebeat-1.2.3-x86_64.rpm

 kibana-4.5.2-1.x86_64.rpm
 logstash-2.3.4-1.noarch.rpm
 elasticsearch-2.3.4.rpm

ELK5.1.2+centos 7.4 安装配置


[root@Va5 ~]# yum  provides  lftp
.......................
[root@Va5 ~]# yum  -y  install   lftp
.......
已安装:
  lftp.x86_64 0:4.4.8-8.el7_3.2                                                   
完毕！
[root@Va5 ~]# rpm  -q  lftp
lftp-4.4.8-8.el7_3.2.x86_64

[root@Va5 ~]# which  lftp
/usr/bin/lftp

[root@Va5 ~]# lftp  192.168.0.254
lftp 192.168.0.254:~> ls
drwxr-xr-x    8 0        0            2048 Sep 05  2017 CentOS7-1708
drwxr-xr-x    3 0        0            4096 Jan 15 09:00 ansible
drwxr-xr-x    2 0        0            4096 Jan 15 08:46 elk
............................
lftp 192.168.0.254:/> pwd
ftp://192.168.0.254/
lftp 192.168.0.254:/> cd  elk/
lftp 192.168.0.254:/elk> ls
........................
-rw-r--r--    1 0        0          274341 Jul 04  2017 bigdesk-master.zip
..................
lftp 192.168.0.254:/elk> get  bigdesk-master.zip 
274341 bytes transferred
lftp 192.168.0.254:/elk> bye 

[root@Va5 ~]# ls
anaconda-ks.cfg     initial-setup-ks.cfg  test.yml 
bigdesk-master.zip  ip.sh  ..............

[root@Va5 ~]# rpm  -ql  elasticsearch  |grep bin
/usr/share/elasticsearch/bin
/usr/share/elasticsearch/bin/elasticsearch
/usr/share/elasticsearch/bin/elasticsearch-systemd-pre-exec
/usr/share/elasticsearch/bin/elasticsearch.in.sh
/usr/share/elasticsearch/bin/plugin
 
[root@Va5 ~]# cd  /usr/share/elasticsearch/
[root@Va5 elasticsearch]# ls
bin  lib  LICENSE.txt  modules  NOTICE.txt  plugins  README.textile

[root@Va5 elasticsearch]# cd  /usr/share/elasticsearch/bin/
[root@Va5 bin]# ls
elasticsearch  elasticsearch.in.sh  elasticsearch-systemd-pre-exec  plugin

[root@Va5 bin]# ll   /usr/share/elasticsearch/bin/plugin 
-rwxr-xr-x 1 root root 3048 6月  30 2016 /usr/share/elasticsearch/bin/plugin

[root@Va5 bin]# file  /usr/share/elasticsearch/bin/plugin
/usr/share/elasticsearch/bin/plugin: POSIX shell script, ASCII text executable

[root@Va5 bin]# ./plugin   --help |grep  -i  "commands"
COMMANDS
    [*] For usage help on specific commands please type "plugin <command> -h"

[root@Va5 bin]# ./plugin   --help |grep  -A6  "COMMANDS"
COMMANDS

    install    Install a plugin

    remove     Remove a plugin

    list       List installed plugins

[root@Va5 bin]# ./plugin  list         ## 查看所有插件
Installed plugins in /usr/share/elasticsearch/plugins:
    - No plugin detected

[root@Va5 bin]# ./plugin  install  --help |egrep  "plugin install (http|file)"

        plugin install http://some.domain.name//my-plugin-1.0.0.zip
        plugin install file:/path/to/my-plugin-1.0.0.zip

[root@Va5 bin]# ./plugin  install  file:///root/bigdesk-master.zip  
                                           ##安装插件bigdesk-master.zip

-> Installing from file:/root/bigdesk-master.zip...
Trying file:/root/bigdesk-master.zip ...
Downloading ...DONE
Verifying file:/root/bigdesk-master.zip checksums if available ...
NOTE: Unable to verify checksum for downloaded plugin (unable to find .sha1 or .md5 file to verify)
Installed bigdesk into /usr/share/elasticsearch/plugins/bigdesk

ES服务器监控工具——bigdesk
http://127.0.0.1:9200/_plugin/bigdesk

ES集群操作的API工具——Kopf
http://127.0.0.1:9200/_plugin/kopf/

3. bigdesk 统计分析和图表化elasticsearch集群状态信息 [ cpu 内存信息]

[root@Va5 bin]# ./plugin  list      ## 查看所有插件
Installed plugins in /usr/share/elasticsearch/plugins:
    - bigdesk

cURL支持的通信协议有
FTP、 FTPS、
HTTP、HTTPS、
TFTP、SFTP、
Gopher、SCP、Telnet、
DICT、 FILE、LDAP、
LDAPS、
IMAP、
POP3、SMTP和RTSP。

[root@Va5 ~]# curl  ftp://192.168.0.254/
drwxr-xr-x    8 0        0            2048 Sep 05  2017 CentOS7-1708
drwxr-xr-x    3 0        0            4096 Jan 15 09:00 ansible
drwxr-xr-x    2 0        0            4096 Jan 15 08:46 elk
drwxr-xr-x    2 0        0            4096 Aug 03  2017 pub
dr-xr-xr-x    9 0        0            4096 Jul 11  2017 rhel7
drwxrwxrwx    2 0        0            4096 Mar 19  2018 share

[root@Va5 ~]# curl  ftp://192.168.0.254/elk
curl: (78) RETR response: 550

[root@room9pc01 ~]# ls  /var/ftp/elk/
accounts.json.gz    elasticsearch-head-master.zip  shakespeare.json.gz
alog.gz             elasticsearch-kopf-master.zip
bigdesk-master.zip  logs.jsonl.gz

[root@room9pc01 ~]# ls  /var/ftp/elk/elasticsearch-head-master.zip 
/var/ftp/elk/elasticsearch-head-master.zip

[root@Va5 ~]# lftp  192.168.0.254
lftp 192.168.0.254:~> ls   elk/elasticsearch-head-master.zip
-rw-r--r--    1 0        0          899857 Jul 04  2017 elasticsearch-head-master.zip
lftp 192.168.0.254:/> bye

[root@Va5 ~]# /usr/share/elasticsearch/bin/plugin  install  ftp://192.168.0.254/elk/elasticsearch-head-master.zip   
                                     ##安装插件 elasticsearch-head-master.zip

-> Installing from ftp://192.168.0.254/elk/elasticsearch-head-master.zip...
Trying ftp://192.168.0.254/elk/elasticsearch-head-master.zip ...
Downloading .........DONE
Verifying ftp://192.168.0.254/elk/elasticsearch-head-master.zip checksums if available ...
Exception in thread "Thread-1" java.lang.IllegalStateException: Not connected
.......................
Exception in thread "Thread-2" java.lang.IllegalStateException: Not connected
.....................
NOTE: Unable to verify checksum for downloaded plugin (unable to find .sha1 or .md5 file to verify)
Installed head into /usr/share/elasticsearch/plugins/head

[root@Va5 ~]# /usr/share/elasticsearch/bin/plugin   list  ## 查看所有插件
Installed plugins in /usr/share/elasticsearch/plugins:
    - bigdesk
    - head

[root@Va5 ~]# ls  /usr/share/elasticsearch/plugins/
bigdesk  head

[root@Va5 ~]# ls   /usr/share/elasticsearch/plugins/bigdesk/
bigdesk_es2.png  NOTICE                        README.md
LICENSE          plugin-descriptor.properties  _site

[root@Va5 ~]# ls  /usr/share/elasticsearch/plugins/head/
elasticsearch-head.sublime-project  LICENCE                       _site
Gruntfile.js                        package.json                  src
grunt_fileSets.js                   plugin-descriptor.properties  test
index.html                          README.textile

[root@Va5 ~]# /usr/share/elasticsearch/bin/plugin  install  ftp://192.168.0.254/elk/elasticsearch-kopf-master.zip
                                     ##安装插件 elasticsearch-kopf-master.zip

[root@Va5 ~]# ls  /usr/share/elasticsearch/plugins/  # 插件的存放路径
bigdesk  head  kopf
[root@Va5 ~]# ls  /usr/share/elasticsearch/plugins/kopf/
CHANGELOG.md  Gruntfile.js  package.json                  _site
dataset       imgs          plugin-descriptor.properties  src
docker        LICENSE       README.md                     tests

 bigdesk 统计分析和图表化elasticsearch集群状态信息 [ cpu 内存信息]

 head 最实用的通过web界面来查看elasticsearch集群状态信息 

 kopf 一个通过web界面来管理和监控elasticsearch集群状态信息 

ES服务器监控工具——bigdesk
http://127.0.0.1:9200/_plugin/bigdesk

ES内容管理工具——head
http://127.0.0.1:9200/_plugin/head/

ES集群操作的API工具——Kopf
http://127.0.0.1:9200/_plugin/kopf/

http://192.168.0.11:9200/_cluster/health?pretty  ##检查集群状态

正常情况下，集群得健康状态分为三种：
green 
最健康得状态，说明所有的分片包括备份都可用
yellow 
基本的分片可用，但是备份不可用（或者是没有备份）
red 
部分的分片可用，表明分片有一部分损坏。此时执行查询部分数据仍然可以查到

[root@Va5 ~]# /usr/share/elasticsearch/bin/plugin  list
Installed plugins in /usr/share/elasticsearch/plugins:
    - bigdesk
    - head
    - kopf
[root@Va5 ~]# ls
bigdesk-master.zip .............
[root@Va5 ~]# rm  -f bigdesk-master.zip  ##插件安装完后可以删除安装包了

[root@Va5 ~]# yum  -y  install  elinks.x86_64 |tail  -1
完毕！

[root@Va5 ~]# elinks  -dump  http://192.168.0.15:9200/_plugin/head
[root@Va5 ~]# curl  http://192.168.0.15:9200/_plugin/head

<head><meta http-equiv="refresh" content="0; URL=/_plugin/head/"></head>

http://192.168.0.15:9200/_plugin/head/    ## 运维最常用的插件 head
===============================
Elasticsearch  http://192.168.0.15:9200/   elk-cluster集群健康值: green (0 of 0)
概览    索引    数据浏览    基本查询 [+]    复合查询 [+]                            信息[下拉菜单]
集群概览  集群排序[下拉菜单]   Sort Indices[下拉菜单]  View Aliases[下拉菜单]    [Index  Filter输入框]
	
* Va1
   信息[下拉菜单]  动作[下拉菜单]	
. Va2
   信息[下拉菜单]  动作[下拉菜单]	
. Va3
   信息[下拉菜单]  动作[下拉菜单]	
. Va4
   信息[下拉菜单]  动作[下拉菜单]	
. Va5
   信息[下拉菜单]  动作[下拉菜单]
=============================
[root@Va5 ~]# elinks  -dump  http://192.168.0.15:9200/

   { "name" : "Va5", "cluster_name" : "elk-cluster", "version" : { "number" :
   "2.3.4", "build_hash" : "e455fd0c13dceca8dbbdbb1665d068ae55dabe3f",
   "build_timestamp" : "2016-06-30T11:24:31Z", "build_snapshot" : false,
   "lucene_version" : "5.5.0" }, "tagline" : "You Know, for Search" }

[root@Va5 ~]# elinks  -dump  http://192.168.0.15:9200/_plugin/kopf
[root@Va5 ~]# echo  $?
0
http://192.168.0.15:9200/_plugin/kopf
http://192.168.0.15:9200/_plugin/kopf/#!/cluster
============================================
 K  cluster     nodes     rest     more
  5 nodes     0 indices     0 shards      0 docs      0b
filter indices byname[输入框]  closed (0)  special (0)  [filter nodes byname输入框] 
				
Va1
192.168.0.11
heap  disk cpu load
				
Va2 
192.168.0.12
heap  disk cpu load
			
Va3 
192.168.0.13
heap  disk cpu load

Va4
192.168.0.14
heap  disk cpu load
				
Va5
192.168.0.15
heap  disk cpu load

 show log[下拉菜单]
=======================================
 [root@Va5 ~]# elinks  -dump  http://192.168.0.15:9200/_plugin/bigdesk
   ES node REST endpoint [1]_________________________________________
   Refresh every [[2]______] Keep [[3]______] history [4][ Connect ]     

References

   Visible links

http://192.168.0.15:9200/_plugin/bigdesk
http://192.168.0.15:9200/_plugin/bigdesk/#nodes
=================================================
ES node REST endpoint   Refresh every[下拉菜单]  Keep[下拉菜单] history  [Connect]

Cluster: elk-cluster [ Va1 ][ Va2 ][ Va3 ][ Va4 ][ Va5 ]
Number of nodes: 5
Status: green
================================================
 bigdesk 统计分析和图表化elasticsearch集群状态信息 [ cpu 内存信息]

 head 最实用的通过web界面来查看elasticsearch集群状态信息 

 kopf 一个通过web界面来管理和监控elasticsearch集群状态信息 

ES服务器监控工具——bigdesk
http://127.0.0.1:9200/_plugin/bigdesk
http://192.168.0.15:9200/_plugin/bigdesk/#nodes

ES内容管理工具——head
http://127.0.0.1:9200/_plugin/head/
http://192.168.0.15:9200/_plugin/head/

ES集群操作的API工具——Kopf
http://127.0.0.1:9200/_plugin/kopf/
http://192.168.0.15:9200/_plugin/kopf/#!/cluster

elasticsearch 
只有主数据库有写入权限,从数据库只读权限,
但是客户端的感觉是 所有 主 从 数据库 都是可读可写,
原因 [ 从数据库 把客户端的写请求 转发 给 主数据库,然后所有服务器同步更新数据 ]

http://192.168.0.15:9200/_plugin/head/    ## 运维最常用的插件 head
===============================
Elasticsearch  http://192.168.0.15:9200/   elk-cluster集群健康值: green (0 of 0)
概览[触发键]  索引[触发键]  数据浏览[触发键]   基本查询 [+]    复合查询 [+]                            信息[下拉菜单]
集群概览  集群排序[下拉菜单]   Sort Indices[下拉菜单]  View Aliases[下拉菜单]    [Index  Filter输入框]
	
* Va1
   信息[下拉菜单]  动作[下拉菜单]	
. Va2
   信息[下拉菜单]  动作[下拉菜单]	
. Va3
   信息[下拉菜单]  动作[下拉菜单]	
. Va4
   信息[下拉菜单]  动作[下拉菜单]	
. Va5
   信息[下拉菜单]  动作[下拉菜单]

点击  索引[触发键]

索引概览 	新建索引[触发键]
Size  Docs

点击  新建索引[触发键]
弹出对话框 
--------------
 新建索引
索引名称* 输入 shujuku1
分片数*  5       # 分片数 和 副本数 建议 小于< 集群节点数,默认等于 集群节点数
副本数*  1      # 副本数 1 表示备份一份数据,加上源数据,总共同样的数据有1+1=2份
      点击  OK
----------------------
弹出对话框 
--------------
{"acknowledge":true}
      点击 确定
--------------------------
	这样就新建了一个数据库
Size     Docs
shujuku1 650B/1.27ki	0
------------------------
点击  概览[触发键] 
弹出更新页面
---------------------------------------------
           shujuku1
          size: 650B (1.27ki)
          docs: 0 (0)
            信息[下拉菜单]  动作[下拉菜单]

* Va1 信息[下拉菜单]  动作[下拉菜单]  0 [1]  # [注意带有加粗黑框的是源数据]
. Va2 信息[下拉菜单]  动作[下拉菜单]      2 [3] # [注意带有加粗黑框的是源数据]
. Va3 信息[下拉菜单]  动作[下拉菜单]     1[2]
. Va4 信息[下拉菜单]  动作[下拉菜单] [0]        4 #没有黑框的是复制的备份数据,即副本
. Va5 信息[下拉菜单]  动作[下拉菜单]         3 [4]
-----------------------算法 是 横竖 所有的数据 都是2份 -------------------------
------------------------------------------------------------------------------

点击  新建索引[触发键]
弹出对话框 
--------------
 新建索引
索引名称* 输入 数据库2 
分片数*  5         # 分片数 和 副本数 建议 小于< 集群节点数,默认等于 集群节点数
副本数*  2      # 副本数 2 表示备份2份数据,加上源数据,总共同样的数据有1+2=3份
      点击  OK
----------------------
弹出对话框 
--------------
{"acknowledge":true}
      点击 确定
--------------------------
	这样就又新建了一个数据库2
	
Size     Docs
shujuku1 795B/1.55ki	0
数据库2    520B/1.52ki	0
------------------------
点击  概览[触发键] 
弹出更新页面
---------------------------------------------
    数据库2                   shujuku1
   size: 520B (1.52ki)  size: 795B (1.55ki)
   docs: 0 (0)          docs: 0 (0)
    信息[]  动作[]              信息[]  动作[]

* Va1 信息[]  动作[]  0 [1] 2       0 [1]   # [注意带有加粗黑框的是源数据]
. Va2 信息[]  动作[]       2 [3] 4      2 [3] # [注意带有加粗黑框的是源数据]
. Va3 信息[]  动作[]  0 1 [2]          1[2]
. Va4 信息[]  动作[] [0]      3 4  [0]        4 #没有黑框的是复制的备份数据,即副本
. Va5 信息[]  动作[]    1    3 [4]         3 [4]

-----------------------算法 是 横竖 所有的数据 都是3+2=5份 ------------------------------------------ 
点击数据库2 -- 下面的 -- 动作[下拉菜单] -- 删除...
弹出对话框 
 输入 '删除' 删除 数据库2,此操作无法恢复
     删除     # 注意这里只能输入中文 " 删除"
  点击 确定
---------------------
弹出对话框 
{"acknowledge":true}
[ ]阻止此页面创建更多对话框
      点击 确定
-----------------------
弹出更新页面
---------------------------------------------
           shujuku1
          size: 795B (1.55ki)
          docs: 0 (0)
            信息[下拉菜单]  动作[下拉菜单]

* Va1 信息[ ]  动作[ ]  0 [1]  # [注意带有加粗黑框的是源数据]
. Va2 信息[ ]  动作[ ]      2 [3] # [注意带有加粗黑框的是源数据]
. Va3 信息[ ]  动作[ ]     1[2]
. Va4 信息[ ]  动作[ ] [0]        4 #没有黑框的是复制的备份数据,即副本
. Va5 信息[ ]  动作[ ]        3 [4]
-----------------------算法 是 横竖 所有的数据 都是2份 -------------------------
------------------------------------------------------------------------------
集群状态 索引属性查询
http://192.168.0.15:9200/_cat
=^.^=
/_cat/allocation
/_cat/shards
/_cat/shards/{index}
/_cat/master
/_cat/nodes
/_cat/indices
/_cat/indices/{index}
/_cat/segments
/_cat/segments/{index}
/_cat/count
/_cat/count/{index}
/_cat/recovery
/_cat/recovery/{index}
/_cat/health
/_cat/pending_tasks
/_cat/aliases
/_cat/aliases/{alias}
/_cat/thread_pool
/_cat/plugins
/_cat/fielddata
/_cat/fielddata/{fields}
/_cat/nodeattrs
/_cat/repositories
/_cat/snapshots/{repository}

ES服务器监控工具——bigdesk
http://127.0.0.1:9200/_plugin/bigdesk

ES内容管理工具——head
http://127.0.0.1:9200/_plugin/head/

ES集群操作的API工具——Kopf
http://127.0.0.1:9200/_plugin/kopf/

http://192.168.0.11:9200/_cluster/health?pretty  ##检查集群状态

集群状态 索引属性查询
http://192.168.0.15:9200/_cat

创建索引{相当于mysql的数据库}
curl  -X POST http://192.168.0.11:9200/sjku/  -d '
{"settings":{
  "index":{
   "number_of_shards":5,"number_of_replicas":1   
  }
 }
}'  # 注意 单引号 '{}' 成对

shard (玻璃、金属或其他硬物的)尖利的碎片,分片数
replica .复制品,副本数
replicas 复制品(replica的名词复数),副本数
shards (玻璃、金属或其他硬物的)尖利的碎片(shard的名词复数),分片数

API --- Application Program Interface 应用程序接口

restful 英 [ˈrestfl]   美 [ˈrɛstfəl]  
adj. 平静的，悠闲的，让人得到休息的;安生

represent
英 [ˌreprɪˈzent]   美 [ˌrɛprɪˈzɛnt]  
vt. 表现，象征;代表，代理;扮演;作为示范
vi. 代表;提出异议

representational
英 [ˌreprɪzenˈteɪʃnl]  美 [ˌrɛprɪzɛnˈteʃənəl, -zən-]  
adj. 代表性的，具象派的

REST  
REpresentational State Transfer
表现层 状态 迁移
一种最好理解的说法是，
URL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作

REST成熟度的四个层次
  第一个层次（Level0）的Web 服务只是使用 HTTP 作为传输方式，
实际上只是远程方法调用（RPC）的一种具体形  式。
SOAP和 XML-RPC都属于此类。

  第二个层次（Level1）的Web 服务引入了资源的概念。
 每个资源有对应的标识符和表达。

  第三个层次（Level2）的Web 服务使用不同的 HTTP 方法来进行不同的操作，
并且使用HTTP 状态码来表示不同的结果。
如 HTTP GET 方法来获取资源，HTTP DELETE 方法来删除资源。

  第四个层次（Level3）的Web 服务使用 HATEOAS。
在资源的表达中包含了链接信息。
客户端可以根据链接来发现可以执行的动作。

HATEOAS（超媒体即应用状态引擎）
Hypermedia as Application State Engine

二、Restful api接口有什么特征？
REST描述的是在网络中client和server的一种交互形式；
REST本身不实用，
实用的是如何设计 RESTful API（REST风格的网络接口）。

Elasticsearch的一个很大的优势是支持多种语言，
比如有Java API，.Net API等等，
最重要的是它还支持使用RESTful API。

RESTful是统一规范的http接口，任何语言都可以使用
restful接口常用的两种方式是get和post
=======================

ES服务器监控工具——bigdesk
http://127.0.0.1:9200/_plugin/bigdesk

ES内容管理工具——head
http://127.0.0.1:9200/_plugin/head/

ES集群操作的API工具——Kopf
http://127.0.0.1:9200/_plugin/kopf/

http://192.168.0.11:9200/_cluster/health?pretty  ##检查集群状态

集群状态 索引属性查询
http://192.168.0.15:9200/_cat

创建索引{相当于mysql的数据库}
curl  -X PSOT http://192.168.0.11:9200/sjku/  -d '
{"settings":{
  "index":{
   "number_of_shards":5,"number_of_replicas":1   
  }
 }
}'  # 注意 单引号 '{}' 成对
=============================
  关系型    --------  非关系型
MySQL    ?--?  NoSQL
Database ---->   Index
Table    ---->   Type
Row      ---->   Document
Column   ---->   Filed


REST  
REpresentational State Transfer
表现层 状态 迁移
一种最好理解的说法是，
URL定位资源，用HTTP动词（GET,POST,DELETE,DETC）描述操作

REST描述的是在网络中client和server的一种交互形式；
REST本身不实用，
实用的是如何设计 RESTful API（REST风格的网络接口）。

Elasticsearch的一个很大的优势是支持多种语言，
比如有Java API，.Net API等等，
最重要的是它还支持使用RESTful API。

RESTful是统一规范的http接口，任何语言都可以使用

restful接口常用的两种方式是get和post

Elasticsearch扩展性非常好，有很多官方和第三方开发的插件，
常用的有 
分词插件, 同步插件, 数据传输插件, 脚本支持插件,  其它插件

一、分词插件
IK Analysis Plugin (作者 Medcl)
简介：大名鼎鼎的ik分词，都懂的！

Mmseg Analysis Plugin (作者 Medcl)
简介：mmseg中文分词

Pinyin Analysis Plugin (作者 Medcl)
简介：拼音分词器

String2Integer Analysis Plugin (作者 Medcl)
简介：字符串转整型工具。主要用在facet这个功能上，如果facet的field的值是字符串的话，计算起来比较耗资源。可以把字符串映射成整型，对整型进行facet操作要比对字符串的快很多。

二、同步插件

CouchDB River Plugin (作者 elasticsearch 团队)
简介：CouchDB和elasticsearch的同步插件

Wikipedia River Plugin (作者 elasticsearch 团队)
简介：wikipedia文件读取插件。wikipedia是维基百科的一个离线库，不定期发布最新数据，
是以xml形式发布的。这个river读取这个文件来建索引。

Twitter River Plugin (作者 elasticsearch 团队)
简介：twitter的同步插件，可以同步你twitter上的微博。

MongoDB River Plugin (作者 Richard Louapre)
简介：mongodb同步插件，mongodb必须搭成副本集的模式，
因为这个插件的原理是通过定期读取mongodb中的oplog来同步数据。

JDBC River Plugin (作者 Jörg Prante)
简介：关系型数据库的同步插件

FileSystem River Plugin (作者 David Pilato)
简介：本地文件系统文件同步插件，使用方法是指定一个本地目录路径，es会定期扫描索引该目录下的文件。

LDAP River Plugin (作者 Tanguy Leroux)
简介：索引LDAP目录下的文件数据。


三、数据传输插件

Servlet transport (作者 elasticsearch 团队)
简介：Servlet rest插件，通过servlet来封装rest接口。

Memcached transport plugin (作者 elasticsearch 团队)
简介：本插件可以通过memcached协议进行rest接口的调用。注意：这里不是使用memcache作为es的缓存。

Jetty HTTP transport plugin (作者 Sonian Inc.)
简介：使用jetty来提供http rest接口。默认是使用netty。这个插件的好处是可以对http接口进行一些权限的设置。

四、脚本插件

Python language Plugin 
简介：python脚本支持

JavaScript language Plugin 
简介：javascript脚本支持

BigDesk Plugin 
简介：监控es状态的插件，推荐！

Elasticsearch Head Plugin 
简介：很方便对es进行各种操作的客户端。

Paramedic Plugin 
简介：es监控插件

SegmentSpy Plugin 
简介：查看es索引segment状态的插件


五、其它插件

Mapper Attachments Type plugin 
简介：附件类型插件，通过tika库把各种类型的文件格式解析成字符串。

Hadoop Plugin 
简介：hadoop和elasticsearch的集成插件，可以通过hadoop的mapreduce算法来并行建立索引，同时支持cascading，hive和pig等框架。

AWS Cloud Plugin 
简介：elasticsearch与amazon web services的集成。

ElasticSearch Changes Plugin 
简介：elasticsearch索引操作记录插件。通过这个插件可以查看用户对索引的增删改操作。

ElasticSearch View Plugin 
简介：这个插件可以把es的文档以html，xml或text的方式显示出来，它也可以通过查询生成web页面。










[root@Va6 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1476         109        1227           8         140        1211
Swap:          2047           0        2047



