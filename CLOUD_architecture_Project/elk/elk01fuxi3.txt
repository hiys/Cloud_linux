 
标准Http协议支持六种请求方法，即：
1、GET  发送一个请求来取得服务器上的某一资源

2、POST 向服务器发送数据,数据存放位置由服务器自己决定

3、PUT  向服务器发送数据,指定了数据资源的在服务器中存放的位置

4、Delete 删除服务器中的某一个资源

5、HEAD  发送一个请求,不含有呈现数据，仅含有HTTP头信息

6、Options 用于获取当前URL所支持的方法,若请求成功，则会在HTTP头中包含一个名为“Allow”的头，
             值是所支持的方法，如“GET, POST”。

ELK是一整套解决方案，是三个软件产品的首字母缩写，很多公司都在使用，
 如：Sina、携程、华为、美团等

ELK分别代表的意思
Elasticsearch：负责日志检索和储存
Logstash：负责日志的收集和分析、处理
Kibana：负责日志的可视化
这三款软件都是开源软件，通常是配合使用，而且又先后归于Elastic.co公司名下，故被简称为ELK

 ELK可以实现什么功能

在海量日志系统的运维中，
可用于解决分布式日志数据集中式查询和管理、系统监控，
包含系统硬件和应用各个组件的监控、故障排查、安全信息和事件管理、报表功能

Elasticsearch主要特点

1、实时分析
2、分布式实时文件存储，并将每一个字段都编入索引
3、文档导向，所有的对象全部是文档
4、高可用性，易扩展，支持集群（Cluster） 、 分片和复制（Shards 和 Replicas）
5、接口友好，支持JSON



关系型     --------  非关系型
MySQL    ?--?  NoSQL
Database ---->   Index
Table    ---->   Type
Row      ---->   Document
Column   ---->   Filed

ELK组成：
    - E：是指Elasticsearch，完成数据的存储和检索
    - L：是Logstash，完成数据的采集、过滤及解析
    - K：Kibana，以WEB方式展示

elastic
英 [ɪˈlæstɪk]   美 [ɪˈlæstɪk]  
adj. 有弹力的;可伸缩的;灵活的
n. 松紧带，橡皮圈

stash
英 [stæʃ]   美 [stæʃ]  
n. 隐（贮）藏物;（旧）藏身处
v. 贮藏;隐藏，藏匿;〈英〉停止

elasticsearch 弹性搜索

logstash 原木

log stash 原木充填

curl 命令

访问一个网页
curl http://www.baidu.com

显示头信息
curl -I http://www.baidu.com

显示详细的交互信息
curl -v http://www.baidu.com

把网页内存保存为文件
curl -o urfile http://www.baidu.com

配置文件

config/elasticsearch.yml   主配置文件
config/jvm.options         jvm参数配置文件
cofnig/log4j2.properties   日志配置文件

概念
1. 配置文件

config/elasticsearch.yml   主配置文件
config/jvm.options         jvm参数配置文件
cofnig/log4j2.properties   日志配置文件
2. 基本概念

接近实时（NRT）

Elasticsearch 是一个接近实时的搜索平台。
这意味着，从索引一个文档直到这个文档能够被搜索到有一个很小的延迟（通常是 1 秒）。
集群（cluster）

代表一个集群，集群中有多个节点（node），
其中有一个为主节点，这个主节点是可以通过选举产生的，
主从节点是对于集群内部来说的。
es的一个概念就是去中心化，
字面上理解就是无中心节点，这是对于集群外部来说的，
因为从外部来看es集群，在逻辑上是个整体，
你与任何一个节点的通信和与整个es集群通信是等价的。

索引（index）
ElasticSearch将它的数据存储在一个或多个索引（index）中。
用SQL领域的术语来类比，索引就像数据库，
可以向索引写入文档或者从索引中读取文档，
并通过ElasticSearch内部使用Lucene将数据写入索引或从索引中检索数据。

文档（document）
文档（document）是ElasticSearch中的主要实体。
对所有使用ElasticSearch的案例来说，他们最终都可以归结为对文档的搜索。文档由字段构成。

映射（mapping）
所有文档写进索引之前都会先进行分析，
如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做映射（mapping）。
一般由用户自己定义规则。

类型（type）
每个文档都有与之对应的类型（type）定义。
这允许用户在一个索引中存储多种文档类型，并为不同文档提供类型提供不同的映射。

shard  英 [ʃɑ:d]   美 [ʃɑ:rd]  
n. （玻璃、金属或其他硬物的）尖利的碎片

分片（shards）
代表索引分片，es可以把一个完整的索引分成多个分片，
这样的好处是可以把一个大的索引拆分成多个，
分布到不同的节点上。

构成分布式搜索。
分片的数量只能在索引创建前指定，并且索引创建后不能更改。
5.X默认不能通过配置文件定义分片

/****************
MongoDB是一个基于分布式文件存储的数据库。
由C++语言编写。
旨在为WEB应用提供可扩展的高性能数据存储解决方案。

MongoDB是一个介于关系数据库和非关系数据库之间的产品，
是非关系数据库当中功能最丰富，
最像关系数据库的。
它支持的数据结构非常松散，是类似json的bson格式，
因此可以存储比较复杂的数据类型。
Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，
几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。

************/
replica
英 [ˈreplɪkə]   美 [ˈrɛplɪkə]  
n. 复制品
replicas
n. 复制品( replica的名词复数 )

副本（replicas）
代表索引副本，
es可以设置多个索引的副本，
副本的作用一是提高系统的容错性，
当个某个节点某个分片损坏或丢失时可以从副本中恢复。
二是提高es的查询效率，
es会自动对搜索请求进行负载均衡。

数据恢复（recovery）
代表数据恢复或叫数据重新分布，
es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，
挂掉的节点重新启动时也会进行数据恢复。

Elasticsearch中存储数据的行为就叫做索引(indexing)： 
在Elasticsearch中，
文档归属于一种类型(type),

而这些类型存在于索引(index)中，

我们可以画一些简单的对比图来类比传统关系型数据库： 
Relational DB -> Databases -> Tables -> Rows -> Columns 
Elasticsearch -> Indexs -> Types -> Documents -> Fields

索引（index）
ElasticSearch将它的数据存储在一个或多个索引（index）中。
用SQL领域的术语来类比，索引就像数据库，
可以向索引写入文档或者从索引中读取文档，
并通过ElasticSearch内部使用Lucene将数据写入索引或从索引中检索数据。

Elasticsearch中的概念与关系型数据库对比

Relational DB  Databases Tables   Rows   Columns
关系型数据库        数据库       表         行         列

Elasticsearch  Indices   Types  Documents  Fields
搜索引擎             索引        类型      文档       域(字段)

Elasticsearch没有典型意义的事务.
Elasticsearch是一种面向文档的数据库。
Elasticsearch没有提供授权和认证特性

标准Http协议支持六种请求方法，即：
1、GET  发送一个请求来取得服务器上的某一资源

2、POST 向服务器发送数据,数据存放位置由服务器自己决定

3、PUT  向服务器发送数据,指定了数据资源的在服务器中存放的位置

4、Delete 删除服务器中的某一个资源

5、HEAD  发送一个请求,不含有呈现数据，仅含有HTTP头信息

6、Options 用于获取当前URL所支持的方法,若请求成功，则会在HTTP头中包含一个名为“Allow”的头，
             值是所支持的方法，如“GET, POST”。

Elasticsearch中的概念与关系型数据库对比

关系型数据库   select  *  from  table...;     update  table  set....;

Elasticsearch  GET  http://...                PUT  http://......


 关系型    --------  非关系型
MySQL    ?--?   NoSQL
Database  ---->   Index
Table     ---->   Type
Row       ---->   Document
Column    ---->   Filed

ELK组成：
    - E：是指Elasticsearch [非关系型数据库,最重要]，完成数据的存储和检索
    - L：是Logstash[可使用 docker 容器技术,数据次重要]，完成数据的采集、过滤及解析
    - K：Kibana [与 apache 作用相同 ] ，以WEB方式展示 

Linux  apache    mysql[关系型]       php[处理后台程序]
L        A         M                  P
L        K         E                  L
Linux  kibana elasticsearch[非关系型] logstash[处理日志的工作[ java开发的 ]]

elastic
英 [ɪˈlæstɪk]   美 [ɪˈlæstɪk]  
adj. 有弹力的;可伸缩的;灵活的
n. 松紧带，橡皮圈

stash
英 [stæʃ]   美 [stæʃ]  
n. 隐（贮）藏物;（旧）藏身处
v. 贮藏;隐藏，藏匿;〈英〉停止

elasticsearch 弹性搜索

禁用 防火墙，禁用 selinux

elasticsearch 安装
1、安装 openjdk 包
yum install -y java-1.8.0-openjdk-devel

验证
java -version
jps

安装 elasticsearch 
rpm -ivh elasticsearch-2.3.4.rpm

修改配置文件启动服务
network.host: ip.xx.xx.xx
systemctl start elasticsearch

验证
systemctl status elasticsearch
netstat -ltunp

通过浏览器访问
http://192.168.4.11:9200/

elastic
英 [ɪˈlæstɪk]   美 [ɪˈlæstɪk]  
adj. 有弹力的;可伸缩的;灵活的
n. 松紧带，橡皮圈

elasticsearch
弹性搜索

elasticsearch 集群安装
在多台机器上安装部署 java-1.8.0-openjdk-devel，elasticsearch-2.3.4.rpm
修改 hosts 文件，保证所有机器通过名称能 ping 通集群中的其他机器

禁用防火墙 和 selinux
禁用防火墙 和 selinux
禁用防火墙 和 selinux

[root@room9pc01 ~]# ll  /var/git/elk.tar
-rwxrwxrwx 1 root root 161884160 11月 21 13:20 /var/git/elk.tar
[root@room9pc01 ~]# du  -sh   /var/git/elk.tar
155M	/var/git/elk.tar

[root@room9pc01 ~]# tar  -xf  /var/git/elk.tar  -C  /var/ftp/

[root@room9pc01 ~]# mkdir  /var/ftp/elk
[root@room9pc01 ~]# mv   /var/ftp/*.{gz,zip}  /var/ftp/elk/

[root@room9pc01 ~]# ls   /var/ftp/elk/
accounts.json.gz    elasticsearch-head-master.zip  shakespeare.json.gz
alog.gz             elasticsearch-kopf-master.zip
bigdesk-master.zip  logs.jsonl.gz

[root@room9pc01 ~]# ls   /var/ftp/
ansible                  filebeat-1.2.3-x86_64.rpm    rhel7
CentOS7-1708             kibana-4.5.2-1.x86_64.rpm    share
elasticsearch-2.3.4.rpm  logstash-2.3.4-1.noarch.rpm
elk                      pub

/** ~]# tar  -xf  /var/git/elk.tar  -C  /var/ftp/ansible/   ***/

[root@room9pc01 ~]# mv  /var/ftp/*.rpm   /var/ftp/ansible/

[root@room9pc01 ~]# ls   /var/ftp/
ansible  CentOS7-1708  elk  pub  rhel7  share

[root@room9pc01 ~]# ls   /var/ftp/ansible/
ansible-2.4.2.0-2.el7.noarch.rpm         python-httplib2-0.9.2-1.el7.noarch.rpm
elasticsearch-2.3.4.rpm                  python-paramiko-2.1.1-4.el7.noarch.rpm
filebeat-1.2.3-x86_64.rpm                python-passlib-1.6.5-2.el7.noarch.rpm
kibana-4.5.2-1.x86_64.rpm                repodata
logstash-2.3.4-1.noarch.rpm              sshpass-1.06-2.el7.x86_64.rpm
python2-jmespath-0.9.0-3.el7.noarch.rpm

[root@room9pc01 ~]# createrepo   --update  /var/ftp/ansible/
Spawning worker 0 with 1 pkgs
Spawning worker 1 with 1 pkgs
Spawning worker 2 with 1 pkgs
Spawning worker 3 with 1 pkgs
Workers Finished
Saving Primary metadata
Saving file lists metadata
Saving other metadata
Generating sqlite DBs
Sqlite DBs complete

[root@Va1 ~]# ifconfig  |awk  '/inet /{print $2}'
192.168.0.11
192.168.1.11
192.168.2.11
127.0.0.1
192.168.122.1
[root@Va1 ~]# cat  /etc/yum.repos.d/local.repo 
[CentOS7-1708]
name=CentOS7-1708
gpgcheck=0
baseurl=ftp://192.168.0.254/CentOS7-1708/
enabled=1

[ansible]
name=ansible
baseurl=ftp://192.168.0.254/ansible
gpgcheck=0
enabled=1
[root@Va1 ~]# ls  /etc/yum.repos.d/
local.repo  redhat.repo

/**********
[root@room9pc01 ~]# ls   /var/ftp/ansible/
ansible-2.4.2.0-2.el7.noarch.rpm         python-httplib2-0.9.2-1.el7.noarch.rpm
elasticsearch-2.3.4.rpm                  python-paramiko-2.1.1-4.el7.noarch.rpm
filebeat-1.2.3-x86_64.rpm                python-passlib-1.6.5-2.el7.noarch.rpm
kibana-4.5.2-1.x86_64.rpm                repodata
logstash-2.3.4-1.noarch.rpm              sshpass-1.06-2.el7.x86_64.rpm
python2-jmespath-0.9.0-3.el7.noarch.rpm
*********/

[root@Va1 ~]# yum  clean all >/dev/null  && yum repolist  |tail  -4
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601
[root@Va1 ~]# cat  /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.0.11  Va1
192.168.1.11  Va1
192.168.0.12  Va2
192.168.1.12  Va2
192.168.0.13  Va3
192.168.1.13  Va3
192.168.0.14  Va4
192.168.1.14  Va4
192.168.0.15  Va5
192.168.1.15  Va5
192.168.0.16  Va6
192.168.1.16  Va6
192.168.0.17  Va7
192.168.1.17  Va7
192.168.0.18  Va8
192.168.1.18  Va8
192.168.0.19  Va9
192.168.1.19  Va9

[root@Va1 ~]# yum list  |grep  openjdk^C
[root@Va1 ~]# yum list  |grep  java-1.8.0-openjdk
java-1.8.0-openjdk.x86_64                1:1.8.0.131-11.b12.el7    @anaconda/7.4
java-1.8.0-openjdk-headless.x86_64       1:1.8.0.131-11.b12.el7    @anaconda/7.4
java-1.8.0-openjdk.i686                  1:1.8.0.131-11.b12.el7    CentOS7-1708 
..........................
java-1.8.0-openjdk-src-debug.x86_64      1:1.8.0.131-11.b12.el7    CentOS7-1708 

[root@Va1 ~]# yum  -y  install   java-1.8.0-openjdk  
..............
软件包 1:java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64 已安装并且是最新版本
无须任何处理
[root@Va1 ~]# rpm  -qa  |grep  java-1.8.0-openjdk
java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64
java-1.8.0-openjdk-headless-1.8.0.131-11.b12.el7.x86_64

[root@Va1 ~]# java -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)

/************
[root@room9pc01 ~]# ls   /var/ftp/
ansible                  filebeat-1.2.3-x86_64.rpm    rhel7
CentOS7-1708             kibana-4.5.2-1.x86_64.rpm    share
elasticsearch-2.3.4.rpm  logstash-2.3.4-1.noarch.rpm
elk                      pub
*********/

[root@Va1 ~]# yum  search  elasticsearch
.................
elasticsearch.noarch : Distribution: RPM
filebeat.x86_64 : Sends log files to Logstash or directly to Elasticsearch.
kibana.x86_64 : Explore and visualize your Elasticsearch data.

  名称和简介匹配 only，使用“search all”试试。

[root@Va1 ~]# yum   -y  install  elasticsearch 
................
已安装:
  elasticsearch.noarch 0:2.3.4-1                                                               

完毕！
[root@Va1 ~]# rpm  -qa  |grep   elasticsearch
elasticsearch-2.3.4-1.noarch

[root@Va1 ~]# ls   /etc/elasticsearch/
elasticsearch.yml  logging.yml  scripts

[root@Va1 ~]# cd   /etc/elasticsearch/

在所有节点修改配置文件 /etc/elasticsearch/elasticsearch.yml 

[root@Va1 elasticsearch]# vim   elasticsearch.yml 

[root@Va1 elasticsearch]# sed  -n  54p   elasticsearch.yml
# 将绑定地址设置为特定IP
network.host: 192.168.0.11  # 绑定监听IP

设置bind_host和publish_host上面两个参数 
# 将绑定地址设置为特定IP
# network.host: 192.168.0.11    # 绑定监听IP

[root@Va1 elasticsearch]# grep  -n "network.host"  elasticsearch.yml
54:network.host: 192.168.0.11

[root@Va1 elasticsearch]# systemctl   start  elasticsearch  &&  systemctl  enable  elasticsearch

Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service.

# 设置节点间交互的tcp端口,默认是9300 
# transport.tcp.port: 9300 
[root@Va1 elasticsearch]# grep  -n http.port  elasticsearch.yml 
58:# http.port: 9200    # 设置对外服务的http端口,默认为9200 

[root@Va1 elasticsearch]# netstat   -npult  |grep  java
tcp6       0      0 192.168.0.11:9200       :::*                    LISTEN      4026/java           
tcp6       0      0 192.168.0.11:9300       :::*                    LISTEN      4026/java  
         
[root@Va1 elasticsearch]# ps  -C  java
  PID TTY          TIME CMD
 4026 ?        00:00:06 java

http://192.168.0.11:9200/  # 测试 安装成功
{
  "name" : "Skullfire",
  "cluster_name" : "elasticsearch",
  "version" : {
    "number" : "2.3.4",
    "build_hash" : "e455fd0c13dceca8dbbdbb1665d068ae55dabe3f",
    "build_timestamp" : "2016-06-30T11:24:31Z",
    "build_snapshot" : false,
    "lucene_version" : "5.5.0"
  },
  "tagline" : "You Know, for Search"
}
[root@room9pc01 ~]# uptime 
 17:52:36 up  4:34,     8 users,   load average: 0.25, 0.28, 0.26
当前时间    系统已运行的时间 当前在线用户  平均负载：最近1分钟、5分钟、15分钟 系统的负载
平均负载量：0.00, 0.01, 0.05 最后一个信息是系统的平均负载量
可以换算成百分比0%，1%，5%

[root@room9pc01 ~]# cat   /proc/loadavg 
0.34 0.30 0.27 2/651 12825
前3个数字表示平均进程数量外，
后面的1个分数 2/651 的分母表示系统进程总数，分子表示正在运行的进程数；
最后一个数字12825 表示最近运行的进程ID

[root@Va1 elasticsearch]# pwd
/etc/elasticsearch
[root@Va1 elasticsearch]# ls
elasticsearch.yml  logging.yml  scripts

[root@Va1 elasticsearch]# ls  scripts/
[root@Va1 elasticsearch]# elinks   -dump  192.168.0.11:9200

   { "name" : "Skullfire", "cluster_name" : "elasticsearch", "version" : {
   "number" : "2.3.4", "build_hash" :
   "e455fd0c13dceca8dbbdbb1665d068ae55dabe3f", "build_timestamp" :
   "2016-06-30T11:24:31Z", "build_snapshot" : false, "lucene_version" :
   "5.5.0" }, "tagline" : "You Know, for Search" }

[root@Va1 elasticsearch]# grep  -n http.port  elasticsearch.yml 
58:# http.port: 9200    # 设置对外服务的http端口,默认为9200 

[root@Va1 elasticsearch]# ls  /usr/share/elasticsearch/bin/plugin 
/usr/share/elasticsearch/bin/plugin

[root@Va1 elasticsearch]# ls  /usr/share/elasticsearch/
bin  lib  LICENSE.txt  modules  NOTICE.txt  plugins  README.textile

[root@Va1 elasticsearch]# cd

[root@Va1 ~]# yum  -y  install  ansible  |tail  -3
............
[root@Va1 ~]# ansible  --version
ansible 2.4.2.0    ## 显示版本说明安装成功
...........
Ansible配置文件查找顺序

– 首先检测 ANSIBLE_CONFIG 变量定义的配置文件
– 其次检查当前目彔下的 ./ansible.cfg 文件　　　（常用方式）
– 再次检查当前用户家目彔下 ~/ansible.cfg 文件
– 最后检查 /etc/ansible/ansible.cfg 文件

• /etc/ansible/ansible.cfg 默认配置文件路径

• ansible.cfg 配置文件（就两个主要配置文件）

– inventory 是定义托管主机地址配置文件

[root@Va1 ~]# ls
anaconda-ks.cfg  index.html            parameter.json  user3.yaml   user.sh    图片
apache.retry     initial-setup-ks.cfg  parameter.vars  user4.retry  user.yaml  文档
apache.yaml      ip.sh                 ping.yml        user4.yaml   公共       下载
baidu.sh         load.retry            user2.yaml      user5.yaml   模板       音乐
echo.yml         load.yaml             user3.retry     user.retry   视频       桌面
[root@Va1 ~]# ls  /etc/ansible/
ansible.cfg  hosts  roles
[root@Va1 ~]# vim  /etc/ansible/hosts 
[root@Va1 ~]# sed  -n  '44,$p'  /etc/ansible/hosts
[web]
Va2
Va4

[db]
Va3
Va5

[other]
Va6

[app:children]
web
db
[root@Va1 ~]# ansible  app  -a  "rm  -rf  /root/.ansible/*"  ##默认的模块command无效


[root@Va1 ~]# ansible  app -m  shell  -a  "rm  -rf  /root/.ansible/*" ##shell模块万能
 [WARNING]: Consider using file module with state=absent rather than running rm
                考虑使用state=absent的文件模块，而不是运行rm
Va5 | SUCCESS | rc=0 >>
Va2 | SUCCESS | rc=0 >>
Va4 | SUCCESS | rc=0 >>
Va3 | SUCCESS | rc=0 >>

[root@Va1 ~]# ls  /root/.ssh/
id_rsa  id_rsa.pub  known_hosts

exclusive adj. 专用的;高级的;排外的;单独的

[root@Va1 ~]# ansible app  -m  authorized_key  -a  "user=root  exclusive=true  \
manage_dir=true  key='$(< /root/.ssh/id_rsa.pub)'"  -k 
SSH password: 1
.........
Va2 | SUCCESS => {
..............
[root@Va1 ~]# ansible  app   -a  "ls -l  /root/.ansible/"Va2 | SUCCESS | rc=0 >>
总用量 0
drwx------ 3 root root 55 1月  15 18:58 tmp

Va4 | SUCCESS | rc=0 >>
总用量 0
drwx------ 3 root root 55 1月  15 18:58 tmp

Va5 | SUCCESS | rc=0 >>
总用量 0
drwx------ 3 root root 54 1月  15 18:58 tmp

Va3 | SUCCESS | rc=0 >>
总用量 0
drwx------ 3 root root 54 1月  15 18:58 tmp

/****************************
                                     #json 格式传参数  注意大括号{}
[root@Va1 ~]# ansible-playbook  -e   '{"user":{"name":"jj","group":"zuxx","uid":"1133"}}'  user.yaml
..........................

                             # yaml格式传参数 注意大括号{ }, 空格, 逗号
[root@Va1 ~]# ansible-playbook  -e   '{ user: { name: jj2, group: zuxx, uid: 1134 } }'  user.yaml
...............................

[root@Va1 ~]# ansible-playbook -i /etc/ansible/hosts  -e  'nameadd="jinj2"  uid="1126"'  user2.yaml  
                                                               ##在命令行里面传参数 键值对 的方法 ,变量优先级命令行最高
...............................
                                      # 将参数放在文件里面 -e  "@文件路径 " 传参数 
[root@Va1 ~]# ansible-playbook  -e  "@parameter.vars"   user.yaml  ##注意parameter.vars是yaml格式文件

[root@Va1 ~]# cat   parameter.vars  ##注意这是yaml格式文件

user:
  name: testname
  group: admin
  uid: 1135

[root@Va1 ~]# file   parameter.vars
parameter.vars: ASCII text

[root@Va1 ~]# cat   parameter.json
{"user":
  {
    "name":"jsontest",
    "group":"apache",
    "uid":"1136"
  }
}
[root@Va1 ~]# ansible-playbook  -e  "@parameter.json"   user.yaml  ##注意parameter.json是json格式文件
...................
***********/
[root@Va1 ~]# ls  /etc/ansible/
ansible.cfg  hosts  roles
[root@Va1 ~]# ls
anaconda-ks.cfg  index.html            parameter.json  user3.yaml   user.sh    图片
apache.retry     initial-setup-ks.cfg  parameter.vars  user4.retry  user.yaml  文档
apache.yaml      ip.sh                 ping.yml        user4.yaml   公共       下载
baidu.sh         load.retry            user2.yaml      user5.yaml   模板       音乐
echo.yml         load.yaml             user3.retry     user.retry   视频       桌面

[root@Va1 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1984         443        1122           8         417        1353
Swap:          2047           0        2047

[root@Va1 ~]# vim  hosts.yml

[root@Va1 ~]# cat  hosts.yml
---
- hosts: app
  remote_user: root
  tasks:
    - copy:
        src: /etc/hosts
        dest: /etc/hosts
        owner: root
        group: root
        mode: 0644
    - copy:
        src: /etc/yum.repos.d/local.repo
        dest: /etc/yum.repos.d/local.repo
        owner: root
        group: root
        mode: 0644

[root@Va1 ~]# ansible-playbook  -i  /etc/ansible/hosts   hosts.yml

PLAY [app] **************************************************************************

TASK [Gathering Facts] **************************************************************
ok: [Va3]
ok: [Va5]
ok: [Va4]
ok: [Va2]

TASK [copy] ..............
.........
[root@Va1 ~]# file /etc/ansible/hosts
/etc/ansible/hosts: ASCII text

[root@Va1 ~]# vim   hosts
[root@Va1 ~]# cat   hosts
[elas]
Va[2:5]

[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m  shell   -a  "yum clean all >/dev/null && yum repolist  |tail   -4"
 [WARNING]: Consider using yum module rather than running yum

Va2 | SUCCESS | rc=0 >>
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

Va5 | SUCCESS | rc=0 >>
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

Va3 | SUCCESS | rc=0 >>
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

Va4 | SUCCESS | rc=0 >>
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

[root@Va1 ~]# vim  setelk.yaml
[root@Va1 ~]# cat  setelk.yaml
---
- hosts: elas
  remote_user: root
  tasks:
    - yum:
        name: java-1.8.0-openjdk,elasticsearch
        state: latest
    - service:
        name: elasticsearch
        enabled: yes

[root@Va1 ~]# ansible-playbook  -i  /root/hosts  setelk.yaml

PLAY [elas] *************************************************************************

TASK [Gathering Facts] ............
...................
[root@Va1 ~]# ansible elas -i /root/hosts -m shell -a "rpm -q  elasticsearch"

 [WARNING]: Consider using yum, dnf or zypper module rather than running rpm

Va4 | SUCCESS | rc=0 >>
elasticsearch-2.3.4-1.noarch
.............
[root@Va1 ~]# ls   /etc/elasticsearch/
elasticsearch.yml  logging.yml  scripts

[root@Va1 elasticsearch]# sed  -n  54p   elasticsearch.yml

# 将绑定地址设置为特定IP
# network.host: 192.168.0.11    # 绑定监听IP

[root@Va1 ~]# vim  /etc/elasticsearch/elasticsearch.yml 

# 代表一个集群,集群中有多个节点,其中有一个为主节点,这个主节点是可以通过选举产生的,主从节点是对于集群内部来说的. 
# es的一个概念就是去中心化,字面上理解就是无中心节点,这是对于集群外部来说的,
因为从外部来看es集群,在逻辑上是个整体,你与任何一个节点的通信和与整个es集群通信是等价的。 
# cluster.name可以确定你的集群名称,
当你的elasticsearch集群在同一个网段中elasticsearch会自动的找到具有相同cluster.name的elasticsearch服务. 
# 所以当同一个网段具有多个elasticsearch集群时cluster.name就成为同一个集群的标识. 

 17 cluster.name: elk-cluster # 设置集群名称{elasticsearch服务器识别集群的唯一方式}

 23 node.name: Va1  # 节点名称,可自动生成也可手动配置(本主机名).

 54 network.host: 192.168.0.0    # 绑定监听IP特定的网络

# 这是一个集群中的主节点的初始列表,当节点(主节点或者数据节点)启动时使用这个列表进行探测 
 68 discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

[root@Va1 ~]# sed  -n  '17p;23p;54p;68p'  /etc/elasticsearch/elasticsearch.yml 
cluster.name: elk-cluster
node.name: Va1
network.host: 192.168.0.0
discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

                        ## 在覆盖之前将原文件备份，备份文件包含时间信息 backup=yes
 ~]# ansible  other  -m  copy  -a  'src=/root/index.html  dest=/var/www/html/index.html backup=yes'
 ~]# ansible all -m copy -a "src=/home/test.sh dest=/tmp/ owner=root group=root mode=0755"    
#src 主控端文件位置
#dest 被控端目标位置
#owner 文件复制过去后的所有者
#group 文件复制过去后的所属组
#mode  文件的权限设定，执行a+x这种方式

[root@Va1 ~]# cat  hosts
[elas]
Va[2:5]
[root@Va1 ~]# ansible elas -i  /root/hosts -m  copy  -a "src=/etc/elasticsearch/elasticsearch.yml  dest=/etc/elasticsearch/  backup=yes  owner=root  group=root  mode=0644"

Va5 | SUCCESS => {
............................
}
Va3 | SUCCESS => {
.........................
}
Va2 | SUCCESS => {
...................
}
Va4 | SUCCESS => {
    "backup_file": "/etc/elasticsearch/elasticsearch.yml.6437.2019-01-15@20:29:56~", 
    "changed": true, 
    "checksum": "48b3bd67f91c7dcbbba58a84e0cf8805ea1b0039", 
    "dest": "/etc/elasticsearch/elasticsearch.yml", 
    "gid": 0, 
    "group": "root", 
    "md5sum": "f2b222c098736234c83b33abe3583ab4", 
    "mode": "0644", 
    "owner": "root", 
    "size": 3178, 
    "src": "/root/.ansible/tmp/ansible-tmp-1547555395.66-272167774563342/source", 
    "state": "file", 
    "uid": 0
}
[root@Va1 ~]# ansible elas -i  /root/hosts -m  shell  -a "sed  -i  's,^\(node.name:\).*,\1 ${HOSTNAME},'  /etc/elasticsearch/elasticsearch.yml"  ##注意必须 sed 不能是 '单引号' #结果执行失败(但是语法没错)

[root@Va1 ~]# ansible elas -i  /root/hosts -m  shell  -a  'sed  -i  "s,^\(node.name:\).*,\1 ${HOSTNAME},"  /etc/elasticsearch/elasticsearch.yml' ##注意必须  外面是单引号 "sed 双引号"#执行成功


 [WARNING]: Consider using template or lineinfile module rather than running sed

Va5 | SUCCESS | rc=0 >>
Va2 | SUCCESS | rc=0 >>
Va3 | SUCCESS | rc=0 >>
Va4 | SUCCESS | rc=0 >>

[root@Va1 ~]# echo  ${HOSTNAME}
Va1
[root@Va1 ~]# sed  -n  '17p;23p;54p;68p'  /etc/elasticsearch/elasticsearch.yml 
cluster.name: elk-cluster
node.name: Va1
network.host: 192.168.0.0
discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]


[root@Va1 ~]# cat  /root/hosts
[elas]
Va[2:5]
[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m  shell  -a  "systemctl  restart elasticsearch"

Va5 | SUCCESS | rc=0 >>
Va4 | SUCCESS | rc=0 >>
Va2 | SUCCESS | rc=0 >>
Va3 | SUCCESS | rc=0 >>

[root@Va1 ~]# ansible  elas -i /root/hosts -m shell -a "netstat -npult|grep java"Va3 | SUCCESS | rc=0 >>
tcp6       0      0 192.168.0.0:9200        :::*                    LISTEN      7120/java           
tcp6       0      0 192.168.0.0:9300        :::*                    LISTEN      7120/java           

Va2 | SUCCESS | rc=0 >>
tcp6       0      0 192.168.0.0:9200        :::*                    LISTEN      7075/java           
tcp6       0      0 192.168.0.0:9300        :::*                    LISTEN      7075/java           

Va5 | SUCCESS | rc=0 >>
tcp6       0      0 192.168.0.0:9200        :::*                    LISTEN      7070/java           
tcp6       0      0 192.168.0.0:9300        :::*                    LISTEN      7070/java           

Va4 | SUCCESS | rc=0 >>
tcp6       0      0 192.168.0.0:9200        :::*                    LISTEN      7026/java           
tcp6       0      0 192.168.0.0:9300        :::*                    LISTEN      7026/java           

 关系型    --------  非关系型
MySQL    ?--?   NoSQL
Database  ---->   Index
Table     ---->   Type
Row       ---->   Document
Column    ---->   Filed

ELK组成：
    - E：是指Elasticsearch [非关系型数据库,最重要]，完成数据的存储和检索
    - L：是Logstash[可使用 docker 容器技术,数据次重要]，完成数据的采集、过滤及解析
    - K：Kibana [与 apache 作用相同 ] ，以WEB方式展示 

Linux  apache    mysql[关系型]       php[处理后台程序]
L        A         M                  P
L        K         E                  L
Linux  kibana elasticsearch[非关系型] logstash[处理日志的工作[ java开发的 ]]

[root@Va1 ~]# sed  -n  '54p'  /etc/elasticsearch/elasticsearch.yml 
network.host: 192.168.0.0  # 配置文件写错了

http://192.168.0.11:9200/_cluster/health?pretty
{
  "cluster_name" : "elasticsearch",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 1,   ## 注意不是5个节点,说明配置文件写错了
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
############################## Network And HTTP ############################### 
# 设置绑定的ip地址,可以是ipv4或ipv6的,默认为0.0.0.0 
# network.bind_host: 192.168.0.1   #只有本机可以访问http接口

# 设置其它节点和该节点交互的ip地址,如果不设置它会自动设置,值必须是个真实的ip地址 
# network.publish_host: 192.168.0.1 

# 同时设置bind_host和publish_host上面两个参数 
# network.host: 192.168.0.1    #绑定监听IP


sed中执行外部命令
 
1.sed命令使用单引号的情况下使用'`shell command`'或者'$(shell command)'引用命令执行的结果
 
还是以上面案例分析，例子如下
 
$ echo|sed 's/^/'`echo $RANDOM`'.rmvb_/g'
 8063.rmvb_
 

# 上面的例子使用了旧式的命令替换，也可以采用新式的命令替换方法，如下
 
$ echo|sed 's/^/'$(echo $RANDOM)'.rmvb_/g'
 18554.rmvb_


HTTP协议是Hyper Text Transfer Protocol（超文本传输协议）的缩写,
是用于从万维网（WWW:World Wide Web ）服务器传输超文本到本地浏览器的传送协议。。
HTTP是一个基于TCP/IP通信协议来传递数据（HTML 文件, 图片文件, 查询结果等）。

HTTP三点注意事项：
HTTP是无连接：
无连接的含义是限制每次连接只处理一个请求。
服务器处理完客户的请求，并收到客户的应答后，即断开连接。
采用这种方式可以节省传输时间。

HTTP是媒体独立的：
这意味着，只要客户端和服务器知道如何处理的数据内容，任何类型的数据都可以通过HTTP发送。
客户端以及服务器指定使用适合的MIME-type内容类型。

HTTP是无状态：
HTTP协议是无状态协议。
无状态是指协议对于事务处理没有记忆能力。
缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。
另一方面，在服务器不需要先前信息时它的应答就较快。

URL和URI的区别

URI：统一资源标识符，用来唯一的标识一个资源。

URI一般由三部分组成：
(1)访问资源的命名机制；
(2)存放资源的主机名；
(3)资源自身的名称，由路径表示，着重强调于资源。

URL：统一资源定位器，它是一种具体的URI，
即URL可以用来标识一个资源，而且还指明了如何locate这个资源。

URL由三部分组成：
(1)协议(或称为服务方式)；
(2)存有该资源的主机IP地址(有时也包括端口号)；
(3)主机资源的具体地址。如目录或文件名等。

--------------------------------------
一、HTTP报文格式 HTTP报文分为两类:
请求报文request, 响应报文response 

HTTP请求报文格式:
HTTP请求报文主要由请求行、请求头部、请求正文3部分组成

1，请求行

由3部分组成，分别为：请求方法、URL（见备注1）以及协议版本，之间由空格分隔

请求方法包括GET、HEAD、PUT、POST、TRACE、OPTIONS、DELETE以及扩展方法，
当然并不是所有的服务器都实现了所有的方法，部分方法即便支持，处于安全性的考虑也是不可用的

协议版本的格式为：HTTP/主版本号.次版本号，常用的有HTTP/1.0和HTTP/1.1

2，请求头部
请求头部为请求报文添加了一些附加信息，由“名/值”对组成，每行一对，名和值之间使用冒号分隔

常见请求头如下：

请求头          说明
Host         接受请求的服务器地址，可以是IP:端口号，也可以是域名
User-Agent   发送请求的应用程序名称
Connection   指定与连接相关的属性，如Connection:Keep-Alive
Accept-Charset   通知服务端可以发送的编码格式
Accept-Encoding  通知服务端可以发送的数据压缩格式
Accept-Language  通知服务端可以发送的语言

请求头部的最后会有一个空行，表示请求头部结束，接下来为请求正文，这一行非常重要，必不可少

3，请求正文

可选部分，比如GET请求就没有请求正文

------------------------------------
一、HTTP报文格式 HTTP报文分为两类:
请求报文request, 响应报文response 

HTTP响应报文格式:

HTTP响应报文主要由状态行、响应头部、响应正文3部分组成


1，状态行

由3部分组成，分别为：协议版本，状态码，状态码描述，之间由空格分隔

状态代码为3位数字，200~299的状态码表示成功，300~399的状态码指资源重定向，400~499的状态码指客户端请求出错，500~599的状态码指服务端出错（HTTP/1.1向协议中引入了信息性状态码，范围为100~199）

这里列举几个常见的：

状态码  说明
200     响应成功
301     永久重定向，搜索引擎将删除源地址，保留重定向地址
302  暂时重定向，重定向地址由响应头中的Location属性指定（JSP中Forward和Redirect之间的区别）
由于搜索引擎的判定问题，较为复杂的URL容易被其它网站使用更为精简的URL及302重定向劫持
304  缓存文件并未过期，还可继续使用，无需再次从服务端获取
400  客户端请求有语法错误，不能被服务器识别
403  服务器接收到请求，但是拒绝提供服务（认证失败）
404  请求资源不存在
500  服务器内部错误


2，响应头部
与请求头部类似，为响应报文添加了一些附加信息

常见响应头部如下：

响应头               说明
Server           服务器应用程序软件的名称和版本
Content-Type     响应正文的类型（是图片还是二进制字符串）
Content-Length   响应正文长度
Content-Charset   响应正文使用的编码
Content-Encoding  响应正文使用的数据压缩格式
Content-Language  响应正文使用的语言
 

PS：

1，URI、URL和URN之间的区别

URI全名为Uniform Resource Indentifier（统一资源标识），用来唯一的标识一个资源，是一个通用的概念，URI由两个主要的子集URL和URN组成

URL全名为Uniform Resource Locator（统一资源定位），通过描述资源的位置来标识资源

URN全名为Uniform Resource Name（统一资源命名），通过资源的名字来标识资源，
与其所处的位置无关，
这样即使资源的位置发生变动，其URN也不会变化

HTTP规范将更通用的概念URI作为其资源标识符，但是实际上，HTTP应用程序处理的只是URI的URL子集


一、HTTP报文格式 HTTP报文分为两类:
请求报文request, 响应报文response 

二、HTTP请求报文: ASCII文本 (易于人读格式) 
GET /somedir/page.ht... 来自：	AspenStars
通过HTTP网络请求过程中的TCP协议


curl命令的使用

http的请求方法：
常用方法 GET，POST，HEAD
其他方法 OPTIONS，PUT，DELETE，TRACE和CONNECT
ES常用：
PUT --增
DELETE --删
POST --改
GET --查
系统命令curl：
是一个利用URL规则在命令行下工作的文件传输工具,可以说是一款很强大的http命令行工具。
它支持多种请求模式,自定义请求头等强大功能,是一款综合工具
curl 常用参数介绍：
-A 修改请求 agent
-X 设置请求方法
-i 显示返回头信息



socket编程之实现一个简单的TCP通信
 3.4万
一、理解socket1、socket即为套接字，在TCP/IP协议中，“IP地址+TCP或UDP端口号”唯一的标识网络通讯中的一个进程，“IP地址+TCP或UDP端口号”就为socket。 2、在T... 来自：	YANG


TCP协议本身是保证传输的数据完整性不会丢数据的。 如果通信中发现缺少数据或者丢包， 那么，最大的可能在于程序发送的过程或者接收的过程出现问题。 例如服务器给客户端发大量数据，Send的频率... 来自：	一缕阳光的博客
http get请求和post请求的格式区别
 8539
写了一个cgi, 支持get请求， 在fiddler中重放get请求， 一切正常， 参数格式如下： GET /cgi-bin/my_cgi?uin=12345&appID=20&content=xxx... 来自：	stpeace的专栏
IP报文格式详解
 4万
IP报文是在网络层传输的数据单元，也叫IP数据报。IP报文格式如下图（图片来源：百度百科） 版本：IP协议的版本，目前的IP协议版本号为4，下一代IP协议版本号为6。 首部长度：IP报头的... 来自：	海阔天空sky的博客
HTTP协议响应(详解)
 2415
HTTP协议详解之响应 什么是HTTP响应 当服务器收到浏览器的请求后，会发送响应消息给浏览器。一个完整的响应消息主要包括响应首行、响应头信息、空行和响应正文。 HTTP响应消息分析 HTTP... 来自：	陈铁锋的博客
Spring 经典面试题和答案
1. 什么是spring?   Spring 是个java企业级应用的开源开发框架。Spring主要用来开发Java应用，但是有些扩展是针对构建J2EE平台的web应用。Spring 框架目标... 来自：	一次次尝试


DELETE
请求服务器删除指定的页面。
DELETE请求一般返回3种码
200（OK）——删除成功，同时返回已经删除的资源。
202（Accepted）——删除请求已经接受，但没有被立即执行（资源也许已经被转移到了待删除区域）。
204（No Content）——删除请求已经被执行，但是没有返回资源（也许是请求删除不存在的资源造成的）。

CONNECT
HTTP/1.1协议中预留给能够将连接改为管道方式的代理服务器。

OPTIONS
允许客户端查看服务器的性能。

TRACE
回显服务器收到的请求，主要用于测试或诊断。


使用 -A 自定义 User-Agent
我们可以使用 -A 来自定义用户代理，例如下面的命令将伪装成安卓火狐浏览器对网页进行请求： 
curl -A “Mozilla/5.0 (Android; Mobile; rv:35.0) Gecko/35.0 Firefox/35.0” http://www.baidu.com 

7. 使用 -H 自定义 header

当我们需要传递特定的 header 的时候，可以仿照以下命令来写： 
curl -H “Referer: www.example.com” -H “User-Agent: Custom-User-Agent” http://www.baidu.com 
可以看到，当我们使用 -H 来自定义 User-Agent 时，需要使用 “User-Agent: xxx” 的格式。

我们能够直接在 header 中传递 Cookie，格式与上面的例子一样： 
curl -H “Cookie: JSESSIONID=D0112A5063D938586B659EF8F939BE24” http://www.example.com 

============================================

2.1 安装 Kibana

wget https://artifacts.elastic.co/downloads/kibana/kibana-5.6.3-linux-x86_64.tar.gz

tar -zxvf kibana-5.6.3-linux-x86_64.tar.gz 

cd kibana-5.6.3-linux-x86_64/ 

2.2 修改配置文件

vim config/kibana.yml

# 将默认配置改成如下：

server.port: 5601
server.host: "0.0.0.0"
elasticsearch.url: "http://192.168.2.41:9200"
kibana.index: ".kibana"
2.3 启动

bin/kibana
启动后打开浏览器访问 http://192.168.2.43:5601 浏览 kibana 界面：

image

三、演示
上图中，提示不能获取映射，即 Elasticsearch 中的索引。我们需要手动配置。在 Index Pattern 下边的输入框中输入 access-*，它是 Elasticsearch 中的一个索引名称开头。

Kibana 会自动检测在 Elasticsearch 中是否存在该索引名称，如果有，则下边出现 “Create” 按钮，我们点击进行创建并来到如下界面：

image

3.1 Discovery

“Discovery” 菜单界面主要用于通过搜索请求，过滤结果，查看文档数据。可以查询搜索请求的文档总数，获取字段值的统计情况并通过柱状图进行展示。

点击左侧 “Discovery” 菜单，来到如下界面：

image

不了解查询条件如何使用，可以先随便输入查询条件进行查询，界面会提示找不到信息，同时还会提示查询方式。

3.2 Visualize

“Visualize” 菜单界面主要用于将查询出的数据进行可视化展示，且可以将其保存或加载合并到 Dashboard 中。

点击左侧 “Visualize” 菜单，再点击界面中间的 “Create a visualization” 按钮来到如下界面：

image

本次测试选择柱状图演示，点击柱状图：

image

点击右上角“Save” 按钮可以进行保存。笔者将该可视化保存为 “Nginx access”。

3.3 Dashboard

在“Dashboard” 菜单界面中，我们可以自由排列一组已保存的可视化数据。

点击左侧 “Dashboard” 菜单，再点击界面中间的 “Create a dashboard” 按钮进行创建：

image

3.4 Timelion

Timelion 是一个时间序列数据的可视化，可以结合在一个单一的可视化完全独立的数据源。它是由一个简单的表达式语言驱动的，用来检索时间序列数据，进行计算，找出复杂的问题的答案，并可视化的结果。

3.5 Dev Tools

“Dev Tools” 菜单界面使用户方便的通过浏览器直接与 Elasticsearch 进行交互，发送 RESTFUL 请求可以对 Elasticsearch 数据进行增删改查：

https://segmentfault.com/a/1190000015568533








[root@Va2 ~]# yum  repolist |tail  -4
源标识                                源名称                               状态
!CentOS7-1708                         CentOS7-1708                         9,591
!ansible                              ansible                                  6
repolist: 9,597
[root@Va2 ~]# cat  /etc/yum.repos.d/local.repo 
[CentOS7-1708]
name=CentOS7-1708
gpgcheck=0
baseurl=ftp://192.168.0.254/CentOS7-1708/
enabled=1

[ansible]
name=ansible
baseurl=ftp://192.168.0.254/ansible
gpgcheck=0
enabled=1
[root@Va2 ~]# yum clean  all >/dev/null  && yum repolist  |tail -4
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

[root@Va2 ~]#  ls   /etc/elasticsearch/
elasticsearch.yml  logging.yml  scripts
[root@Va2 ~]#  ls   /etc/elasticsearch/
elasticsearch.yml  elasticsearch.yml.6469.2019-01-15@20:29:56~  logging.yml  scripts

[root@Va2 ~]# sed  -n  "/^node.name:/p"   /etc/elasticsearch/elasticsearch.yml
node.name: Va1

[root@Va2 ~]# echo  $HOSTNAME
Va2
[root@Va2 ~]# echo  ${HOSTNAME}
Va2
[root@Va2 ~]# sed  -n  's,^\(node.name:\).*,\1 ${HOSTNAME},p'  /etc/elasticsearch/elasticsearch.yml
node.name: ${HOSTNAME}

[root@Va2 ~]# sed  -n  '17p;23p;54p;68p'  /etc/elasticsearch/elasticsearch.yml 
cluster.name: elk-cluster
node.name: Va2
network.host: 192.168.0.0
discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

[root@Va2 ~]# 






在所有节点修改配置文件 /etc/elasticsearch/elasticsearch.yml 
cluster.name: my-elk01
node.name: node5
network.host: 0.0.0.0  # 0.0.0.0指在本机的路由表里没有特定条目指明如何到达的所有主机和目的网络
discovery.zen.ping.unicast.hosts: ["node1", "node2", "node3", "node5"]

启动所有节点的 elasticsearch 服务
通过浏览器可以访问任意节点的 http://ip.xx.xx.xx:9200/

验证集群是否正常，访问
http://192.168.4.15:9200/_cluster/health?pretty

{
  "cluster_name" : "my-elk01", #集群名称
  "status" : "green", # 表示正常
  "timed_out" : false,
  "number_of_nodes" : 5, #当前节点数量
  "number_of_data_nodes" : 5,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}

插件的安装 head  kopf  bigdesk
1 拷贝插件 zip 包到一个目录
2 /usr/share/elasticsearch/bin/plugin install file:///插件的位置/插件包.zip 安装

3 验证：
安装完成以后可以通过
/usr/share/elasticsearch/bin/plugin list 看到我们已经安装的插件的名称

4 访问head 插件
它展现ES集群的拓扑结构
可以通过它来进行索引（Index）和节点（Node）级别的操作
它提供一组针对集群的查询API，并将结果以json和表格形式返回
它提供一些快捷菜单，用以展现集群的各种状态
http://192.168.4.11:9200/_plugin/head/


5 kopf 插件安装
kopf是一个ElasticSearch的管理工具，它提供了对ES集群操作的API。
/usr/share/elasticsearch/bin/plugin install file:///xxx-kopf.zip

访问地址
http://192.168.4.11:9200/_plugin/kopf/

6 bigdesk 插件安装
bigdesk是elasticsearch的一个集群监控工具
可以通过它来查看es集群的各种状态，
如：cpu、内存使用情况，索引数据、搜索情况，http连接数等。
/usr/share/elasticsearch/bin/plugin install file:///bigdesk-xxx.zip

访问地址
http://192.168.4.11:9200/_plugin/bigdesk/

使用RESTful API操作elasticsearch
curl -XPUT 'http://192.168.4.11:9200/school/' -d '{
    "settings":{
        "index":{
            "number_of_shards": 5,
            "number_of_replicas": 1
        }
    }
}'

获取索引配置信息：
curl -XGET 'http://192.168.4.11:9200/school/_settings/'
curl -XGET 'http://192.168.4.11:9200/_all/_settings/'

创建文档
curl -XPUT 'http://192.168.4.11:9200/school/students/1' -d '{
    "title": "devops",
    "name":{
        "first": "guzhang",
        "last": "wu"
    },
    "age": 25
}'

查询文档信息
curl -XGET 'http://192.168.4.11:9200/school/students/1'
curl -XGET 'http://192.168.4.11:9200/school/students/1?_source=name,age'

更新文档信息
curl -XPOST 'http://192.168.4.11:9200/school/students/1/_update' -d '{
    "doc":{
        "age": 30
    }
}'

删除文档信息
curl -XDELETE 'http://192.168.4.14:9200/school/students/1'

批量导入数据
curl -XPOST 'http://192.168.4.14:9200/_bulk' --data-binary @shakespeare.json
curl -XPOST 'http://192.168.4.14:9200/_bulk' --data-binary @logs.jsonl
curl -XPOST 'http://192.168.4.14:9200/accounts/act/_bulk?pretty' --data-binary @accounts.json

批量查询数据
curl -XGET 'http://192.168.4.11:9200/_mget?pretty' -d '{ 
    "docs":[
        {
            "_index": "accounts",
            "_type:": "act",
            "_id": 1
        },
        {
            "_index": "accounts",
            "_type:": "act",
            "_id": 2
        },
        {
            "_index": "shakespeare",
            "_type:": "scene",
            "_id": 1
        }
    ]
}'
  

Elasticsearch扩展性非常好，有很多官方和第三方开发的插件，
下面以分词、同步、数据传输、脚本支持、站点、其它这几个类别进行划分。

一、分词插件

Combo Analysis Plugin (作者 Olivier Favre, Yakaz)
简介：组合分词器，可以把多个分词器的结果组合在一起。

Smart Chinese Analysis Plugin (作者 elasticsearch 团队)
简介：lucene默认的中文分词器

ICU Analysis plugin (作者 elasticsearch 团队)
简介：lucene自带的ICU分词，ICU是一套稳定、成熟、功能强大、轻便易用和跨平台支持Unicode 的开发包。


IK Analysis Plugin (作者 Medcl)
简介：大名鼎鼎的ik分词，都懂的！

Mmseg Analysis Plugin (作者 Medcl)
简介：mmseg中文分词


Pinyin Analysis Plugin (作者 Medcl)
简介：拼音分词器

String2Integer Analysis Plugin (作者 Medcl)
简介：字符串转整型工具。主要用在facet这个功能上，如果facet的field的值是字符串的话，计算起来比较耗资源。可以把字符串映射成整型，对整型进行facet操作要比对字符串的快很多。

二、同步插件

CouchDB River Plugin (作者 elasticsearch 团队)
简介：CouchDB和elasticsearch的同步插件

Wikipedia River Plugin (作者 elasticsearch 团队)
简介：wikipedia文件读取插件。wikipedia是维基百科的一个离线库，不定期发布最新数据，
是以xml形式发布的。这个river读取这个文件来建索引。

Twitter River Plugin (作者 elasticsearch 团队)
简介：twitter的同步插件，可以同步你twitter上的微博。


MongoDB River Plugin (作者 Richard Louapre)
简介：mongodb同步插件，mongodb必须搭成副本集的模式，
因为这个插件的原理是通过定期读取mongodb中的oplog来同步数据。


JDBC River Plugin (作者 Jörg Prante)
简介：关系型数据库的同步插件

FileSystem River Plugin (作者 David Pilato)
简介：本地文件系统文件同步插件，使用方法是指定一个本地目录路径，es会定期扫描索引该目录下的文件。

LDAP River Plugin (作者 Tanguy Leroux)
简介：索引LDAP目录下的文件数据。


三、数据传输插件

Servlet transport (作者 elasticsearch 团队)
简介：Servlet rest插件，通过servlet来封装rest接口。

Memcached transport plugin (作者 elasticsearch 团队)
简介：本插件可以通过memcached协议进行rest接口的调用。注意：这里不是使用memcache作为es的缓存。

Jetty HTTP transport plugin (作者 Sonian Inc.)
简介：使用jetty来提供http rest接口。默认是使用netty。这个插件的好处是可以对http接口进行一些权限的设置。

四、脚本插件

Python language Plugin (作者 elasticsearch 团队)
简介：python脚本支持

JavaScript language Plugin (作者 elasticsearch 团队)
简介：javascript脚本支持

BigDesk Plugin (作者 Lukáš Vlček)
简介：监控es状态的插件，推荐！

Elasticsearch Head Plugin (作者 Ben Birch)
简介：很方便对es进行各种操作的客户端。

Paramedic Plugin (作者 Karel Minařík)
简介：es监控插件

SegmentSpy Plugin (作者 Zachary Tong)
简介：查看es索引segment状态的插件



五、其它插件

Mapper Attachments Type plugin (作者 elasticsearch 团队)
简介：附件类型插件，通过tika库把各种类型的文件格式解析成字符串。

Hadoop Plugin (作者 elasticsearch team)
简介：hadoop和elasticsearch的集成插件，可以通过hadoop的mapreduce算法来并行建立索引，同时支持cascading，hive和pig等框架。

AWS Cloud Plugin (作者 elasticsearch 团队)
简介：elasticsearch与amazon web services的集成。

ElasticSearch Mock Solr Plugin (作者 Matt Weber)
简介：elasticsearch的solr api接口。用了这个插件可以使用solr的api来调用es，
直接用solrj就可以调用es。比较适用于从solr转es时暂时过度。

Suggester Plugin (作者 Alexander Reelsen)
简介：es 搜索提示功能插件，不过es0.9版本后自带了这个功能，

ElasticSearch PartialUpdate Plugin (作者 Medcl)
简介：elasticsearch的部分更新插件。

ZooKeeper Discovery Plugin (作者 Sonian Inc.)
简介：通过zookeeper管理集群的插件。通过这个插件，es的分布式架构和solrcloud相似。

ElasticSearch Changes Plugin (作者 Thomas Peuss)
简介：elasticsearch索引操作记录插件。通过这个插件可以查看用户对索引的增删改操作。

ElasticSearch View Plugin (作者 Tanguy Leroux)
简介：这个插件可以把es的文档以html，xml或text的方式显示出来，它也可以通过查询生成web页面。






