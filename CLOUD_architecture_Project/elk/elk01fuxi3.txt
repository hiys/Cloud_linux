 
标准Http协议支持六种请求方法，即：
1、GET  发送一个请求来取得服务器上的某一资源

2、POST 向服务器发送数据,数据存放位置由服务器自己决定

3、PUT  向服务器发送数据,指定了数据资源的在服务器中存放的位置

4、Delete 删除服务器中的某一个资源

5、HEAD  发送一个请求,不含有呈现数据，仅含有HTTP头信息

6、Options 用于获取当前URL所支持的方法,若请求成功，则会在HTTP头中包含一个名为“Allow”的头，
             值是所支持的方法，如“GET, POST”。

ELK是一整套解决方案，是三个软件产品的首字母缩写，很多公司都在使用，
 如：Sina、携程、华为、美团等

ELK分别代表的意思
Elasticsearch：负责日志检索和储存
Logstash：负责日志的收集和分析、处理
Kibana：负责日志的可视化
这三款软件都是开源软件，通常是配合使用，而且又先后归于Elastic.co公司名下，故被简称为ELK

 ELK可以实现什么功能

在海量日志系统的运维中，
可用于解决分布式日志数据集中式查询和管理、系统监控，
包含系统硬件和应用各个组件的监控、故障排查、安全信息和事件管理、报表功能

Elasticsearch主要特点

1、实时分析
2、分布式实时文件存储，并将每一个字段都编入索引
3、文档导向，所有的对象全部是文档
4、高可用性，易扩展，支持集群（Cluster） 、 分片和复制（Shards 和 Replicas）
5、接口友好，支持JSON



关系型   --------  非关系型
MySQL    ?--?  NoSQL
Database  ---->   Index
Table        ---->   Type
Row          ---->   Document
Column    ---->   Filed

ELK组成：
    - E：是指Elasticsearch，完成数据的存储和检索
    - L：是Logstash，完成数据的采集、过滤及解析
    - K：Kibana，以WEB方式展示

elastic
英 [ɪˈlæstɪk]   美 [ɪˈlæstɪk]  
adj. 有弹力的;可伸缩的;灵活的
n. 松紧带，橡皮圈

stash
英 [stæʃ]   美 [stæʃ]  
n. 隐（贮）藏物;（旧）藏身处
v. 贮藏;隐藏，藏匿;〈英〉停止

elasticsearch 弹性搜索

logstash 原木

log stash 原木充填

curl 命令

访问一个网页
curl http://www.baidu.com

显示头信息
curl -I http://www.baidu.com

显示详细的交互信息
curl -v http://www.baidu.com

把网页内存保存为文件
curl -o urfile http://www.baidu.com

配置文件

config/elasticsearch.yml   主配置文件
config/jvm.options         jvm参数配置文件
cofnig/log4j2.properties   日志配置文件

概念
1. 配置文件

config/elasticsearch.yml   主配置文件
config/jvm.options         jvm参数配置文件
cofnig/log4j2.properties   日志配置文件
2. 基本概念

接近实时（NRT）

Elasticsearch 是一个接近实时的搜索平台。
这意味着，从索引一个文档直到这个文档能够被搜索到有一个很小的延迟（通常是 1 秒）。
集群（cluster）

代表一个集群，集群中有多个节点（node），
其中有一个为主节点，这个主节点是可以通过选举产生的，
主从节点是对于集群内部来说的。
es的一个概念就是去中心化，
字面上理解就是无中心节点，这是对于集群外部来说的，
因为从外部来看es集群，在逻辑上是个整体，
你与任何一个节点的通信和与整个es集群通信是等价的。

索引（index）
ElasticSearch将它的数据存储在一个或多个索引（index）中。
用SQL领域的术语来类比，索引就像数据库，
可以向索引写入文档或者从索引中读取文档，
并通过ElasticSearch内部使用Lucene将数据写入索引或从索引中检索数据。

文档（document）
文档（document）是ElasticSearch中的主要实体。
对所有使用ElasticSearch的案例来说，他们最终都可以归结为对文档的搜索。文档由字段构成。

映射（mapping）
所有文档写进索引之前都会先进行分析，
如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做映射（mapping）。
一般由用户自己定义规则。

类型（type）
每个文档都有与之对应的类型（type）定义。
这允许用户在一个索引中存储多种文档类型，并为不同文档提供类型提供不同的映射。

shard  英 [ʃɑ:d]   美 [ʃɑ:rd]  
n. （玻璃、金属或其他硬物的）尖利的碎片

分片（shards）
代表索引分片，es可以把一个完整的索引分成多个分片，
这样的好处是可以把一个大的索引拆分成多个，
分布到不同的节点上。

构成分布式搜索。
分片的数量只能在索引创建前指定，并且索引创建后不能更改。
5.X默认不能通过配置文件定义分片

/****************
MongoDB是一个基于分布式文件存储的数据库。
由C++语言编写。
旨在为WEB应用提供可扩展的高性能数据存储解决方案。

MongoDB是一个介于关系数据库和非关系数据库之间的产品，
是非关系数据库当中功能最丰富，
最像关系数据库的。
它支持的数据结构非常松散，是类似json的bson格式，
因此可以存储比较复杂的数据类型。
Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，
几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。

************/
replica
英 [ˈreplɪkə]   美 [ˈrɛplɪkə]  
n. 复制品
replicas
n. 复制品( replica的名词复数 )

副本（replicas）
代表索引副本，
es可以设置多个索引的副本，
副本的作用一是提高系统的容错性，
当个某个节点某个分片损坏或丢失时可以从副本中恢复。
二是提高es的查询效率，
es会自动对搜索请求进行负载均衡。

数据恢复（recovery）
代表数据恢复或叫数据重新分布，
es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，
挂掉的节点重新启动时也会进行数据恢复。

Elasticsearch中存储数据的行为就叫做索引(indexing)： 
在Elasticsearch中，
文档归属于一种类型(type),

而这些类型存在于索引(index)中，

我们可以画一些简单的对比图来类比传统关系型数据库： 
Relational DB -> Databases -> Tables -> Rows -> Columns 
Elasticsearch -> Indexs -> Types -> Documents -> Fields

索引（index）
ElasticSearch将它的数据存储在一个或多个索引（index）中。
用SQL领域的术语来类比，索引就像数据库，
可以向索引写入文档或者从索引中读取文档，
并通过ElasticSearch内部使用Lucene将数据写入索引或从索引中检索数据。

Elasticsearch中的概念与关系型数据库对比

Relational DB  Databases Tables   Rows   Columns
关系型数据库        数据库       表         行         列

Elasticsearch  Indices   Types  Documents  Fields
搜索引擎             索引        类型      文档       域(字段)

Elasticsearch没有典型意义的事务.
Elasticsearch是一种面向文档的数据库。
Elasticsearch没有提供授权和认证特性

标准Http协议支持六种请求方法，即：
1、GET  发送一个请求来取得服务器上的某一资源

2、POST 向服务器发送数据,数据存放位置由服务器自己决定

3、PUT  向服务器发送数据,指定了数据资源的在服务器中存放的位置

4、Delete 删除服务器中的某一个资源

5、HEAD  发送一个请求,不含有呈现数据，仅含有HTTP头信息

6、Options 用于获取当前URL所支持的方法,若请求成功，则会在HTTP头中包含一个名为“Allow”的头，
             值是所支持的方法，如“GET, POST”。

Elasticsearch中的概念与关系型数据库对比

关系型数据库   select  *  from  table...;     update  table  set....;

Elasticsearch  GET  http://...                PUT  http://......


 关系型    --------  非关系型
MySQL    ?--?   NoSQL
Database  ---->   Index
Table     ---->   Type
Row       ---->   Document
Column    ---->   Filed

ELK组成：
    - E：是指Elasticsearch [非关系型数据库,最重要]，完成数据的存储和检索
    - L：是Logstash[可使用 docker 容器技术,数据次重要]，完成数据的采集、过滤及解析
    - K：Kibana [与 apache 作用相同 ] ，以WEB方式展示 

Linux  apache    mysql[关系型]       php[处理后台程序]
L        A         M                  P
L        K         E                  L
Linux  kibana elasticsearch[非关系型] logstash[处理日志的工作[ java开发的 ]]

elastic
英 [ɪˈlæstɪk]   美 [ɪˈlæstɪk]  
adj. 有弹力的;可伸缩的;灵活的
n. 松紧带，橡皮圈

stash
英 [stæʃ]   美 [stæʃ]  
n. 隐（贮）藏物;（旧）藏身处
v. 贮藏;隐藏，藏匿;〈英〉停止

elasticsearch 弹性搜索

禁用 防火墙，禁用 selinux

elasticsearch 安装
1、安装 openjdk 包
yum install -y java-1.8.0-openjdk-devel

验证
java -version
jps

安装 elasticsearch 
rpm -ivh elasticsearch-2.3.4.rpm

修改配置文件启动服务
network.host: ip.xx.xx.xx
systemctl start elasticsearch

验证
systemctl status elasticsearch
netstat -ltunp

通过浏览器访问
http://192.168.4.11:9200/

elastic
英 [ɪˈlæstɪk]   美 [ɪˈlæstɪk]  
adj. 有弹力的;可伸缩的;灵活的
n. 松紧带，橡皮圈

elasticsearch
弹性搜索

elasticsearch 集群安装
在多台机器上安装部署 java-1.8.0-openjdk-devel，elasticsearch-2.3.4.rpm
修改 hosts 文件，保证所有机器通过名称能 ping 通集群中的其他机器

禁用防火墙 和 selinux
禁用防火墙 和 selinux
禁用防火墙 和 selinux

[root@room9pc01 ~]# ll  /var/git/elk.tar
-rwxrwxrwx 1 root root 161884160 11月 21 13:20 /var/git/elk.tar
[root@room9pc01 ~]# du  -sh   /var/git/elk.tar
155M	/var/git/elk.tar

[root@room9pc01 ~]# tar  -xf  /var/git/elk.tar  -C  /var/ftp/

[root@room9pc01 ~]# mkdir  /var/ftp/elk
[root@room9pc01 ~]# mv   /var/ftp/*.{gz,zip}  /var/ftp/elk/

[root@room9pc01 ~]# ls   /var/ftp/elk/
accounts.json.gz    elasticsearch-head-master.zip  shakespeare.json.gz
alog.gz             elasticsearch-kopf-master.zip
bigdesk-master.zip  logs.jsonl.gz

[root@room9pc01 ~]# ls   /var/ftp/
ansible                  filebeat-1.2.3-x86_64.rpm    rhel7
CentOS7-1708             kibana-4.5.2-1.x86_64.rpm    share
elasticsearch-2.3.4.rpm  logstash-2.3.4-1.noarch.rpm
elk                      pub

/** ~]# tar  -xf  /var/git/elk.tar  -C  /var/ftp/ansible/   ***/

[root@room9pc01 ~]# mv  /var/ftp/*.rpm   /var/ftp/ansible/

[root@room9pc01 ~]# ls   /var/ftp/
ansible  CentOS7-1708  elk  pub  rhel7  share

[root@room9pc01 ~]# ls   /var/ftp/ansible/
ansible-2.4.2.0-2.el7.noarch.rpm         python-httplib2-0.9.2-1.el7.noarch.rpm
elasticsearch-2.3.4.rpm                  python-paramiko-2.1.1-4.el7.noarch.rpm
filebeat-1.2.3-x86_64.rpm                python-passlib-1.6.5-2.el7.noarch.rpm
kibana-4.5.2-1.x86_64.rpm                repodata
logstash-2.3.4-1.noarch.rpm              sshpass-1.06-2.el7.x86_64.rpm
python2-jmespath-0.9.0-3.el7.noarch.rpm

[root@room9pc01 ~]# createrepo   --update  /var/ftp/ansible/
Spawning worker 0 with 1 pkgs
Spawning worker 1 with 1 pkgs
Spawning worker 2 with 1 pkgs
Spawning worker 3 with 1 pkgs
Workers Finished
Saving Primary metadata
Saving file lists metadata
Saving other metadata
Generating sqlite DBs
Sqlite DBs complete

[root@Va1 ~]# ifconfig  |awk  '/inet /{print $2}'
192.168.0.11
192.168.1.11
192.168.2.11
127.0.0.1
192.168.122.1
[root@Va1 ~]# cat  /etc/yum.repos.d/local.repo 
[CentOS7-1708]
name=CentOS7-1708
gpgcheck=0
baseurl=ftp://192.168.0.254/CentOS7-1708/
enabled=1

[ansible]
name=ansible
baseurl=ftp://192.168.0.254/ansible
gpgcheck=0
enabled=1
[root@Va1 ~]# ls  /etc/yum.repos.d/
local.repo  redhat.repo

/**********
[root@room9pc01 ~]# ls   /var/ftp/ansible/
ansible-2.4.2.0-2.el7.noarch.rpm         python-httplib2-0.9.2-1.el7.noarch.rpm
elasticsearch-2.3.4.rpm                  python-paramiko-2.1.1-4.el7.noarch.rpm
filebeat-1.2.3-x86_64.rpm                python-passlib-1.6.5-2.el7.noarch.rpm
kibana-4.5.2-1.x86_64.rpm                repodata
logstash-2.3.4-1.noarch.rpm              sshpass-1.06-2.el7.x86_64.rpm
python2-jmespath-0.9.0-3.el7.noarch.rpm
*********/

[root@Va1 ~]# yum  clean all >/dev/null  && yum repolist  |tail  -4
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601
[root@Va1 ~]# cat  /etc/hosts
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.0.11  Va1
192.168.1.11  Va1
192.168.0.12  Va2
192.168.1.12  Va2
192.168.0.13  Va3
192.168.1.13  Va3
192.168.0.14  Va4
192.168.1.14  Va4
192.168.0.15  Va5
192.168.1.15  Va5
192.168.0.16  Va6
192.168.1.16  Va6
192.168.0.17  Va7
192.168.1.17  Va7
192.168.0.18  Va8
192.168.1.18  Va8
192.168.0.19  Va9
192.168.1.19  Va9

[root@Va1 ~]# yum list  |grep  openjdk^C
[root@Va1 ~]# yum list  |grep  java-1.8.0-openjdk
java-1.8.0-openjdk.x86_64                1:1.8.0.131-11.b12.el7    @anaconda/7.4
java-1.8.0-openjdk-headless.x86_64       1:1.8.0.131-11.b12.el7    @anaconda/7.4
java-1.8.0-openjdk.i686                  1:1.8.0.131-11.b12.el7    CentOS7-1708 
..........................
java-1.8.0-openjdk-src-debug.x86_64      1:1.8.0.131-11.b12.el7    CentOS7-1708 

[root@Va1 ~]# yum  -y  install   java-1.8.0-openjdk  
..............
软件包 1:java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64 已安装并且是最新版本
无须任何处理
[root@Va1 ~]# rpm  -qa  |grep  java-1.8.0-openjdk
java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64
java-1.8.0-openjdk-headless-1.8.0.131-11.b12.el7.x86_64

[root@Va1 ~]# java -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)

/************
[root@room9pc01 ~]# ls   /var/ftp/
ansible                  filebeat-1.2.3-x86_64.rpm    rhel7
CentOS7-1708             kibana-4.5.2-1.x86_64.rpm    share
elasticsearch-2.3.4.rpm  logstash-2.3.4-1.noarch.rpm
elk                      pub
*********/

[root@Va1 ~]# yum  search  elasticsearch
.................
elasticsearch.noarch : Distribution: RPM
filebeat.x86_64 : Sends log files to Logstash or directly to Elasticsearch.
kibana.x86_64 : Explore and visualize your Elasticsearch data.

  名称和简介匹配 only，使用“search all”试试。

[root@Va1 ~]# yum   -y  install  elasticsearch 
................
已安装:
  elasticsearch.noarch 0:2.3.4-1                                                               

完毕！
[root@Va1 ~]# rpm  -qa  |grep   elasticsearch
elasticsearch-2.3.4-1.noarch

[root@Va1 ~]# ls   /etc/elasticsearch/
elasticsearch.yml  logging.yml  scripts

[root@Va1 ~]# cd   /etc/elasticsearch/

在所有节点修改配置文件 /etc/elasticsearch/elasticsearch.yml 

[root@Va1 elasticsearch]# vim   elasticsearch.yml 

[root@Va1 elasticsearch]# sed  -n  54p   elasticsearch.yml
# 将绑定地址设置为特定IP
network.host: 192.168.0.11  # 绑定监听IP

设置bind_host和publish_host上面两个参数 
# 将绑定地址设置为特定IP
# network.host: 192.168.0.11    # 绑定监听IP

[root@Va1 elasticsearch]# grep  -n "network.host"  elasticsearch.yml
54:network.host: 192.168.0.11

[root@Va1 elasticsearch]# systemctl   start  elasticsearch  &&  systemctl  enable  elasticsearch

Created symlink from /etc/systemd/system/multi-user.target.wants/elasticsearch.service to /usr/lib/systemd/system/elasticsearch.service.

# 设置节点间交互的tcp端口,默认是9300 
# transport.tcp.port: 9300 
[root@Va1 elasticsearch]# grep  -n http.port  elasticsearch.yml 
58:# http.port: 9200    # 设置对外服务的http端口,默认为9200 

[root@Va1 elasticsearch]# netstat   -npult  |grep  java
tcp6       0      0 192.168.0.11:9200       :::*                    LISTEN      4026/java           
tcp6       0      0 192.168.0.11:9300       :::*                    LISTEN      4026/java  
         
[root@Va1 elasticsearch]# ps  -C  java
  PID TTY          TIME CMD
 4026 ?        00:00:06 java

http://192.168.0.11:9200/  # 测试 安装成功
{
  "name" : "Skullfire",
  "cluster_name" : "elasticsearch",
  "version" : {
    "number" : "2.3.4",
    "build_hash" : "e455fd0c13dceca8dbbdbb1665d068ae55dabe3f",
    "build_timestamp" : "2016-06-30T11:24:31Z",
    "build_snapshot" : false,
    "lucene_version" : "5.5.0"
  },
  "tagline" : "You Know, for Search"
}
[root@room9pc01 ~]# uptime 
 17:52:36 up  4:34,     8 users,   load average: 0.25, 0.28, 0.26
当前时间    系统已运行的时间 当前在线用户  平均负载：最近1分钟、5分钟、15分钟 系统的负载
平均负载量：0.00, 0.01, 0.05 最后一个信息是系统的平均负载量
可以换算成百分比0%，1%，5%

[root@room9pc01 ~]# cat   /proc/loadavg 
0.34 0.30 0.27 2/651 12825
前3个数字表示平均进程数量外，
后面的1个分数 2/651 的分母表示系统进程总数，分子表示正在运行的进程数；
最后一个数字12825 表示最近运行的进程ID

[root@Va1 elasticsearch]# pwd
/etc/elasticsearch
[root@Va1 elasticsearch]# ls
elasticsearch.yml  logging.yml  scripts

[root@Va1 elasticsearch]# ls  scripts/
[root@Va1 elasticsearch]# elinks   -dump  192.168.0.11:9200

   { "name" : "Skullfire", "cluster_name" : "elasticsearch", "version" : {
   "number" : "2.3.4", "build_hash" :
   "e455fd0c13dceca8dbbdbb1665d068ae55dabe3f", "build_timestamp" :
   "2016-06-30T11:24:31Z", "build_snapshot" : false, "lucene_version" :
   "5.5.0" }, "tagline" : "You Know, for Search" }

[root@Va1 elasticsearch]# grep  -n http.port  elasticsearch.yml 
58:# http.port: 9200    # 设置对外服务的http端口,默认为9200 

[root@Va1 elasticsearch]# ls  /usr/share/elasticsearch/bin/plugin 
/usr/share/elasticsearch/bin/plugin

[root@Va1 elasticsearch]# ls  /usr/share/elasticsearch/
bin  lib  LICENSE.txt  modules  NOTICE.txt  plugins  README.textile

[root@Va1 elasticsearch]# cd

[root@Va1 ~]# yum  -y  install  ansible  |tail  -3
............
[root@Va1 ~]# ansible  --version
ansible 2.4.2.0    ## 显示版本说明安装成功
...........
Ansible配置文件查找顺序

– 首先检测 ANSIBLE_CONFIG 变量定义的配置文件
– 其次检查当前目彔下的 ./ansible.cfg 文件　　　（常用方式）
– 再次检查当前用户家目彔下 ~/ansible.cfg 文件
– 最后检查 /etc/ansible/ansible.cfg 文件

• /etc/ansible/ansible.cfg 默认配置文件路径

• ansible.cfg 配置文件（就两个主要配置文件）

– inventory 是定义托管主机地址配置文件

[root@Va1 ~]# ls
anaconda-ks.cfg  index.html            parameter.json  user3.yaml   user.sh    图片
apache.retry     initial-setup-ks.cfg  parameter.vars  user4.retry  user.yaml  文档
apache.yaml      ip.sh                 ping.yml        user4.yaml   公共       下载
baidu.sh         load.retry            user2.yaml      user5.yaml   模板       音乐
echo.yml         load.yaml             user3.retry     user.retry   视频       桌面
[root@Va1 ~]# ls  /etc/ansible/
ansible.cfg  hosts  roles
[root@Va1 ~]# vim  /etc/ansible/hosts 
[root@Va1 ~]# sed  -n  '44,$p'  /etc/ansible/hosts
[web]
Va2
Va4

[db]
Va3
Va5

[other]
Va6

[app:children]
web
db
[root@Va1 ~]# ansible  app  -a  "rm  -rf  /root/.ansible/*"  ##默认的模块command无效


[root@Va1 ~]# ansible  app -m  shell  -a  "rm  -rf  /root/.ansible/*" ##shell模块万能
 [WARNING]: Consider using file module with state=absent rather than running rm
                考虑使用state=absent的文件模块，而不是运行rm
Va5 | SUCCESS | rc=0 >>
Va2 | SUCCESS | rc=0 >>
Va4 | SUCCESS | rc=0 >>
Va3 | SUCCESS | rc=0 >>

[root@Va1 ~]# ls  /root/.ssh/
id_rsa  id_rsa.pub  known_hosts

exclusive adj. 专用的;高级的;排外的;单独的

[root@Va1 ~]# ansible app  -m  authorized_key  -a  "user=root  exclusive=true  \
manage_dir=true  key='$(< /root/.ssh/id_rsa.pub)'"  -k 
SSH password: 1
.........
Va2 | SUCCESS => {
..............
[root@Va1 ~]# ansible  app   -a  "ls -l  /root/.ansible/"Va2 | SUCCESS | rc=0 >>
总用量 0
drwx------ 3 root root 55 1月  15 18:58 tmp

Va4 | SUCCESS | rc=0 >>
总用量 0
drwx------ 3 root root 55 1月  15 18:58 tmp

Va5 | SUCCESS | rc=0 >>
总用量 0
drwx------ 3 root root 54 1月  15 18:58 tmp

Va3 | SUCCESS | rc=0 >>
总用量 0
drwx------ 3 root root 54 1月  15 18:58 tmp

/****************************
                                     #json 格式传参数  注意大括号{}
[root@Va1 ~]# ansible-playbook  -e   '{"user":{"name":"jj","group":"zuxx","uid":"1133"}}'  user.yaml
..........................

                             # yaml格式传参数 注意大括号{ }, 空格, 逗号
[root@Va1 ~]# ansible-playbook  -e   '{ user: { name: jj2, group: zuxx, uid: 1134 } }'  user.yaml
...............................

[root@Va1 ~]# ansible-playbook -i /etc/ansible/hosts  -e  'nameadd="jinj2"  uid="1126"'  user2.yaml  
                                                               ##在命令行里面传参数 键值对 的方法 ,变量优先级命令行最高
...............................
                                      # 将参数放在文件里面 -e  "@文件路径 " 传参数 
[root@Va1 ~]# ansible-playbook  -e  "@parameter.vars"   user.yaml  ##注意parameter.vars是yaml格式文件

[root@Va1 ~]# cat   parameter.vars  ##注意这是yaml格式文件

user:
  name: testname
  group: admin
  uid: 1135

[root@Va1 ~]# file   parameter.vars
parameter.vars: ASCII text

[root@Va1 ~]# cat   parameter.json
{"user":
  {
    "name":"jsontest",
    "group":"apache",
    "uid":"1136"
  }
}
[root@Va1 ~]# ansible-playbook  -e  "@parameter.json"   user.yaml  ##注意parameter.json是json格式文件
...................
***********/
[root@Va1 ~]# ls  /etc/ansible/
ansible.cfg  hosts  roles
[root@Va1 ~]# ls
anaconda-ks.cfg  index.html            parameter.json  user3.yaml   user.sh    图片
apache.retry     initial-setup-ks.cfg  parameter.vars  user4.retry  user.yaml  文档
apache.yaml      ip.sh                 ping.yml        user4.yaml   公共       下载
baidu.sh         load.retry            user2.yaml      user5.yaml   模板       音乐
echo.yml         load.yaml             user3.retry     user.retry   视频       桌面

[root@Va1 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1984         443        1122           8         417        1353
Swap:          2047           0        2047

[root@Va1 ~]# vim  hosts.yml

[root@Va1 ~]# cat  hosts.yml
---
- hosts: app
  remote_user: root
  tasks:
    - copy:
        src: /etc/hosts
        dest: /etc/hosts
        owner: root
        group: root
        mode: 0644
    - copy:
        src: /etc/yum.repos.d/local.repo
        dest: /etc/yum.repos.d/local.repo
        owner: root
        group: root
        mode: 0644

[root@Va1 ~]# ansible-playbook  -i  /etc/ansible/hosts   hosts.yml

PLAY [app] **************************************************************************

TASK [Gathering Facts] **************************************************************
ok: [Va3]
ok: [Va5]
ok: [Va4]
ok: [Va2]

TASK [copy] ..............
.........
[root@Va1 ~]# file /etc/ansible/hosts
/etc/ansible/hosts: ASCII text

[root@Va1 ~]# vim   hosts
[root@Va1 ~]# cat   hosts
[elas]
Va[2:5]

[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m  shell   -a  "yum clean all >/dev/null && yum repolist  |tail   -4"
 [WARNING]: Consider using yum module rather than running yum

Va2 | SUCCESS | rc=0 >>
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

Va5 | SUCCESS | rc=0 >>
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

Va3 | SUCCESS | rc=0 >>
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

Va4 | SUCCESS | rc=0 >>
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

[root@Va1 ~]# vim  setelk.yaml
[root@Va1 ~]# cat  setelk.yaml
---
- hosts: elas
  remote_user: root
  tasks:
    - yum:
        name: java-1.8.0-openjdk,elasticsearch
        state: latest
    - service:
        name: elasticsearch
        enabled: yes

[root@Va1 ~]# ansible-playbook  -i  /root/hosts  setelk.yaml

PLAY [elas] *************************************************************************

TASK [Gathering Facts] ............
...................
[root@Va1 ~]# ansible elas -i /root/hosts -m shell -a "rpm -q  elasticsearch"

 [WARNING]: Consider using yum, dnf or zypper module rather than running rpm

Va4 | SUCCESS | rc=0 >>
elasticsearch-2.3.4-1.noarch
.............
[root@Va1 ~]# ls   /etc/elasticsearch/
elasticsearch.yml  logging.yml  scripts

[root@Va1 elasticsearch]# sed  -n  54p   elasticsearch.yml

# 将绑定地址设置为特定IP
# network.host: 192.168.0.11    # 绑定监听IP

[root@Va1 ~]# vim  /etc/elasticsearch/elasticsearch.yml 

# 代表一个集群,集群中有多个节点,其中有一个为主节点,这个主节点是可以通过选举产生的,主从节点是对于集群内部来说的. 
# es的一个概念就是去中心化,字面上理解就是无中心节点,这是对于集群外部来说的,
因为从外部来看es集群,在逻辑上是个整体,你与任何一个节点的通信和与整个es集群通信是等价的。 
# cluster.name可以确定你的集群名称,
当你的elasticsearch集群在同一个网段中elasticsearch会自动的找到具有相同cluster.name的elasticsearch服务. 
# 所以当同一个网段具有多个elasticsearch集群时cluster.name就成为同一个集群的标识. 

 17 cluster.name: elk-cluster # 设置集群名称{elasticsearch服务器识别集群的唯一方式}

 23 node.name: Va1  # 节点名称,可自动生成也可手动配置(本主机名).

 54 network.host: 192.168.0.0    # 绑定监听IP特定的网络

# 这是一个集群中的主节点的初始列表,当节点(主节点或者数据节点)启动时使用这个列表进行探测 
 68 discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

[root@Va1 ~]# sed  -n  '17p;23p;54p;68p'  /etc/elasticsearch/elasticsearch.yml 
cluster.name: elk-cluster
node.name: Va1
network.host: 192.168.0.0
discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

                        ## 在覆盖之前将原文件备份，备份文件包含时间信息 backup=yes
 ~]# ansible  other  -m  copy  -a  'src=/root/index.html  dest=/var/www/html/index.html backup=yes'
 ~]# ansible all -m copy -a "src=/home/test.sh dest=/tmp/ owner=root group=root mode=0755"    
#src 主控端文件位置
#dest 被控端目标位置
#owner 文件复制过去后的所有者
#group 文件复制过去后的所属组
#mode  文件的权限设定，执行a+x这种方式

[root@Va1 ~]# cat  hosts
[elas]
Va[2:5]
[root@Va1 ~]# ansible elas -i  /root/hosts -m  copy  -a "src=/etc/elasticsearch/elasticsearch.yml  dest=/etc/elasticsearch/  backup=yes  owner=root  group=root  mode=0644"

Va5 | SUCCESS => {
............................
}
Va3 | SUCCESS => {
.........................
}
Va2 | SUCCESS => {
...................
}
Va4 | SUCCESS => {
    "backup_file": "/etc/elasticsearch/elasticsearch.yml.6437.2019-01-15@20:29:56~", 
    "changed": true, 
    "checksum": "48b3bd67f91c7dcbbba58a84e0cf8805ea1b0039", 
    "dest": "/etc/elasticsearch/elasticsearch.yml", 
    "gid": 0, 
    "group": "root", 
    "md5sum": "f2b222c098736234c83b33abe3583ab4", 
    "mode": "0644", 
    "owner": "root", 
    "size": 3178, 
    "src": "/root/.ansible/tmp/ansible-tmp-1547555395.66-272167774563342/source", 
    "state": "file", 
    "uid": 0
}
[root@Va1 ~]# ansible elas -i  /root/hosts -m  shell  -a "sed  -i  's,^\(node.name:\).*,\1 ${HOSTNAME},'  /etc/elasticsearch/elasticsearch.yml"  ##注意必须 sed 不能是 '单引号' #结果执行失败(但是语法没错)

[root@Va1 ~]# ansible elas -i  /root/hosts -m  shell  -a  'sed  -i  "s,^\(node.name:\).*,\1 ${HOSTNAME},"  /etc/elasticsearch/elasticsearch.yml' ##注意必须  外面是单引号 "sed 双引号"#执行成功


 [WARNING]: Consider using template or lineinfile module rather than running sed

Va5 | SUCCESS | rc=0 >>
Va2 | SUCCESS | rc=0 >>
Va3 | SUCCESS | rc=0 >>
Va4 | SUCCESS | rc=0 >>

[root@Va1 ~]# echo  ${HOSTNAME}
Va1
[root@Va1 ~]# sed  -n  '17p;23p;54p;68p'  /etc/elasticsearch/elasticsearch.yml 
cluster.name: elk-cluster
node.name: Va1
network.host: 192.168.0.0
discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]


[root@Va1 ~]# cat  /root/hosts
[elas]
Va[2:5]
[root@Va1 ~]# ansible  elas  -i  /root/hosts  -m  shell  -a  "systemctl  restart elasticsearch"

Va5 | SUCCESS | rc=0 >>
Va4 | SUCCESS | rc=0 >>
Va2 | SUCCESS | rc=0 >>
Va3 | SUCCESS | rc=0 >>

[root@Va1 ~]# ansible  elas -i /root/hosts -m shell -a "netstat -npult|grep java"Va3 | SUCCESS | rc=0 >>
tcp6       0      0 192.168.0.0:9200        :::*                    LISTEN      7120/java           
tcp6       0      0 192.168.0.0:9300        :::*                    LISTEN      7120/java           

Va2 | SUCCESS | rc=0 >>
tcp6       0      0 192.168.0.0:9200        :::*                    LISTEN      7075/java           
tcp6       0      0 192.168.0.0:9300        :::*                    LISTEN      7075/java           

Va5 | SUCCESS | rc=0 >>
tcp6       0      0 192.168.0.0:9200        :::*                    LISTEN      7070/java           
tcp6       0      0 192.168.0.0:9300        :::*                    LISTEN      7070/java           

Va4 | SUCCESS | rc=0 >>
tcp6       0      0 192.168.0.0:9200        :::*                    LISTEN      7026/java           
tcp6       0      0 192.168.0.0:9300        :::*                    LISTEN      7026/java           

 关系型    --------  非关系型
MySQL    ?--?   NoSQL
Database  ---->   Index
Table     ---->   Type
Row       ---->   Document
Column    ---->   Filed

ELK组成：
    - E：是指Elasticsearch [非关系型数据库,最重要]，完成数据的存储和检索
    - L：是Logstash[可使用 docker 容器技术,数据次重要]，完成数据的采集、过滤及解析
    - K：Kibana [与 apache 作用相同 ] ，以WEB方式展示 

Linux  apache    mysql[关系型]       php[处理后台程序]
L        A         M                  P
L        K         E                  L
Linux  kibana elasticsearch[非关系型] logstash[处理日志的工作[ java开发的 ]]

[root@Va1 ~]# sed  -n  '54p'  /etc/elasticsearch/elasticsearch.yml 
network.host: 192.168.0.0  # 配置文件写错了

http://192.168.0.11:9200/_cluster/health?pretty
{
  "cluster_name" : "elasticsearch",
  "status" : "green",
  "timed_out" : false,
  "number_of_nodes" : 1,   ## 注意不是5个节点,说明配置文件写错了
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}
############################## Network And HTTP ############################### 
# 设置绑定的ip地址,可以是ipv4或ipv6的,默认为0.0.0.0 
# network.bind_host: 192.168.0.1   #只有本机可以访问http接口

# 设置其它节点和该节点交互的ip地址,如果不设置它会自动设置,值必须是个真实的ip地址 
# network.publish_host: 192.168.0.1 

# 同时设置bind_host和publish_host上面两个参数 
# network.host: 192.168.0.1    #绑定监听IP













[root@Va2 ~]# yum  repolist |tail  -4
源标识                                源名称                               状态
!CentOS7-1708                         CentOS7-1708                         9,591
!ansible                              ansible                                  6
repolist: 9,597
[root@Va2 ~]# cat  /etc/yum.repos.d/local.repo 
[CentOS7-1708]
name=CentOS7-1708
gpgcheck=0
baseurl=ftp://192.168.0.254/CentOS7-1708/
enabled=1

[ansible]
name=ansible
baseurl=ftp://192.168.0.254/ansible
gpgcheck=0
enabled=1
[root@Va2 ~]# yum clean  all >/dev/null  && yum repolist  |tail -4
源标识                               源名称                                状态
CentOS7-1708                         CentOS7-1708                          9,591
ansible                              ansible                                  10
repolist: 9,601

[root@Va2 ~]#  ls   /etc/elasticsearch/
elasticsearch.yml  logging.yml  scripts
[root@Va2 ~]#  ls   /etc/elasticsearch/
elasticsearch.yml  elasticsearch.yml.6469.2019-01-15@20:29:56~  logging.yml  scripts

[root@Va2 ~]# sed  -n  "/^node.name:/p"   /etc/elasticsearch/elasticsearch.yml
node.name: Va1

[root@Va2 ~]# echo  $HOSTNAME
Va2
[root@Va2 ~]# echo  ${HOSTNAME}
Va2
[root@Va2 ~]# sed  -n  's,^\(node.name:\).*,\1 ${HOSTNAME},p'  /etc/elasticsearch/elasticsearch.yml
node.name: ${HOSTNAME}

[root@Va2 ~]# sed  -n  '17p;23p;54p;68p'  /etc/elasticsearch/elasticsearch.yml 
cluster.name: elk-cluster
node.name: Va2
network.host: 192.168.0.0
discovery.zen.ping.unicast.hosts: ["Va1", "Va2", "Va3"]

[root@Va2 ~]# 






在所有节点修改配置文件 /etc/elasticsearch/elasticsearch.yml 
cluster.name: my-elk01
node.name: node5
network.host: 0.0.0.0  # 0.0.0.0指在本机的路由表里没有特定条目指明如何到达的所有主机和目的网络
discovery.zen.ping.unicast.hosts: ["node1", "node2", "node3", "node5"]

启动所有节点的 elasticsearch 服务
通过浏览器可以访问任意节点的 http://ip.xx.xx.xx:9200/

验证集群是否正常，访问
http://192.168.4.15:9200/_cluster/health?pretty

{
  "cluster_name" : "my-elk01", #集群名称
  "status" : "green", # 表示正常
  "timed_out" : false,
  "number_of_nodes" : 5, #当前节点数量
  "number_of_data_nodes" : 5,
  "active_primary_shards" : 0,
  "active_shards" : 0,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 0,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 100.0
}

插件的安装 head  kopf  bigdesk
1 拷贝插件 zip 包到一个目录
2 /usr/share/elasticsearch/bin/plugin install file:///插件的位置/插件包.zip 安装

3 验证：
安装完成以后可以通过
/usr/share/elasticsearch/bin/plugin list 看到我们已经安装的插件的名称

4 访问head 插件
它展现ES集群的拓扑结构
可以通过它来进行索引（Index）和节点（Node）级别的操作
它提供一组针对集群的查询API，并将结果以json和表格形式返回
它提供一些快捷菜单，用以展现集群的各种状态
http://192.168.4.11:9200/_plugin/head/


5 kopf 插件安装
kopf是一个ElasticSearch的管理工具，它提供了对ES集群操作的API。
/usr/share/elasticsearch/bin/plugin install file:///xxx-kopf.zip

访问地址
http://192.168.4.11:9200/_plugin/kopf/

6 bigdesk 插件安装
bigdesk是elasticsearch的一个集群监控工具
可以通过它来查看es集群的各种状态，
如：cpu、内存使用情况，索引数据、搜索情况，http连接数等。
/usr/share/elasticsearch/bin/plugin install file:///bigdesk-xxx.zip

访问地址
http://192.168.4.11:9200/_plugin/bigdesk/

使用RESTful API操作elasticsearch
curl -XPUT 'http://192.168.4.11:9200/school/' -d '{
    "settings":{
        "index":{
            "number_of_shards": 5,
            "number_of_replicas": 1
        }
    }
}'

获取索引配置信息：
curl -XGET 'http://192.168.4.11:9200/school/_settings/'
curl -XGET 'http://192.168.4.11:9200/_all/_settings/'

创建文档
curl -XPUT 'http://192.168.4.11:9200/school/students/1' -d '{
    "title": "devops",
    "name":{
        "first": "guzhang",
        "last": "wu"
    },
    "age": 25
}'

查询文档信息
curl -XGET 'http://192.168.4.11:9200/school/students/1'
curl -XGET 'http://192.168.4.11:9200/school/students/1?_source=name,age'

更新文档信息
curl -XPOST 'http://192.168.4.11:9200/school/students/1/_update' -d '{
    "doc":{
        "age": 30
    }
}'

删除文档信息
curl -XDELETE 'http://192.168.4.14:9200/school/students/1'

批量导入数据
curl -XPOST 'http://192.168.4.14:9200/_bulk' --data-binary @shakespeare.json
curl -XPOST 'http://192.168.4.14:9200/_bulk' --data-binary @logs.jsonl
curl -XPOST 'http://192.168.4.14:9200/accounts/act/_bulk?pretty' --data-binary @accounts.json

批量查询数据
curl -XGET 'http://192.168.4.11:9200/_mget?pretty' -d '{ 
    "docs":[
        {
            "_index": "accounts",
            "_type:": "act",
            "_id": 1
        },
        {
            "_index": "accounts",
            "_type:": "act",
            "_id": 2
        },
        {
            "_index": "shakespeare",
            "_type:": "scene",
            "_id": 1
        }
    ]
}'
  






