hadoop 安装 （单机模式）

禁用 selinux 和 iptables
禁用 selinux 和 iptables
禁用 selinux 和 iptables
配置 /etc/hosts 保证所有主机域名能够相互解析
配置 /etc/hosts 保证所有主机域名能够相互解析
配置 /etc/hosts 保证所有主机域名能够相互解析

1、安装 java 
yum install java-1.8.0-openjdk -y

验证：
java -version

2、安装 jps
yum install java-1.8.0-openjdk-devel -y

验证：
jps

3、安装 hadoop 
tar zxf hadoop-2.7.3.tar.gz
mv hadoop-2.7.3 /usr/local/hadoop

修改配置文件的运行环境：
/usr/local/hadoop/etc/hadoop/hadoop-env.sh
export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64/jre"
export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"

验证：
cd /usr/local/hadoop
./bin/hadoop version

统计分析热词
创建数据源
mkdir input
在这个文件夹里面放入需要统计分析的数据
cp *.txt input/

统计分析1  单词出现的频率
./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount input output

统计分析2  某一个关键词出现的频率，例如 dfs 这个词前面字母是 h 的出现的频率
./bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar grep input output1 '(?<=h)dfs'

排错 1
提示  JAVA_HOME is not set and could not be found
表示  JAVA_HOME 没有设置
解决方法：
设置 hadoop-env.sh 里面的 JAVA_HOME 或在运行脚本前面加入前置变量设置
JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64/jre" ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar wordcount input output

排错 2
提示 java.net.UnknownHostException: host: host: unknown error
	at java.net.InetAddress.getLocalHost(InetAddress.java:1505)
表示主机名没有 IP 解析
解决方法：
在 /etc/hosts 里面增加 主机名 IP 对应关系

排错 3
提示：17/07/24 23:10:46 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory file:/usr/local/hadoop/output already exists
表示输出的文件目录已经存在
解决方法：
删除已经存在的目录或更改结果保存位置

伪分布式配置：

xml 配置格式
<property>
        <name>关键字</name>
        <value>变量值</value>
        <description> 描述 </description>
</property>

配置文件路径 /usr/local/hadoop/etc/hadoop/
1 配置 hadoop-env.sh
export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.65-3.b17.el7.x86_64/jre"
export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop"
查找 JAVA_HOME
readlink -f $(which java)

2 配置 core-site.xml
https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-common/core-default.xml

<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>file:///</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/var/hadoop</value>
    </property>
</configuration>

3 配置 hdfs-site.xml
https://hadoop.apache.org/docs/r2.7.3/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>2</value>
        <description> 文件复制份数 </description>
    </property>
    <property>
        <name>dfs.namenode.http-address</name>
        <value>192.168.4.10:50070</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>192.168.4.10:50090</value>
    </property>
</configuration>

常用配置选项
dfs.namenode.name.dir
dfs.datanode.data.dir
dfs.namenode.http-address
dfs.namenode.secondary.http-address
dfs.webhdfs.enabled
dfs.permissions.enabled

4 配置 mapred-site.xml
https://hadoop.apache.org/docs/r2.7.3/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml

<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.jobtracker.http.address</name>
        <value>master:50030</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>master:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>master:19888</value>
    </property>
</configuration>

常用配置选项
mapreduce.framework.name
mapreduce.jobtracker.http.address
mapreduce.jobhistory.address
mapreduce.jobhistory.webapp.address

5 配置 yarn-site.xml
https://hadoop.apache.org/docs/r2.7.3/hadoop-yarn/hadoop-yarn-common/yarn-default.xml

<configuration>

<!-- Site specific YARN configuration properties -->
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>myhadoop</value>
    </property>

    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>master</value>
    </property>
</configuration>


常用配置选项
yarn.nodemanager.aux-services
yarn.nodemanager.aux-services.mapreduce.shuffle.class
yarn.resourcemanager.hostname


GFS是一个可扩展的分布式文件系统,
用于大型的,分布式的,对大量数据进行访问
的应用
GFS可以运行在廉价的普通硬件上,提供容错功能

Map/Reduce
Mapreduce是一种编程模型，是一种编程方法，抽象理论。
Map和Reduce其实是两种操作
Mapreduce是针对分布式并行计算的一套编程模型,
由 Map 和Reduce 组成,
Map是映射,
把指令分发到多个worker上,
Reduce 是规约,
把worker计算出的结果合并

BigTable存储结构化数据,是一个数据库
BigTable建立在GFS,Scheduler,Lock Service 和MapReduce之上
每个Table都是一个多维的稀疏图



Hadoop就是一个实现了Google云计算系统的开源系统，
包括并行计算模型Map/Reduce，
分布式文件系统HDFS，
以及分布式数据库Hbase，
同时Hadoop的相关项目也很丰富，
包括ZooKeeper，Pig，Chukwa，Hive，Hbase，Mahout，flume等.


Google三驾马车——GFS、MapReduce、Bigtable


[root@room9pc01 ~]# unzip   /var/git/Hadoop.zip   -d   /var/ftp/
Archive:  /var/git/Hadoop.zip
  inflating: /var/ftp/hadoop/hadoop-2.7.6.tar.gz  
 extracting: /var/ftp/hadoop/kafka_2.10-0.10.2.1.tgz  
  inflating: /var/ftp/hadoop/zookeeper-3.4.10.tar.gz  

[root@room9pc01 ~]# ls  /var/ftp/
ansible  CentOS7-1708  elk  hadoop  pub  rhel7  share

[root@room9pc01 ~]# ls  /var/ftp/hadoop/
hadoop-2.7.6.tar.gz  kafka_2.10-0.10.2.1.tgz  zookeeper-3.4.10.tar.gz

[root@Va1 ~]# cat  /etc/hosts  #hadoop 对主机名强依赖,必须添加域名解析配置
127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
192.168.0.11  Va1
192.168.1.11  Va1
192.168.0.12  Va2
192.168.1.12  Va2
192.168.0.13  Va3
192.168.1.13  Va3
192.168.0.14  Va4
192.168.1.14  Va4
192.168.0.15  Va5
192.168.1.15  Va5
192.168.0.16  Va6
192.168.1.16  Va6
192.168.0.17  Va7
192.168.1.17  Va7
192.168.0.18  Va8
192.168.1.18  Va8
192.168.0.19  Va9
192.168.1.19  Va9

-------------------------------------------------
[root@Va1 ~]# mkdir   /root/hadoop
[root@Va1 ~]# lftp  192.168.0.254
lftp 192.168.0.254:~> lcd  /root/hadoop/  #选择下载的家目录
lcd 成功, 本地目录=/root/hadoop
lftp 192.168.0.254:~> mget   hadoop/* #从 lftp服务器上一次下载多个文件
290212575 bytes transferred                                     
Total 3 files transferred
lftp 192.168.0.254:/> exit
[root@Va1 ~]# ls  /root/hadoop
hadoop/              hadoop-2.7.6.tar.gz  

[root@Va1 ~]# ls  /root/hadoop/
hadoop-2.7.6.tar.gz  kafka_2.10-0.10.2.1.tgz  zookeeper-3.4.10.tar.gz

[root@Va1 ~]# du  -sh  /root/hadoop/hadoop-2.7.6.tar.gz 
207M	/root/hadoop/hadoop-2.7.6.tar.gz

 ------------------------------------------- 安装java环境 -----------------------
[root@Va1 ~]# yum  -y  install  java-1.8.0-openjdk  java-1.8.0-openjdk-devel
........
已安装:
  java-1.8.0-openjdk-devel.x86_64 1:1.8.0.131-11.b12.el7                                

完毕！
[root@Va1 ~]# java  -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)
 
没添加option的时候，默认列出VM标示符号和简单的class或jar名称.如下:
[root@Va1 ~]# jps  #
1121 Elasticsearch
6158 Jps

----------------------------------  安装hadoop  ---------------------------

[root@Va1 ~]# ls  /root/hadoop/
hadoop-2.7.6.tar.gz  kafka_2.10-0.10.2.1.tgz  zookeeper-3.4.10.tar.gz

[root@Va1 ~]# du  -sh  /root/hadoop/hadoop-2.7.6.tar.gz 
207M	/root/hadoop/hadoop-2.7.6.tar.gz

[root@Va1 ~]# tar  -xzvf  /root/hadoop/hadoop-2.7.6.tar.gz  -C   /usr/local/
..............
[root@Va1 ~]# mv   /usr/local/hadoop-2.7.6/    /usr/local/hadoop/
[root@Va1 ~]# ls  /usr/local/hadoop/
bin  etc  include  lib  libexec  LICENSE.txt  NOTICE.txt  README.txt  sbin  share

[root@Va1 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1984        1622          76           1         285         168
Swap:          2047          10        2037

[root@Va1 ~]# systemctl  stop  elasticsearch  kibana && systemctl  disable  elasticsearch  kibana.service 

[root@Va1 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1984         128        1572           1         283        1662
Swap:          2047          10        2037

[root@Va1 ~]# ls  /usr/local/hadoop/sbin/
distribute-exclude.sh    start-all.cmd        stop-balancer.sh
.........................
slaves.sh                stop-all.sh

[root@Va1 ~]# ls  /usr/local/hadoop/bin/
container-executor  hdfs      mapred.cmd               yarn
hadoop              hdfs.cmd  rcc                      yarn.cmd
hadoop.cmd          mapred    test-container-executor

[root@Va1 ~]# cd   /usr/local/hadoop/
[root@Va1 hadoop]# ./bin/hadoop   version   ## 查看 hadoop 版本
Error: JAVA_HOME is not set and could not be found.
            Java_Home未设置，找不到

[root@Va1 hadoop]# rpm  -ql  java-1.8.0-openjdk  |grep  jre  #查看 Java_Home 家目录路径
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre/bin/policytool
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre/lib/amd64/libawt_xawt.so
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre/lib/amd64/libjawt.so
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre/lib/amd64/libjsoundalsa.so
/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre/lib/amd64/libsplashscreen.so

[root@Va1 hadoop]# cd   /usr/local/hadoop/etc/hadoop/  #hadoop配置文件路径

[root@Va1 hadoop]# ll  hadoop-env.sh              #hadoop 运行环境变量的配置文件
-rw-r--r-- 1 20415 101 4224 4月  18 2018 hadoop-env.sh


[root@Va1 hadoop]# sed  -n  "/JAVA_HOME=/p;/HADOOP_CONF_DIR=/p"  hadoop-env.sh
export JAVA_HOME=${JAVA_HOME}                   #查看 Java_Home 家目录路径
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-"/etc/hadoop"} #hadoop配置文件路径

--------------------------------- 修改配置文件的运行环境： ----------------------------------------

                                          # 设置 Java_Home 家目录路径
[root@Va1 hadoop]# sed  -i   "/JAVA_HOME=/s#\(=\).*#\1\"/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre\"#"   hadoop-env.sh

[root@Va1 hadoop]# ls   /usr/local/hadoop/etc/hadoop/  # 全是hadoop配置文件
........................
[root@Va1 hadoop]# ls   /usr/local/hadoop/etc/hadoop/  # 全是hadoop配置文件
capacity-scheduler.xml      httpfs-env.sh            mapred-env.sh
configuration.xsl           httpfs-log4j.properties  mapred-queues.xml.template
container-executor.cfg      httpfs-signature.secret  mapred-site.xml.template
core-site.xml               httpfs-site.xml          slaves
hadoop-env.cmd              kms-acls.xml             ssl-client.xml.example
hadoop-env.sh               kms-env.sh               ssl-server.xml.example
.......................   
                                                      # 设置 hadoop配置文件路径
[root@Va1 hadoop]# sed  -i  "/HADOOP_CONF_DIR=\${/s#\${HADOOP_CONF_DIR:-.*#\"/usr/local/hadoop/etc/hadoop/\"#"  hadoop-env.sh

                                                   #查看 Java_Home 家目录路径 #hadoop配置文件路径
[root@Va1 hadoop]# egrep  -n  "JAVA_HOME=|HADOOP_CONF_DIR="  hadoop-env.sh

25:export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre"  #Java_Home 家目录路径
33:export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop/"   #hadoop配置文件路径

[root@Va1 hadoop]# grep  -Env "^(\s*#|$)"  hadoop-env.sh   #查看 Java_Home 家目录路径 #hadoop配置文件路径

                            #查看 Java_Home 家目录路径
25:export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre"

33:export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop/"  #hadoop配置文件路径

36:for f in $HADOOP_HOME/contrib/capacity-scheduler/*.jar; do
37:  if [ "$HADOOP_CLASSPATH" ]; then
38:    export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$f
39:  else
40:    export HADOOP_CLASSPATH=$f
41:  fi
42:done
.....................

[root@Va1 hadoop]# /usr/local/hadoop/bin/hadoop  version ## 查看 hadoop 版本
...................
[root@Va1 hadoop]# cd   /usr/local/hadoop/bin/
[root@Va1 bin]# ls
container-executor  hdfs      mapred.cmd               yarn
hadoop              hdfs.cmd  rcc                      yarn.cmd
hadoop.cmd          mapred    test-container-executor

[root@Va1 bin]# /usr/local/hadoop/bin/hadoop   version   ## 查看 hadoop 版本
Hadoop 2.7.6
Subversion https://shv@git-wip-us.apache.org/repos/asf/hadoop.git -r 085099c66cf28be31604560c376fa282e69282b8
Compiled by kshvachk on 2018-04-18T01:33Z
Compiled with protoc 2.5.0
From source with checksum 71e2695531cb3360ab74598755d036
This command was run using /usr/local/hadoop/share/hadoop/common/hadoop-common-2.7.6.jar

[root@Va1 bin]# pwd
/usr/local/hadoop/bin
[root@Va1 bin]# cd  ../
[root@Va1 hadoop]# pwd
/usr/local/hadoop
[root@Va1 hadoop]# ls
bin  etc  include  lib  libexec  LICENSE.txt  NOTICE.txt  README.txt  sbin  share

[root@Va1 hadoop]# mkdir  newtest  # 创建数据源

[root@Va1 hadoop]# cp  *.txt  newtest/ # 创建数据源
[root@Va1 hadoop]# ls   newtest/
LICENSE.txt  NOTICE.txt  README.txt

[root@Va1 hadoop]# ./bin/hadoop  --help  |grep  -A2  "jar <jar>"
  jar <jar>            run a jar file
                       note: please use "yarn jar" to launch
                             YARN applications, not this command.
           请使用“yarn jar”启动 yarn 应用程序，而不是此命令。

[root@Va1 hadoop]# ./bin/hadoop  jar  share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar
  
An example program must be given as the first argument.
必须给出一个示例程序作为第一个参数。
Valid program names are:
有效的程序名是：
  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
...........................
  distbbp: A map/reduce program that uses a BBP-type formula to compute exact bits of Pi.
  grep: A map/reduce program that counts the matches of a regex in the input.
  join: A job that effects a join over sorted, equally partitioned datasets
................
  sort: A map/reduce program that sorts the data written by the random writer.
..................
  wordcount: A map/reduce program that counts the words in the input files.
  wordmean: A map/reduce program that counts the average length of the words in the input files.
...............
[root@Va1 hadoop]# ./bin/hadoop  jar  share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar   |grep  wordcount

聚合字计数 : 一种基于聚合的映射/减少程序，对输入文件中的字进行计数。
  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.
  wordcount: A map/reduce program that counts the words in the input files.
                对输入文件中的字进行计数的映射/减少程序。


# 可执行文件/usr/local/hadoop/bin/hadoop  jar（使用hadoop运行jar包）   运行的jar文件(.jar包)   (要使用的类名)程序名wordcount  (参数)输入的文件路径(已有的)   (参数)输出的文件路径(可以是还不存在的文件夹)

[root@Va1 hadoop]# ./bin/hadoop  jar  share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar   wordcount
Usage: wordcount <in> [<in>...] <out>

# 可执行文件/usr/local/hadoop/bin/hadoop  jar  运行的jar文件(.jar包)   (参数)程序名wordcount  输入的文件路径(已有的)   输出的文件路径(可以是还不存在的文件夹)
  ----------------------------统计分析1  单词出现的频率 ----------------------------

[root@Va1 hadoop]# ./bin/hadoop  jar  share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar   wordcount  newtest  new2  # 统计出现频率(对输入文件中的字进行计数)
...................
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=102768
	File Output Format Counters 
		Bytes Written=30538
[root@Va1 hadoop]# ll  new2/
总用量 32
-rw-r--r-- 1 root root 30290 1月  24 19:57 part-r-00000
-rw-r--r-- 1 root root     0 1月  24 19:57 _SUCCESS

[root@Va1 hadoop]# head  -2  new2/part-r-00000
""AS	2
"AS	17
[root@Va1 hadoop]# tail   -3  new2/part-r-00000
“You”	2
“commercial	3
“control”	1

[root@Va1 hadoop]# grep  701  new2/part-r-00000 ##查看结果中 统计出现频率最大的字词
252.227-7014(a)(1))	1
the	701
 252.227-7014(a)(1))	1


[root@Va1 hadoop]# mkdir   olddir/   # 创建数据源
[root@Va1 hadoop]# cp  *.txt   olddir/

                    -------------------------------------- 统计分析1  单词出现的频率 ------------------------------------

[root@Va1 hadoop]# /usr/local/hadoop/bin/hadoop  jar    share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar   wordcount   olddir/   newdir

# 可执行文件/usr/local/hadoop/bin/hadoop  jar（使用hadoop运行jar包）   运行的jar文件(.jar包)   (要使用的类名)程序名wordcount  (参数)输入的文件路径(已有的)   (参数)输出的文件路径(可以是还不存在的文件夹)

19/01/24 20:51:59 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
19/01/24 20:51:59 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
19/01/24 20:51:59 INFO input.FileInputFormat: Total input paths to process : 3
19/01/24 20:51:59 INFO mapreduce.JobSubmitter: number of splits:3
....................
	File System Counters
		FILE: Number of bytes read=1665799
		FILE: Number of bytes written=2587463
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2062
.................
	Shuffle Errors
        ...............
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=102768
	File Output Format Counters 
		Bytes Written=30538
[root@Va1 hadoop]#  ll  newdir/
总用量 32
-rw-r--r-- 1 root root 30290 1月  24 20:51 part-r-00000
-rw-r--r-- 1 root root     0 1月  24 20:51 _SUCCESS

非打印字符
非打印字符也可以是正则表达式的组成部分。下表列出了表示非打印字符的转义序列：
\s	匹配任何空白字符，包括空格、制表符、换页符等等。等价于 [ \f\n\r\t\v]。注意 Unicode 正则表达式会匹配全角空格符。
\S	匹配任何非空白字符。等价于 [^ \f\n\r\t\v]。
\t	匹配一个制表符。等价于 \x09 和 \cI。
\v	匹配一个垂直制表符。等价于 \x0b 和 \cK。
\f	匹配一个换页符。等价于 \x0c 和 \cL。
\n	匹配一个换行符。等价于 \x0a 和 \cJ。
\r	匹配一个回车符。等价于 \x0d 和 \cM。
http://www.runoob.com/regexp/regexp-syntax.html

[root@Va1 hadoop]# egrep  -n  "\s([0-9]){3,}"   newdir/part-r-00000 
124:*	174
768:OF	169
770:OR	170
930:THE	116
1028:You	125
1037:a	157
1105:and	285
1110:any	129
1197:by	134
1657:in	174
1710:is	100
1920:of	448
1941:or	277
2265:that	119
2267:the	701
2283:this	183
2289:to	253
2369:with	105
[root@Va1 hadoop]# ls  newdir/
part-r-00000  _SUCCESS
[root@Va1 hadoop]# ls  olddir/
LICENSE.txt  NOTICE.txt  README.txt

[root@Va1 hadoop]# cat  newdir/_SUCCESS 
[root@Va1 hadoop]# ll  newdir/_SUCCESS
-rw-r--r-- 1 root root 0 1月  24 20:51 newdir/_SUCCESS

# 可执行文件/usr/local/hadoop/bin/hadoop  jar（使用hadoop运行jar包）   运行的jar文件(.jar包)   (要使用的类名)程序名wordcount  (参数)输入的文件路径(已有的)   (参数)输出的文件路径(可以是还不存在的文件夹)

[root@Va1 hadoop]# /usr/local/hadoop/bin/hadoop  jar    share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar   wordcount   olddir/   newdir  
         # 报错提示文件已经存在/usr/local/hadoop/newdir already exists
........................

[root@Va1 hadoop]# 统计分析2  某一个关键词出现的频率，例如 dfs 这个词前面字母是 h 的出现的频率

# 可执行文件/usr/local/hadoop/bin/hadoop  jar（使用hadoop运行jar包）   运行的jar文件(.jar包)   (要使用的类名)程序名wordcount  (参数)输入的文件路径(已有的)   (参数)输出的文件路径(可以是还不存在的文件夹)

[root@Va1 hadoop]# /usr/local/hadoop/bin/hadoop  jar    share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar   grep   olddir/  newdir2   '(?<=h)dfs'

.......................
[root@Va1 hadoop]# ls   
bin  include  libexec      newdir   NOTICE.txt  README.txt  share
etc  lib      LICENSE.txt  newdir2  olddir      sbin
[root@Va1 hadoop]# ls   newdir2/
part-r-00000  _SUCCESS

[root@Va1 hadoop]# cat  newdir2/part-r-00000
10	dfs
------------- 统计分析  某一个关键词出现的频率，例如 he 这个词前面字母是 t 的出现的频率 ----------

[root@Va1 hadoop]# /usr/local/hadoop/bin/hadoop  jar    share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.6.jar   grep   olddir/  newdir3  '(?<=t)he'
..............
	      WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=117
	File Output Format Counters 
		Bytes Written=19
[root@Va1 hadoop]# ls
bin  include  libexec      newdir   newdir3     olddir      sbin
etc  lib      LICENSE.txt  newdir2  NOTICE.txt  README.txt  share
[root@Va1 hadoop]# ls   newdir3/
part-r-00000  _SUCCESS
[root@Va1 hadoop]# cat  newdir3/part-r-00000 
891	he
[root@Va1 ~]# free  -m
              total        used        free      shared  buff/cache   available
Mem:           1984         107        1736           8         140        1717
Swap:          2047           0        2047
[root@Va1 ~]# echo  "scale=2;1024/128" |bc
8.00
[root@Va1 ~]# echo  "scale=2;1024%128" |bc
0
[root@Va1 ~]# echo  "scale=2;128*8" |bc
1024
 [root@Va1 ~]# egrep  -nv  "^(\s*#|$)"  /usr/local/hadoop/etc/hadoop/hadoop-env.sh 
25:export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre"
33:export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop/"
36:for f in $HADOOP_HOME/contrib/capacity-scheduler/*.jar; do
37:  if [ "$HADOOP_CLASSPATH" ]; then
38:    export HADOOP_CLASSPATH=$HADOOP_CLASSPATH:$f
39:  else
40:    export HADOOP_CLASSPATH=$f
41:  fi
42:done
49:export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true"
52:export HADOOP_NAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
53:export HADOOP_DATANODE_OPTS="-Dhadoop.security.logger=ERROR,RFAS $HADOOP_DATANODE_OPTS"
55:export HADOOP_SECONDARYNAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"
57:export HADOOP_NFS3_OPTS="$HADOOP_NFS3_OPTS"
58:export HADOOP_PORTMAP_OPTS="-Xmx512m $HADOOP_PORTMAP_OPTS"
61:export HADOOP_CLIENT_OPTS="-Xmx512m $HADOOP_CLIENT_OPTS"
69:export HADOOP_SECURE_DN_USER=${HADOOP_SECURE_DN_USER}
75:export HADOOP_SECURE_DN_LOG_DIR=${HADOOP_LOG_DIR}/${HADOOP_HDFS_USER}
94:export HADOOP_PID_DIR=${HADOOP_PID_DIR}
95:export HADOOP_SECURE_DN_PID_DIR=${HADOOP_PID_DIR}
98:export HADOOP_IDENT_STRING=$USER

[root@Va1 ~]# ls  /usr/local/hadoop/
bin  include  libexec      newdir   newdir3     olddir      sbin
etc  lib      LICENSE.txt  newdir2  NOTICE.txt  README.txt  share

[root@Va1 ~]# cd   /usr/local/hadoop/bin/ ;ls
container-executor  hdfs      mapred.cmd               yarn
hadoop              hdfs.cmd  rcc                      yarn.cmd
hadoop.cmd          mapred    test-container-executor

[root@Va1 bin]# head  -4 /usr/local/hadoop/bin/hadoop
#!/usr/bin/env bash
.............

[root@Va1 bin]# file  /usr/bin/env
/usr/bin/env: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked 
(uses shared libs), for GNU/Linux 2.6.32, BuildID[sha1]=4279a25ddbac2a7480923cd05d70e33a73dce721, stripped
 ELF 电子测位器，电子定位器(Electronic Location Finder)
一种为Linux系统所采用的通用文件格式，支持动态连接

[root@Va1 bin]# file   /usr/local/hadoop/bin/hadoop
/usr/local/hadoop/bin/hadoop: a /usr/bin/env bash script, ASCII text executable

 ###  /usr/local/hadoop/bin/hadoop  version ## 查看 hadoop 版本

---------------------------- rsync 本地同步至远程 ------------------------- 
daemon模式
1、服务启动方式
1.1、对于负荷较重的 rsync 服务器应该使用独立运行方式
# yum install rsync xinetd --服务安装
# /usr/bin/rsync --daemon

1.2、对于负荷较轻的 rsync 服务器可以使用 xinetd 运行方式
# yum install rsync xinetd --服务安装
# vim /etc/xinetd.d/rsync --配置托管服务，将下项改为 no
disable = no
# /etc/init.d/xinetd start --启动托管服务 xinetd
# chkconfig rsync on
# netstat -ntpl | grep 873 --查看服务是否启动
..........
服务端配置
# vim /etc/rsyncd.conf --为 rsyncd 服务编辑配置文件，默认没有，需自己编辑
uid = root --rsync运行权限为root
gid = root --rsync运行权限为root
use chroot = no --是否让进程离开工作目录
max connections = 5 --最大并发连接数，0为不限制
........................
[web1] --模块名称
path = /data/test/src --该模块存放文件的基础路径
ignore errors = yes --忽略一些无关的I/O错误
read only = no --客户端可以上传
write only = no --客户端可以下载
hosts allow = 192.168.22.12 --允许连接的客户端主机ip
hosts deny = * --黑名单，*表示任何主机
list = yes
auth users = web --认证此模块的用户名
secrets file = /etc/web.passwd --指定存放“用户名：密码”格式的文件
# mkdir /data/test/src --创建基础目录
# mkdir /data/test/src/george --再创建一个目录
# touch /data/test/src/{1,2,3}
# echo "web:123" > /etc/web.passwd --创建密码文件
# chmod 600 /etc/web.passwd

# service xinetd restart
................
# rsync -ir --password-file=/tmp/rsync.password web@192.168.22.11::web1 --递归列出服务端 web1 模块的文件
# rsync -avzP --exclude="*3*" --password-file=/tmp/rsync.password web@192.168.22.11::web1  /data/test/ --同步除了路径以及文件名中包含 “3” *的所有文件

、通过密码文件同步
# echo "123"> /tmp/rsync.password
# chmod 600 /tmp/rsync.password
# rsync -avzP --delete --password-file=/tmp/rsync.password web@192.168.22.11::web1 /data/test/ --调用密码文件

http://www.cnblogs.com/george-guo/p/7718515.html

rsync 参数说明：
-a --参数，相当于-rlptgoD， 
-r --是递归 
-l --是链接文件，意思是拷贝链接文件
-i --列出 rsync 服务器中的文件
-p --表示保持文件原有权限
-t --保持文件原有时间 
-g --保持文件原有用户组 
-o --保持文件原有属主 
-D --相当于块设备文件 
-z --传输时压缩
-P --传输进度 
-v --传输时的进度等信息，和-P有点关系 

[root@Va1 ~]# for  i  in  192.168.0.1{2..9};
do rsync  -av   /etc/yum.repos.d/local.repo '-e  ssh  -p22'  root@${i}:/etc/yum.repos.d/;
done
root@192.168.0.12's password: 1

[root@Va1 bin]# cd    /usr/local/hadoop/etc/hadoop/
[root@Va1 hadoop]# ls
capacity-scheduler.xml      kms-env.sh
configuration.xsl           kms-log4j.properties
container-executor.cfg      kms-site.xml
core-site.xml               log4j.properties
hadoop-env.cmd              mapred-env.cmd
hadoop-env.sh               mapred-env.sh
hadoop-metrics2.properties  mapred-queues.xml.template
hadoop-metrics.properties   mapred-site.xml.template
hadoop-policy.xml           slaves
hdfs-site.xml               ssl-client.xml.example
httpfs-env.sh               ssl-server.xml.example
httpfs-log4j.properties     yarn-env.cmd
httpfs-signature.secret     yarn-env.sh
httpfs-site.xml             yarn-site.xml
kms-acls.xml
====================================================
配置 /etc/hosts 保证所有主机域名能够相互解析
==========   完全分布式 系统规划 =======================
主机                            角色                 软件 
192.168.0.11 Va1       NameNode           HDFS
                   SecondaryNameNode
192.168.0.12 Va2      DataNode            HDFS
192.168.0.13 Va3      DataNode            HDFS
192.168.0.14 Va4      DataNode            HDFS

  NameNode：是Master节点，是大领导。 
SecondaryNameNode：是一个小弟，非 NameNode的热备份
  Datanode 提供真实文件数据的存储服务。

Hadoop Distributed File  System(HDFS)：
Hadoop分布式文件系统，
提供 高吞吐量 应用程序 数据访问，并具有高容错性。

 Hadoop常用组件以及核心组件有哪些

HDFS：Hadoop分布式文件系统（核心组件）
HDFS也是按照Master和Slave的结构。
分NameNode、SecondaryNameNode、DataNode这几个角色。

MapReduce：分布式计算框架（核心组件）
Yarn：集群资源管理系统（核心组件）

Zookeeper：分布式协作服务
Hbase：分布式列存数据库
Hive：基于Hadoop的数据仓库
Sqoop：数据同步工具
Pig：基于Hadoop的数据流系统
Mahout：数据挖掘算法库
Flume：日志收集工具

Yarn，英文全名是 Yet Another Resource Negotiator，
是由雅虎开发的第二代集群资源调度器

[root@Va1 hadoop]# pwd
/usr/local/hadoop/etc/hadoop
[root@Va1 hadoop]# cp   mapred-site.xml.template  mapred-site.xml
[root@Va1 hadoop]# ll  mapred-site.xml
-rw-r--r-- 1 root root 758 1月  25 15:24 mapred-site.xml
[root@Va1 hadoop]# ll  core-site.xml   hadoop-env.sh   hdfs-site.xml   mapred-site.xml   slaves   yarn-site.xml 
-rw-r--r-- 1 20415  101  774 4月  18 2018 core-site.xml # 全局配置文件
-rw-r--r-- 1 20415  101 4275 1月  24 19:06 hadoop-env.sh
-rw-r--r-- 1 20415  101  775 4月  18 2018 hdfs-site.xml  # HDFS：Hadoop分布式文件系统（核心组件）
-rw-r--r-- 1 root  root  758 1月  25 15:24 mapred-site.xml # MapReduce：分布式计算框架（核心组件）
-rw-r--r-- 1 20415  101   10 4月  18 2018 slaves  # 节点配置文件(主机名)
-rw-r--r-- 1 20415  101  690 4月  18 2018 yarn-site.xml  # Yarn：集群资源管理系统（核心组件）

                          #查看 Java_Home 家目录路径 #hadoop配置文件路径
[root@Va1 hadoop]# egrep  -n  "JAVA_HOME=|HADOOP_CONF_DIR="  hadoop-env.sh

25:export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre" 
         #Java_Home 家目录路径
33:export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop/"   #hadoop配置文件路径

[root@Va1 ~]# ping  -c1  Va2 >/dev/null  && echo Va2 ok;ping -c1 Va3 >/dev/null && echo Va3 ok ;ping  -c1  Va4 >/dev/null  && echo Va4 ok
Va2 ok
Va3 ok
Va4 ok
/*********************************************
SSH 为 Secure Shell 的缩写，
SSH 为建立在应用层基础上的安全协议。
SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议

ssh-keygen -t rsa -b 4096 -C "邮箱"
-t 表示密钥的类型 ，-b表示密钥的长度，-C 用于识别这个密钥的注释 

这条命令的目的是为了让本地机器ssh登录远程机器上的GitHub账户无需输入密码

ssh-keygen -b 2048 -t rsa                    
#这里的-b 2048 是密钥加密的长度，最好设大点

key文件会保存在/root/.ssh目录下
这时候.ssh目下会多出几个文件

id_rsa   私钥文件
id_rsa.pub  公钥文件,这个文件里的内容要放到其它主机里面去。

-t rsa：t是type的缩写

-t即指定密钥的类型，密钥的类型有两种，一种是RSA，一种是DSA

-N new_passphrase 
提供一个新密码。 

[root@Va1 .ssh]# >  known_hosts
[root@Va1 .ssh]# ssh-keygen  -t  rsa  -b  2048  -N  ''  ##注意-N 空格''
# ssh-keygen  -t 指定密钥的类型  -b 指定密钥长度  -N new_passphrase提供一个新的密码

[root@Va1 ~]# ls  /root/.ssh/
id_rsa  id_rsa.pub  known_hosts

ssh-copy-id 命令可以把本地的ssh公钥文件安装到远程主机对应的账户下。
用ssh-copy-id -i  ~/.ssh/id_rsa.pub  root@192.168.0.12将公钥复制到远程机器中
“-i”选项 指定 这个认证文件（默认是~/.ssh/id_rsa.pub）被使用，
                     不管在你的ssh-agent那里是否有任何密钥

ssh-copy-id 将key写到远程机器的 ~/ .ssh/authorized_key 文件中
[root@Va2 ~]# ls  /root/.ssh/
authorized_keys
[root@Va2 ~]# ls  ~/.ssh/
authorized_keys
[root@Va2 ~]# rm  -f  ~/.ssh/authorized_keys 
[root@Va1 ~]# rm  -f /root/.ssh/*
[root@Va1 ~]# ls  /root/.ssh/
[root@Va1 ~]# vim   /etc/ssh/ssh_config  #客户端配置文件
[root@Va1 ~]# egrep   -nA2  "^Host *"   /etc/ssh/ssh_config
58:Host *
59-	GSSAPIAuthentication yes
60-        StrictHostKeyChecking no

[root@Va1 ~]# ssh-keygen   -t  rsa  -b 2048 -N ''   # 生成免密码登陆的密码钥匙

Generating public/private rsa key pair.
Enter file in which to save the key (/root/.ssh/id_rsa): 
Your identification has been saved in /root/.ssh/id_rsa.
Your public key has been saved in /root/.ssh/id_rsa.pub.
The key fingerprint is:直接回车
SHA256:Yg1RJNIpI6nfu28eUNTKHLyPfIqU5JGdEELhC9dXy2M root@Va1
The key's randomart image is:
+---[RSA 2048]----+
| .+oo++=+        |
| .oo+o==..       |
|..o..O+=E        |
|.o .+oB+ .       |
| ..+.+ooS        |
|  . =oo.o        |
|   . o.o         |
|    o o.         |
|    .=o          |
+----[SHA256]-----+

[root@Va1 ~]# ls  /root/.ssh/
id_rsa  id_rsa.pub
                             # 批量传递公钥
[root@Va1 ~]# for  i in  Va{2..4}; do 
> ssh-copy-id  -i  ~/.ssh/id_rsa.pub  root@$i
> done

/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@va2's password:  输入密码
.........
[root@Va1 ~]# ls  /root/.ssh/
id_rsa  id_rsa.pub  known_hosts

[root@Va1 ~]# cat  /root/.ssh/known_hosts 
va2,192.168.0.12 ecdsa-sha2-nistp256 AAAAE2VjZHNhLX...............
va3,192.168.0.13 ecdsa-sha2-nistp256 AAAAE2VjZHNhL.............
va4,192.168.0.14 ecdsa-sha2-nistp256 AAAAE2................

[root@Va1 ~]#  cat  /root/.ssh/id_rsa.pub 
ssh-rsa AAAAB3Nza.............5WuZ root@Va1

[root@Va2 ~]# cat   ~/.ssh/authorized_keys 
ssh-rsa AAAAB3Nz............WuZ root@Va1

---------- 注意必须同时给自己本身复制一份公钥  配置ssh信任关系,包括本机都不能出现 输入yes 的现象----------------

[root@Va1 ~]#  ssh-copy-id  -i  ~/.ssh/id_rsa.pub  Va1  #给自己本身复制一份公钥(非常重要)

/usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: "/root/.ssh/id_rsa.pub"
/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed
/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys
root@va1's password: 输入密码

Number of key(s) added: 1

Now try logging into the machine, with:   "ssh 'Va1'"
and check to make sure that only the key(s) you wanted were added.

[root@Va1 ~]# ls  /root/.ssh/
authorized_keys  id_rsa  id_rsa.pub  known_hosts
[root@Va1 ~]# cat   /root/.ssh/known_hosts 
va2,192.168.0.12 ecdsa-sha2-nistp256 AAAAE2Vj............WMY=
va3,192.168.0.13 ecdsa-sha2-nistp256 AAAAE2Vj............MY=
va4,192.168.0.14 ecdsa-sha2-nistp256 AAAAE2V..............WWMY=
va1,192.168.0.11 ecdsa-sha2-nistp256 AAAAE2V..............WMY=

--------------------------  批量远程执行命令 --------------------------
[root@Va1 ~]# for  i   in  Va{2..4};do
> ssh -lroot -p22  root@$i   hostname;done
Va2
Va3
Va4
[root@Va1 ~]# function  sshhost(){
> for  i   in  Va{2..4};do
> ssh -lroot -p22  root@$i   hostname;done
> }
[root@Va1 ~]# type  sshhost 
sshhost 是函数
sshhost () 
{ 
    for i in Va{2..4};
    do
        ssh -lroot -p22 root@$i hostname;
    done
}
[root@Va1 ~]# which  sshhost
/usr/bin/which: no sshhost in (/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin)
[root@Va1 ~]# sshhost
Va2
Va3
Va4
[root@Va1 ~]#  cd  /usr/local/hadoop/etc/hadoop/

[root@Va1 hadoop]# pwd
/usr/local/hadoop/etc/hadoop

[root@Va1 hadoop]# ll  core-site.xml   hadoop-env.sh   hdfs-site.xml   mapred-site.xml   slaves   yarn-site.xml 
-rw-r--r-- 1 20415  101  774 4月  18 2018 core-site.xml # 全局配置文件
-rw-r--r-- 1 20415  101 4275 1月  24 19:06 hadoop-env.sh
-rw-r--r-- 1 20415  101  775 4月  18 2018 hdfs-site.xml  # HDFS：Hadoop分布式文件系统（核心组件）
-rw-r--r-- 1 root  root  758 1月  25 15:24 mapred-site.xml # MapReduce：分布式计算框架（核心组件）
-rw-r--r-- 1 20415  101   10 4月  18 2018 slaves  # 节点配置文件(主机名)
-rw-r--r-- 1 20415  101  690 4月  18 2018 yarn-site.xml  # Yarn：集群资源管理系统（核心组件）

                          #查看 Java_Home 家目录路径 #hadoop配置文件路径
[root@Va1 hadoop]# egrep  -n  "JAVA_HOME=|HADOOP_CONF_DIR="  hadoop-env.sh

25:export JAVA_HOME="/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64/jre" 
         #Java_Home 家目录路径
33:export HADOOP_CONF_DIR="/usr/local/hadoop/etc/hadoop/"   #hadoop配置文件路径





对外部客户机而言，
HDFS就像一个传统的 分级文件系统，
可以进行 增 删 改 查 或 重命名 等常规文件操作。

但实际上HDFS中的文件被分成块，
然后复制到多个计算机中，
这与传统的RAID架构大不相同。


]# /usr/local/hadoop/bin/hadoop   version   ## 查看 hadoop 版本
Hadoop 2.7.6

http://hadoop.apache.org/   # hadoop 官网网页链接较慢
http://hadoop.apache.org/doc
Index of /docs
.............
[DIR]	r2.7.6/	2018-09-07 15:17	- # 点击链接 [r2.7.6/]

http://hadoop.apache.org/docs/r2.7.6/
 靠近网页左下角 的链接文档
Configuration
 core-default.xml 对应配置文件 /usr/local/hadoop/etc/hadoop/core-site.xml

 hdfs-default.xml 对应配置文件 /usr/local/hadoop/etc/hadoop/hdfs-site.xml 
 mapred-default.xml 对应配置文件 /usr/local/hadoop/etc/hadoop/mapred-site.xml
 yarn-default.xml  对应配置文件   /usr/local/hadoop/etc/hadoop/yarn-site.xml 
 Deprecated Properties 对应配置文件?

点击 core-default.xml 打开网页
http://hadoop.apache.org/docs/r2.7.6/hadoop-project-dist/hadoop-common/core-default.xml
 name {<name>...}   value {<value> ...}   description{相当于注释类的作用,可省略<description>...}

 name                                value      description
hadoop.common.configuration.version   0.23.0     version of this configuration file

hadoop.tmp.dir  /tmp/hadoop-${user.name}  其他临时目录的基础(相当于/var/lib/mysql/ 所有数据的根目录)
...........
hdfs 规定了hadoop使用的存储方式(默认本地文件file:///存储方式,即本地硬盘存储 )

fs.defaultFS    file:///     默认文件系统的名称。其方案和权限决定文件系统实现的URI。
                             URI的方案确定了命名文件系统实现类的配置属性（fs.scheme.impl）。
                             URI的权限用于确定文件系统的主机、端口等。


property    n. 特性，属性;财产，地产;[戏]道具;所有权
<configuration>
 <property>
  <name> </name>
  <value> </value>
  <description> </description>
 </property>
</configuration>

Hadoop Distributed File  System(HDFS)
Hadoop分布式文件系统，
提供 高吞吐量 应用程序 数据访问，并具有高容错性。

----------------------------------------------  core-site.xml --------------------
[root@Va1 hadoop]# vim   core-site.xml

<configuration>
 <property>
  <name>fs.defaultFS</name> # hdfs 规定了hadoop使用的存储方式(默认本地文件file:///存储方式)
  <value>hdfs://Va1:9000</value> # 修改为 默认的文件系统使用 hdfs(Hadoop分布式文件系统)
 </property>
 <property>
  <name>hadoop.tmp.dir</name>
  <value>/var/hadoop</value> #创建单独的所有数据文件根目录(mount 单独分区,使用分区)
                     # 配置 hadoop.tmp.dir 路径到持久化目录/var/hadoop
 </property>
</configuration>
配置过后不需要自己去创建这样的目录/var/hadoop ，格式化hdfs系统时，会自动为你创建
Hadoop 找到dfs/name 这个dfs文件系统的域名空间文件。
hadoop.tmp.dir 是 hadoop文件系统依赖的基本配置，很多配置路径都依赖它，它的默认位置在/tmp/hadoop-${user.name}下面。

由于重新配置了hadoop.tmp.dir 目录，意味着，必须重新格式hdfs

#bin/hadoop namenode -format

[root@Va1 hadoop]# ll  ../../bin/hadoop
-rwxr-xr-x 1 20415 101 6488 4月  18 2018 ../../bin/hadoop

----------------------------- /usr/local/hadoop/etc/hadoop/core-site.xml  ------- 

[root@Va1 hadoop]# tail   -10  /usr/local/hadoop/etc/hadoop/core-site.xml 

<configuration>
 <property>
  <name>fs.defaultFS</name>
  <value>hdfs://Va1:9000</value>
 </property>
 <property>
  <name>hadoop.tmp.dir</name>
  <value>/var/hadoop</value>
 </property>
</configuration>

[root@Va1 hadoop]# pwd
/usr/local/hadoop/etc/hadoop
[root@Va1 hadoop]# ll   /usr/local/hadoop/bin/hadoop
-rwxr-xr-x 1 20415 101 6488 4月  18 2018 /usr/local/hadoop/bin/hadoop

[root@Va1 hadoop]# ls  ../../
bin  include  libexec      newdir   newdir3     olddir      sbin
etc  lib      LICENSE.txt  newdir2  NOTICE.txt  README.txt  share
[root@Va1 hadoop]# ll  ../../bin/hadoop
-rwxr-xr-x 1 20415 101 6488 4月  18 2018 ../../bin/hadoop

http://hadoop.apache.org/docs/r2.7.6/
 靠近网页左下角 的链接文档
Configuration
 core-default.xml 对应配置文件 /usr/local/hadoop/etc/hadoop/core-site.xml
 hdfs-default.xml 对应配置文件 /usr/local/hadoop/etc/hadoop/hdfs-site.xml 

 mapred-default.xml 对应配置文件 /usr/local/hadoop/etc/hadoop/mapred-site.xml
 yarn-default.xml  对应配置文件   /usr/local/hadoop/etc/hadoop/yarn-site.xml 
 Deprecated Properties 对应配置文件?

点击  hdfs-default.xml  打开网页
http://hadoop.apache.org/docs/r2.7.6/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml

dfs.namenode.name.dir  file://${hadoop.tmp.dir}/dfs/name  确定DFS名称节点应在本地文件系统上存储名称表（fsimage）的位置。
如果这是一个以逗号分隔的目录列表，那么将在所有目录中复制名称表，以实现冗余。

dfs.namenode.http-address  0.0.0.0:50070  DFS namenode  Web UI将侦听的地址和基本端口

dfs.secondary.namenode.kerberos.internal.spnego.principal   ${dfs.web.authentication.kerberos.principal}
服务器主体 由辅助名称节点使用 对于 web UI SPNEGO 身份验证 when Kerberos security is enabled.  
与所有其他辅助名称节点设置一样，它在HA设置中被忽略  
如果值为“*”，Web服务器将尝试使用keytab文件df.web.authentication.kerberos.keytab中指定的每个主体登录。

dfs.namenode.secondary.http-address  0.0.0.0:50090  辅助名称节点HTTP服务器地址和端口。
dfs.namenode.secondary.https-address	0.0.0.0:50091	The secondary namenode HTTPS server address and port.

dfs.replication   3  默认块复制。创建文件时可以指定实际复制数。
                          如果在创建时间中未指定复制，则使用默认值。



  NameNode：是Master节点，是大领导。 
SecondaryNameNode：是一个小弟，非 NameNode的热备份
  Datanode 提供真实文件数据的存储服务。



principal  adj. 主要的;本金的;最重要的;资本的
n. 本金;首长，负责人;主要演员，主角;

Hadoop Distributed File  System(HDFS)
Hadoop分布式文件系统，
提供 高吞吐量 应用程序 数据访问，并具有高容错性。
 <property>
  <name> </name>
  <value> </value>
 </property>
 <property>
  <name> </name>
  <value> </value>
 </property>


/******************************
有关hadoop的配置，但是这些配置多数是将namenode和secondaryNameNode配置在同一台计算机上，
这种配置方法如果是做做实验的还可以，如果应用到实际中，存在较大风险，
如果存放namenode的主机出现问题，整个文件系统将被破坏，严重的情况是所有文件都丢失。
现在来配置hadoop2.2,将namenode和secondaryNameNode配置在不同的机器上，这样的实用价值更大。

hadoop/hdfs-site.xml 
此处将cloud002作为secondaryNameNode的主机。
3.修改hdfs-site.xml的内容

<property>
<name>dfs.http.address</name>
<value>cloud001:50070</value>
<description>
DFS名称节点Web UI将侦听的地址和基本端口。
</description>
</property>
<property>
<name>dfs.namenode.secondary.http-address</name>
<value>cloud002:50090</value>
</property>

网上也有说要修改core-site.xml的代码
******************/

------------------------ etc/hadoop/hdfs-site.xml  -------------------

[root@Va1 hadoop]# vim  /usr/local/hadoop/etc/hadoop/hdfs-site.xml 

<configuration>
 <property>
  <name>dfs.namenode.http-address</name>  #寻找 NameNode 节点
  <value>Va1:50070</value> #向所有的主机节点声明 namenode的ip 地址和基本端口
 </property>
 <property>

SecondaryNameNode：是一个小弟，非 NameNode的热备份
分担大哥namenode的工作量；
负责定时默认1小时，
是NameNode的 " 冷 备份 "；
从namenode上，获取fsimage和edits,定期合并fsimage(即名称空间) 和fsedits(即变更日志)
然后再发给namenode,减少namenode的工作量。

  <name>dfs.namenode.secondary.http-address</name>
  <value>Va1:50090</value>  # SecondaryNameNode HTTP服务器地址和端口
 </property>

<!--指定DataNode存储block的副本数量-->
文件的各个block的存储管理由datanode节点承担
---- datanode是HDFS集群从节点，每一个block都可以在多个datanode上存储多个副本
   （副本数量也可以通过参数设置dfs.replication）

 <property>
  <name>dfs.replication</name> #NameNode 告诉客户端 数据默认存多少备份
  <value>2</value>
 </property>
</configuration>
--------------------------/usr/local/hadoop/etc/hadoop/hdfs-site.xml -----------------

[root@Va1 hadoop]# tail  -15  /usr/local/hadoop/etc/hadoop/hdfs-site.xml

<configuration>
 <property>
  <name>dfs.namenode.http-address</name>
  <value>Va1:50070</value>
 </property>
 <property>
  <name>dfs.namenode.secondary.http-address</name>
  <value>Va1:50090</value>
 </property>
 <property>
  <name>dfs.replication</name>
  <value>2</value>
 </property>
</configuration>

[root@Va1 hadoop]# 

---------------/usr/local/hadoop/etc/hadoop/hdfs-site.xml --------

----------------------------------------------  core-site.xml --------------------
[root@Va1 hadoop]# vim   core-site.xml

<configuration>
 <property>
  <name>fs.defaultFS</name> # hdfs 规定了hadoop使用的存储方式(默认本地文件file:///存储方式)
  <value>hdfs://Va1:9000</value> # 修改为 默认的文件系统使用 hdfs(Hadoop分布式文件系统)
 </property>
 <property>
  <name>hadoop.tmp.dir</name>
  <value>/var/hadoop</value> #创建单独的所有数据文件根目录(mount 单独分区,使用分区)
                     # 配置 hadoop.tmp.dir 路径到持久化目录/var/hadoop
 </property>
</configuration>
配置过后不需要自己去创建这样的目录/var/hadoop ，格式化hdfs系统时，会自动为你创建
Hadoop 找到dfs/name 这个dfs文件系统的域名空间文件。
hadoop.tmp.dir 是 hadoop文件系统依赖的基本配置，很多配置路径都依赖它，它的默认位置在/tmp/hadoop-${user.name}下面。


------------- /usr/local/hadoop/etc/hadoop/core-site.xml  ----

[root@Va1 hadoop]# tail   -10  /usr/local/hadoop/etc/hadoop/core-site.xml 
<configuration>
 <property>
  <name>fs.defaultFS</name>
  <value>hdfs://Va1:9000</value>
 </property>
 <property>
  <name>hadoop.tmp.dir</name>
  <value>/var/hadoop</value>
 </property>
</configuration>

[root@Va1 hadoop]# ll  core-site.xml   hadoop-env.sh   hdfs-site.xml   mapred-site.xml   slaves   yarn-site.xml 
-rw-r--r-- 1 20415  101  774 4月  18 2018 core-site.xml # 全局配置文件

-rw-r--r-- 1 20415  101 4275 1月  24 19:06 hadoop-env.sh
-rw-r--r-- 1 20415  101  775 4月  18 2018 hdfs-site.xml  # HDFS：Hadoop分布式文件系统（核心组件）

-rw-r--r-- 1 root  root  758 1月  25 15:24 mapred-site.xml # MapReduce：分布式计算框架（核心组件）
-rw-r--r-- 1 20415  101   10 4月  18 2018 slaves  # 节点配置文件(主机名)

-rw-r--r-- 1 20415  101  690 4月  18 2018 yarn-site.xml  # Yarn：集群资源管理系统（核心组件）

[root@Va1 hadoop]# vim  /usr/local/hadoop/etc/hadoop/slaves 
[root@Va1 hadoop]# cat  /usr/local/hadoop/etc/hadoop/slaves
Va2
Va3
Va4

https://wenku.baidu.com/view/860d41d4a6c30c2259019ee3.html

rsync   -aSH  --delete  

rsync参数的具体解释如下：
-a, --archive 	归档模式，表示以递归方式传输文件，并保留所有文件属性，等于-rlptgoD
-H, --hard-links   保留硬链结
-S, --sparse 	handle sparse files efficiently 有效率处理稀疏文件
-v, --verbose 	显示同步过程详细信息
--delete 		删除那些DST中SRC没有的文件

[root@Va1 hadoop]# for  i  in  Va{2..4};do  ssh $i mkdir  /var/hadoop;done
[root@Va1 hadoop]# mkdir   /var/hadoop
[root@Va1 hadoop]# cd  /usr/local/  复制 /usr/local/hadoop 到所有的主机上
[root@Va1 local]# rsync   -aSH  --delete  /usr/local/hadoop  Va2:/usr/local/  &
[1] 6639
[root@Va1 local]# rsync   -aSH  --delete  /usr/local/hadoop  Va3:/usr/local/  &
[2] 6642
[root@Va1 local]# rsync   -aSH  --delete  /usr/local/hadoop  Va4:/usr/local/  &
[3] 6644
[root@Va1 local]# jobs
[1]   运行中               rsync -aSH --delete /usr/local/hadoop Va2:/usr/local/ &
[2]-  运行中               rsync -aSH --delete /usr/local/hadoop Va3:/usr/local/ &
[3]+  运行中               rsync -aSH --delete /usr/local/hadoop Va4:/usr/local/ &
[root@Va1 local]# wait
[1]   完成                  rsync -aSH --delete /usr/local/hadoop Va2:/usr/local/
[2]-  完成                  rsync -aSH --delete /usr/local/hadoop Va3:/usr/local/
[3]+  完成                  rsync -aSH --delete /usr/local/hadoop Va4:/usr/local/
[root@Va1 local]# jobs
[root@Va1 local]#  
[root@Va1 local]# pwd
/usr/local
[root@Va1 local]# cd  /usr/local/hadoop/
[root@Va1 hadoop]# ls
bin  include  libexec      newdir   newdir3     olddir      sbin
etc  lib      LICENSE.txt  newdir2  NOTICE.txt  README.txt  share

[root@Va1 hadoop]# ./bin/hadoop  namenode  -format  格式化[只在namenode上执行]

DEPRECATED: Use of this script to execute hdfs command is deprecated.
Instead use the hdfs command for it.

19/01/25 21:43:47 INFO namenode.NameNode: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting NameNode
STARTUP_MSG:   host = Va1/192.168.0.11
STARTUP_MSG:   args = [-format]
STARTUP_MSG:   version = 2.7.6
STARTUP_MSG:   classpath = /usr/local/hadoop/etc/hadoop/:/usr/local/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:.............
..............
19/01/25 21:43:48 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0
19/01/25 21:43:48 INFO util.ExitUtil: Exiting with status 0
19/01/25 21:43:48 INFO namenode.NameNode: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down NameNode at Va1/192.168.0.11
************************************************************/
[root@Va1 hadoop]# echo  $?
0
[root@Va1 hadoop]#   pwd
/usr/local/hadoop
[root@Va1 hadoop]# ls  /usr/local/hadoop/sbin/start-dfs.sh 
/usr/local/hadoop/sbin/start-dfs.sh

[root@Va1 hadoop]# /usr/local/hadoop/sbin/start-dfs.sh
Starting namenodes on [Va1]
Va1: starting namenode, logging to /usr/local/hadoop/logs/hadoop-root-namenode-Va1.out
Va4: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-Va4.out
Va2: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-Va2.out
Va3: starting datanode, logging to /usr/local/hadoop/logs/hadoop-root-datanode-Va3.out
Starting secondary namenodes [Va1]
Va1: starting secondarynamenode, logging to /usr/local/hadoop/logs/hadoop-root-secondarynamenode-Va1.out

[root@Va1 hadoop]# jps
7216 Jps
6913 NameNode
7101 SecondaryNameNode
[root@Va1 hadoop]# ssh  Va2  jps
6308 Jps
6233 DataNode
[root@Va1 hadoop]# ssh  Va3  jps
6258 Jps
6184 DataNode
[root@Va1 hadoop]# ssh  Va4  jps
4906 DataNode
4989 Jps
[root@Va1 hadoop]# /usr/local/hadoop/bin/hdfs  dfsadmin  -report
Configured Capacity: 54716792832 (50.96 GB)
Present Capacity: 43628851200 (40.63 GB)
DFS Remaining: 43628838912 (40.63 GB)
DFS Used: 12288 (12 KB)
DFS Used%: 0.00%
Under replicated blocks: 0
Blocks with corrupt replicas: 0
Missing blocks: 0
Missing blocks (with replication factor 1): 0

-------------------------------------------------
Live datanodes (3):

Name: 192.168.0.14:50010 (Va4)
Hostname: Va4
Decommission Status : Normal
Configured Capacity: 18238930944 (16.99 GB)
DFS Used: 4096 (4 KB)
Non DFS Used: 3699933184 (3.45 GB)
DFS Remaining: 14538993664 (13.54 GB)
DFS Used%: 0.00%
DFS Remaining%: 79.71%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Fri Jan 25 21:49:35 CST 2019


Name: 192.168.0.12:50010 (Va2)
Hostname: Va2
Decommission Status : Normal
Configured Capacity: 18238930944 (16.99 GB)
DFS Used: 4096 (4 KB)
Non DFS Used: 3714936832 (3.46 GB)
DFS Remaining: 14523990016 (13.53 GB)
DFS Used%: 0.00%
DFS Remaining%: 79.63%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Fri Jan 25 21:49:35 CST 2019


Name: 192.168.0.13:50010 (Va3)
Hostname: Va3
Decommission Status : Normal
Configured Capacity: 18238930944 (16.99 GB)
DFS Used: 4096 (4 KB)
Non DFS Used: 3673071616 (3.42 GB)
DFS Remaining: 14565855232 (13.57 GB)
DFS Used%: 0.00%
DFS Remaining%: 79.86%
Configured Cache Capacity: 0 (0 B)
Cache Used: 0 (0 B)
Cache Remaining: 0 (0 B)
Cache Used%: 100.00%
Cache Remaining%: 0.00%
Xceivers: 1
Last contact: Fri Jan 25 21:49:35 CST 2019


[root@Va1 hadoop]# 










[root@room9pc01 ~]# ssh  -X  192.168.0.12
root@192.168.0.12's password: 
Last login: Thu Jan 24 21:52:50 2019 from 192.168.0.11
[root@Va2 ~]# getenforce 
Disabled
[root@Va2 ~]# sed  -n 7p   /etc/selinux/config 
SELINUX=disabled
[root@Va2 ~]# systemctl  is-active  firewalld
unknown
[root@Va2 ~]# yum -y install  java-1.8.0-openjdk-devel >/dev/null
[root@Va2 ~]# java  -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)
[root@Va2 ~]# jps
3125 Jps
1111 Elasticsearch
[root@Va2 ~]# systemctl  stop  elasticsearch.service  && systemctl  disable  elasticsearch
Removed symlink /etc/systemd/system/multi-user.target.wants/elasticsearch.service.

[root@Va2 ~]# 配置 /etc/hosts 保证所有主机域名能够相互解析
==========   完全分布式 系统规划 =======================
主机                            角色                 软件 
192.168.0.11 Va1       NameNode           HDFS
                   SecondaryNameNode
192.168.0.12 Va2      DataNode            HDFS
192.168.0.13 Va3      DataNode            HDFS
192.168.0.14 Va4      DataNode            HDFS

[root@Va2 ~]# ping  -c1  Va1 >/dev/null  && echo Va1-Va2 ok;ping -c1 Va3 >/dev/null && echo Va2-Va3 ok ;ping  -c1  Va4 >/dev/null  && echo Va4-Va2 ok
Va1-Va2 ok
Va2-Va3 ok
Va4-Va2 ok











[root@room9pc01 ~]# ssh  -X  192.168.0.13
root@192.168.0.13's password: 
Last login: Thu Jan 24 21:52:49 2019 from 192.168.0.11
[root@Va3 ~]# getenforce 
Disabled
[root@Va3 ~]# grep  -n  "^SELINUX="  /etc/selinux/config 
7:SELINUX=disabled
[root@Va3 ~]# service  iptables  status  |grep -io active
Redirecting to /bin/systemctl status iptables.service
Unit iptables.service could not be found.

[root@Va3 ~]# systemctl  stop  firewalld && systemctl mask  firewalld
Failed to stop firewalld.service: Unit firewalld.service not loaded.

[root@Va3 ~]# yum -y  install  java-1.8.0-openjdk-devel  >/dev/null

[root@Va3 ~]# rpm  -qa  |grep  java
tzdata-java-2017b-1.el7.noarch
javapackages-tools-3.4.1-11.el7.noarch
java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64
java-1.8.0-openjdk-devel-1.8.0.131-11.b12.el7.x86_64
java-1.8.0-openjdk-headless-1.8.0.131-11.b12.el7.x86_64
python-javapackages-3.4.1-11.el7.noarch

[root@Va3 ~]# java  -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)

[root@Va3 ~]# jps
3113 Jps
1113 Elasticsearch
[root@Va3 ~]# systemctl  stop  elasticsearch && systemctl  disable  elasticsearch
Removed symlink /etc/systemd/system/multi-user.target.wants/elasticsearch.service.

[root@Va3 ~]# 配置 /etc/hosts 保证所有主机域名能够相互解析
==========   完全分布式 系统规划 =======================
主机                            角色                 软件 
192.168.0.11 Va1       NameNode           HDFS
                   SecondaryNameNode
192.168.0.12 Va2      DataNode            HDFS
192.168.0.13 Va3      DataNode            HDFS
192.168.0.14 Va4      DataNode            HDFS










==========   完全分布式 系统规划 =======================
主机                            角色                 软件 
192.168.0.11 Va1       NameNode           HDFS
                   SecondaryNameNode
192.168.0.12 Va2      DataNode            HDFS
192.168.0.13 Va3      DataNode            HDFS
192.168.0.14 Va4      DataNode            HDFS

  NameNode：是Master节点，是大领导。 
SecondaryNameNode：是一个小弟，非 NameNode的热备份
  Datanode 提供真实文件数据的存储服务。

禁用 selinux 和 iptables
配置 /etc/hosts 保证所有主机域名能够相互解析

1、安装 java 
yum install java-1.8.0-openjdk -y

验证：
java -version

2、安装 jps
yum install java-1.8.0-openjdk-devel -y

验证：jps

[root@room9pc01 ~]# ssh  -X  192.168.0.14
..........
[root@Va4 ~]# systemctl mask   firewalld
Created symlink from /etc/systemd/system/firewalld.service to /dev/null.

[root@Va4 ~]# getenforce 
Disabled
[root@Va4 ~]# sed  -n  7p  /etc/selinux/config
SELINUX=disabled
[root@Va4 ~]# grep  -n  "^SELINUX="   /etc/selinux/config
7:SELINUX=disabled

[root@Va4 ~]# service  iptables  status  |grep  -io active
Redirecting to /bin/systemctl status iptables.service
Unit iptables.service could not be found.

[root@Va4 ~]# yum  -y  install  java-1.8.0-openjdk  java-1.8.0-openjdk-devel  |tail  -2

完毕！
[root@Va4 ~]# rpm  -qa  |grep  java
tzdata-java-2017b-1.el7.noarch
javapackages-tools-3.4.1-11.el7.noarch
java-1.8.0-openjdk-1.8.0.131-11.b12.el7.x86_64
java-1.8.0-openjdk-devel-1.8.0.131-11.b12.el7.x86_64
java-1.8.0-openjdk-headless-1.8.0.131-11.b12.el7.x86_64
python-javapackages-3.4.1-11.el7.noarch

[root@Va4 ~]# jps  #验证：jps
1760 Jps
1098 Elasticsearch

[root@Va4 ~]# java  version
错误: 找不到或无法加载主类 version
[root@Va4 ~]# java  -version
openjdk version "1.8.0_131"
OpenJDK Runtime Environment (build 1.8.0_131-b12)
OpenJDK 64-Bit Server VM (build 25.131-b12, mixed mode)

[root@Va4 ~]# systemctl  stop  elasticsearch.service  &&  systemctl disable   elasticsearch
Removed symlink /etc/systemd/system/multi-user.target.wants/elasticsearch.service.

[root@Va4 ~]# 配置 /etc/hosts 保证所有主机域名能够相互解析
==========   完全分布式 系统规划 =======================
主机                            角色                 软件 
192.168.0.11 Va1       NameNode           HDFS
                   SecondaryNameNode
192.168.0.12 Va2      DataNode            HDFS
192.168.0.13 Va3      DataNode            HDFS
192.168.0.14 Va4      DataNode            HDFS





















