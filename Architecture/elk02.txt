1 昨天已经搭建好 elasticsearch 集群
清除所有 index
导入 logs.jsonl 日志

mapping：
映射：创建索引的时候，可以预先定义字段的类型及相关属性。
作用：这样会让索引建立得更加的细致和完善。
分类：静态映射和动态映射。
动态映射：自动根据数据进行相应的映射。
静态映射：自定义字段映射数据类型。

kibana部分

1.kibana的概念及特点。
概念：数据可视化平台工具
特点：
    - 灵活的分析和可视化平台
    - 实时总结和流数据的图表
    - 为不同的用户显示直观的界面
    - 即时分享和嵌入的仪表板

2.kibana的安装配置。
rpm -ivh kibana-4.5.2-1.x86_64.rpm

#配置 kibana 
/opt/kibana/config/kibana.yml
server.port: 5601
server.host: "0.0.0.0"
elasticsearch.url: "http://192.168.4.13:9200"
kibana.index: ".kibana"
kibana.defaultAppId: "discover"
elasticsearch.pingTimeout: 1500
elasticsearch.requestTimeout: 30000
elasticsearch.startupTimeout: 5000

通过图形页面展示，注意时间是 2015 年，需要调整时间才能正常显示

logstash部分

3.logstash的概念及特点。
概念：logstash是一个数据采集、加工处理以及传输(输出)的工具。
特点：
    - 所有类型的数据集中处理
    - 不同模式和格式数据的正常化
    - 自定义日志格式的迅速扩展
    - 为自定义数据源轻松添加插件

安装Logstash
rpm -ivh logstash-2.3.4-1.noarch.rpm
Logstash 依赖 java 环境，需要安装 java-1.8.0-openjdk

安装之后，创建第一个测试的配置文件
/etc/Logstash/logstash.conf
input{ stdin{} } 
filter{  }
output{ stdout{} }

使用 logstash -f logstash.conf 启动，如果输入数据能看到返回证明 logstash 安装正确

logstash 数据处理结构
                          | -------------------------logstash---------------------------|
  ｛数据源｝ -->{ input{数据接收} -- filter{数据处理} -- output{数据发送}  } --> {ES集群}
                          |--------------------------logstash---------------------------|


布尔值类型:  ssl_enable => true
字节类型:     bytes => "1MiB"
字符串类型:  name => "xkops"
数值类型:     port => 22
数组:            match => ["datetime","UNIX"]
哈希:            options => {key1 => "value1",key2 => "value2"}
编码解码:     codec => "json"
路径:            file_path => "/tmp/filename"
注释:       #

条件判断：
等于:       ==
不等于:     !=
小于:       <
大于:       >
小于等于:   <=
大于等于:   >=
匹配正则:   =~
不匹配正则: !~
包含:        in
不包含:     not in 
与:	and
或:	or
非与:          nand
非或:	xor
复合表达式: ()
取反符合:   !()

logstash-file 插件: 从文件读取，在屏幕输出
file插件字段解释：
codec =>  #可选项，默认是plain，可设置其他编码方式。
discover_interval => #可选项，logstash多久检查一下path下有新文件，默认15s。
exclude => #可选项，排除path下不想监听的文件。
sincedb_path => #可选项，记录文件以及文件读取信息位置的数据文件。~/.sincedb_xxxx
sincedb_write_interval => #可选项，logstash多久写一次sincedb文件，默认15s.
stat_interval => #可选项，logstash多久检查一次被监听文件的变化，默认1s。
start_position => #可选项，logstash从哪个位置读取文件数据，默认从尾部，值为：end。初次导入，设置为：beginning。
path => #必选项，配置文件路径，可定义多个。
tags => #可选项，在数据处理过程中，由具体的插件来添加或者删除的标记。
type => #可选项，自定义处理时间类型。比如nginxlog。

input{
    file{
        start_position => "beginning"
        sincedb_path => "/var/lib/logstash/sincedb-access"
        path => ["/tmp/blog","/tmp/alog"]
        type => 'filelog'
    }
}

filter{  }
output{ stdout{} }

logstash-tcp 插件：从网络读取，在屏幕输出
tcp插件字段解释：
add_field => #可选项，默认{}。
codec => #可选项，默认plain。
data_timeout => #可选项，默认-1。
host => #可选项，默认0.0.0.0。
mode => #可选项，值为["server","client"]之一，默认为server。
port => #必选，端口。
ssl_cacert => #可选项，定义相关路径。
ssl_cert => #可选项，定义相关路径。
ssl_enable => #可选项，默认为false。
ssl_key => #可选项，定义相关路径。
ssl_key_passphrase => #可选项，默认nil
ssl_verify => #可选项，默认false。
tags => #可选项
type => #可选项
input{
    tcp{
        host => "0.0.0.0"
        port => 8888
        type => "tcplog"
    }
}
filter{  }
output{ stdout{} }

在服务器上启动 logstash , 在客户机上使用 shell 脚本测试
function tcpmsg() {
    exec 9<>/dev/tcp/192.168.4.10/8888
    echo -ne "${1}\r\n" >&9
    exec 9<&-
}

logstash-udp插件：
udp插件字段解释：
add_field => #可选项，默认{}。
host => #可选项，默认0.0.0.0。
queue_size => #默认2000
tags => #可选项
type => #可选项
workers => #默认为2

input{
    udp{
        host => "192.168.4.10"
        port => 9999
    }
}
filter{  }
output{ stdout{} }

在服务器上启动 logstash , 在客户机上使用 shell 脚本测试
function udpmsg() {
    exec 9<>/dev/udp/192.168.4.10/9999
    echo -ne "${1}\r" >&9
    exec 9<&-
}

logstash-syslog 插件：

input{
    syslog{
        host => "192.168.4.10"
        port => 514
        type => "syslog"
    }
}
filter{  }
output{ stdout{} }

在服务器启动 logstash，在客户机修改 /etc/rsyslog.conf 配置问件，添加
*.*	@@192.168.4.10:514
重新启动 rsyslog 服务
systemctl restart rsyslog
使用明令写入 syslog 进行测试
logger -p local0.info -t test_logstash 'test message'
输入命令以后可以在 /var/log/messages 看到，在 logstash 服务器端也同时能看到输出

codec类插件
常用的插件：plain、json、json_lines、rubydebug、multiline等

input{
    file{
        start_position => "beginning"
        sincedb_path => "/dev/null"
        path => ["/tmp/alog"]
        type => 'filelog'
        codec => "json"
    }
}
output{
    stdout{ codec => "rubydebug" }
}

利用 rubydebug 方便调试，如果输入在文件是 json 在 input 指定编码格式

filter grok插件：解析各种非结构化的日志数据插件
grok有丰富的patterns,查看方式
/opt/logstash/vendor/bundle/jruby/1.9/gems/logstash-patterns-core-2.0.5/patterns/grok-patterns

filter{
    grok{
        match => ["message","%{IP:ip} %{WORD:method} %{URIPATH:uri} %{NUMBER:bytes} %{NUMBER:duration}"]
    }
}

grok 使用正则表达式把飞结构化的数据结构化在分组匹配，正则表达式需要根据具体数据结构编写，虽然编写困难，但适用性极广，几乎可以应用于各类数据

最后是一个完整的 Logstash 的配置文件，使用Logstash 收集数据，格式化以后放入 ES 集群
input{
    file{
        start_position => "beginning"
        sincedb_path => "/dev/null"
        path => ["/tmp/alog"]
        type => 'filelog'
        codec => "json"
    }
}

filter{
}
output{ 
    if [type] == "filelog"{
    elasticsearch {
        hosts => ["192.168.4.15:9200"]
        index => "weblog"
        flush_size => 2000
        idle_flush_time => 10
    }}
}

放入集群以后的数据可以通过 kibana 展示
在生产环境中，我们往往还需要配置 redis 用来缓存 或 filebeat 用来收集日志，这里给出简单的配置样例，需要更深入学习的同学请查看官方文档

https://github.com/logstash-plugins

redis 配置
input{
    redis{
    host => 'redis-server'
    port => '6379'
    data_type => 'list'
    key => 'lb'
    codec => 'json'
    }
}

filebeat 配置
input {
    beats {
        port => 5044
        codec => "json"
    }
}

filebeat 客户端相关配置文件
filebeat:
  prospectors:
    -
      paths:
        - /root/logs.jsonl
      document_type: logstash
    - 
      paths:
        - /root/shakespeare.json
      document_type: shakespeare
    - 
      paths:
        - /root/accounts.json
      document_type: account
    
  registry_file: /var/lib/filebeat/registry
output:
  logstash:
    hosts: ["192.168.4.10:5044"]
shipper:
logging:
  files:
